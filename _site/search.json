[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rain or Shine: Unveiling The Mysteries of Singapore Weather",
    "section": "",
    "text": "Introduction\nAs a small, low-lying city-state, Singapore is vulnerable to the effects of climate change which has brought about more extreme weather patterns - rising sea levels, dry spells and intense rainfall which at times can lead to flash floods.\n\nAccording to an infographic above by the National Climate Change Secretariat Singapore:\n\nDaily mean temperatures are projected to increase by 1.4 to 4.6 degrees celsius; and\nThe contrast between the wet months (November to January) and dry months (February and June to September) is likely to be more pronounced.\n\nIn Jan 2024, the Centre for Climate Research Singapore (CCRS) announced the Third National Climate Change Study (V3) which provided potential scenarios of our future based on low, medium, and high global greenhouse gas emissions.\n\nVery hot days will become more frequent.\nExtreme daily rainfall is projected to intensify.\nThe mean sea level around Singapore is projected to rise up to 1.15m by end century, and up to around 2m by 2150 under the high emissions scenario.\n\nIt is important that we better understand how climate change has been affecting Singapore, by understanding the trends in our daily temperatures and rainfall over the years, and utilise historical data to forecast future climate data. It will provide guidance on whether and how Singapore will need to urgently develop ways to mitigate and adapt.\n\n\nKey Observations\n\n\nShiny App\n\n\nUser Guide\n\n\nPoster"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi there, we are Group 12 of ISSS608 Visual Analytics & Applications AY2023-24 January Term!"
  },
  {
    "objectID": "Proposal/proposal.html",
    "href": "Proposal/proposal.html",
    "title": "Project Proposal",
    "section": "",
    "text": "1 Project Motivation\nAs a small, low-lying city-state, Singapore is vulnerable to the consequences of climate change, such as rising sea levels, intense rainfall, dry spells and other extreme weather events. In Jan 2024, the Centre for Climate Research Singapore (CCRS) announced the Third National Climate Change Study (V3) which provided a preview into potential scenarios of our future based on low, medium, and high global greenhouse gas emissions. Very hot days will become more frequent. Extreme daily rainfall is projected to intensify. The mean sea level around Singapore is projected to rise up to 1.15m by end century, and up to around 2m by 2150 under the high emissions scenario.\nAdapting to the effects of climate change is a national priority and Singapore has started to integrate long-term adaptation planning into national policies for key sectors including food security, public health, infrastructure resilience, flood risks, water security, coastal line and biodiversity, as indicated in its intended Nationally Determined Contribution to the United Nations Framework Convention on Climate Change (UNFCCC).\nIt is important that we take a closer look into how climate change has been affecting Singapore, by understanding the trends in our daily temperatures, rainfall and sea level rise over the years and utilise historical data to forecast future climate data. This will allow us to ascertain the severity of the impact of climate change and provide guidance as to whether Singapore will need to more urgently develop ways to mitigate and adapt.\n\n\n2 Issues to Address\n\nWhat are the trends in daily temperature across the years?\nWhat are the trends in rainfall across the years?\nWhich areas (based on weather station location) are hotter and have more rain?\nWhat is the future trend of temperature and rainfall? Is Singapore really going to get hotter and experience more rain?\nWould certain regions within Singapore experience a greater increase in temperature and precipitation as compared to other areas?\n\n\n\n3 Approach\n\nData Preparation\n\nTo make use of monthly weather data from 2014 to 2023\nDownloaded from weather.gov.sg\n\nExploratory Data Analysis (EDA)\n\nTrend of monthly temperature, and rainfall across years\nTrend of mean monthly temperature and rainfall\nGeospatial distribution of temperature and rainfall across Singapore\n\n\n\n\nConfirmatory Data Analysis (CDA)\n\nAre the changes in rainfall/ temperature statistically significant? \nAre there really certain months “drier” or “wetter”/ “hotter” or “cooler”?\nAre there certain locations “drier” or “wetter”/ “hotter” or “cooler”?\n\nForecasting\n\nTime-series forecasting of temperature, rainfall and wind speed in the next 10 to 30 years\n\n\n\n\n4 Possible Ideas for Shiny Dashboard\n\nTemperature trend across the years\n\nInteractivity: allow user to select a range of years, for whole Singapore or a particular location (based on weather stations)\n\nRain fall trend across the years\n\nInteractivity: allow user to select a range of years, for whole Singapore or a particular location (based on weather stations)\n\nProjections for temperature and rain\n\n\n\nDraft Shiny Dashboard\n\n\n\n\n\n5 Relevant Work and References\n\nhttps://climateknowledgeportal.worldbank.org/country/singapore\nhttps://www.nccs.gov.sg/ \nhttps://iopscience.iop.org/article/10.1088/1757-899X/407/1/012154/pdf\nhttps://www.sciencedirect.com/science/article/pii/S266682702100102X\nhttps://arxiv.org/pdf/1302.6613.pdf"
  },
  {
    "objectID": "Meeting_Minutes/meeting_minutes.html",
    "href": "Meeting_Minutes/meeting_minutes.html",
    "title": "Group 12 Project Meeting Minutes",
    "section": "",
    "text": "Refer to the links below for Group 12’s meeting minutes:\n\nMeeting 1\nMeeting 2\nMeeting 3\nMeeting 4"
  },
  {
    "objectID": "Analysis/CDA.html",
    "href": "Analysis/CDA.html",
    "title": "Confirmatory Data Analysis",
    "section": "",
    "text": "The group’s Confirmatory Data Analysis seeks to address the following issues:\n\nAre the changes in rainfall and temperature over the years statistically significant? \nAre there really certain months “drier” or “wetter”/ “hotter” or “cooler”?\nAre there certain locations “drier” or “wetter”/ “hotter” or “cooler”?"
  },
  {
    "objectID": "Analysis/CDA.html#issues-to-address",
    "href": "Analysis/CDA.html#issues-to-address",
    "title": "Prototype - Confirmatory Data Analysis",
    "section": "",
    "text": "The group’s Confirmatory Data Analysis seeks to address the following issues:\n\nAre the changes in rainfall and temperature over the years statistically significant? \nAre there really certain months “drier” or “wetter”/ “hotter” or “cooler”?\nAre there certain locations “drier” or “wetter”/ “hotter” or “cooler”?"
  },
  {
    "objectID": "Analysis/CDA.html#the-data",
    "href": "Analysis/CDA.html#the-data",
    "title": "Prototype - Confirmatory Data Analysis",
    "section": "2. The Data",
    "text": "2. The Data\nFor the project, data utilised is the historical climate data from Metrological Service Singapore.\nThe team downloaded historical daily records from various weather stations across Singapore from 1980 to 2023 via API scrapping as a daily_historical.csv datafile, which was subsequently processed to weather_data_imputed.rds."
  },
  {
    "objectID": "Analysis/CDA.html#set-up",
    "href": "Analysis/CDA.html#set-up",
    "title": "Prototype - Confirmatory Data Analysis",
    "section": "3. Set-up",
    "text": "3. Set-up\n\n3.1 Installing and loading the required libraries\nThe following code chunk is used to install the necessary R packages:\n\npacman::p_load(tidyverse,ggridges,ggrepel,ggthemes,ggstatsplot,ggsignif,hrbrthemes,patchwork,dplyr, gifski, gapminder,plotly,gganimate,ggiraph,magick,car,lubridate)\n\n\n\n3.2 Importing the Dataset\n\nweather_data &lt;- read_rds(\"data/weather_data_imputed.rds\")\n\nglimpse(weather_data)\n\nRows: 1,548\nColumns: 6\nGroups: station [13]\n$ station                  &lt;chr&gt; \"Admiralty\", \"Admiralty\", \"Admiralty\", \"Admir…\n$ DATE                     &lt;date&gt; 2014-01-01, 2014-02-01, 2014-03-01, 2014-04-…\n$ mean_monthly_temperature &lt;dbl&gt; 26.22903, 25.79355, 26.76071, 27.35484, 27.81…\n$ min_monthly_temperature  &lt;dbl&gt; 21.70000, 22.40000, 21.80000, 23.50000, 22.40…\n$ max_monthly_temperature  &lt;dbl&gt; 25.30000, 24.90000, 24.90000, 25.80000, 26.50…\n$ monthly_rainfall         &lt;dbl&gt; 98.8000, 15.8000, 120.0000, 261.4000, 301.000…\n\nDT::datatable(weather_data)\n\n\n\n\n\nAs can be seen, there are a total of 1548 records across 6 variables:\n\nstation\nDATE\nmean_monthly_temperature\nmin_monthly_temperature\nmax_monthly_temperature\nmonthly_rainfalls\n\n\n\n3.3 Data Cleaning\n\n3.3.1 Check for missing values\n\nsum(is.na(weather_data))\n\n[1] 0\n\n\n\n\n3.3.2 Ensuring alignment in time period of records across weather stations\n\nStarting YearEnding Year\n\n\n\nweather_data_start &lt;- weather_data %&gt;% \n  group_by(station) %&gt;% \n  mutate(year=year(lubridate::ymd(DATE))) %&gt;%\n  summarise(earliest_year = min(year))\n\nweather_data_start\n\n# A tibble: 13 × 2\n   station               earliest_year\n   &lt;chr&gt;                         &lt;dbl&gt;\n 1 Admiralty                      2014\n 2 Ang Mo Kio                     2014\n 3 Changi                         2014\n 4 Choa Chu Kang (South)          2014\n 5 Clementi                       2014\n 6 East Coast Parkway             2014\n 7 Jurong (West)                  2014\n 8 Jurong Island                  2014\n 9 Newton                         2014\n10 Pasir Panjang                  2014\n11 Sentosa Island                 2014\n12 Tai Seng                       2014\n13 Tuas South                     2014\n\n\n\n\n\nweather_data_end &lt;- weather_data %&gt;%\n  group_by(station) %&gt;%\n  mutate(year=year(lubridate::ymd(DATE))) %&gt;%\n  summarise(latest_year = max(year))\n\nweather_data_end\n\n# A tibble: 13 × 2\n   station               latest_year\n   &lt;chr&gt;                       &lt;dbl&gt;\n 1 Admiralty                    2023\n 2 Ang Mo Kio                   2023\n 3 Changi                       2023\n 4 Choa Chu Kang (South)        2023\n 5 Clementi                     2023\n 6 East Coast Parkway           2023\n 7 Jurong (West)                2023\n 8 Jurong Island                2023\n 9 Newton                       2023\n10 Pasir Panjang                2023\n11 Sentosa Island               2023\n12 Tai Seng                     2023\n13 Tuas South                   2023\n\n\n\n\n\nThe starting and ending year of weather data across all 13 weather stations is 2014 and 2023 respectively, no further steps are required to align the time period of the data.\n\n\n3.3.3 Detailed dataset - adding year and month columns - for ease of analysis\nFor ease of analysis, the DATE in weather_data was further broken down into year and month and added as columns to weather_data_detailed:\n\nweather_data_detailed &lt;- weather_data %&gt;%\n  mutate(year=year(lubridate::ymd(DATE))) %&gt;%\n  mutate(month=month(lubridate::ymd(DATE)))\n\nglimpse(weather_data_detailed)\n\nRows: 1,548\nColumns: 8\nGroups: station [13]\n$ station                  &lt;chr&gt; \"Admiralty\", \"Admiralty\", \"Admiralty\", \"Admir…\n$ DATE                     &lt;date&gt; 2014-01-01, 2014-02-01, 2014-03-01, 2014-04-…\n$ mean_monthly_temperature &lt;dbl&gt; 26.22903, 25.79355, 26.76071, 27.35484, 27.81…\n$ min_monthly_temperature  &lt;dbl&gt; 21.70000, 22.40000, 21.80000, 23.50000, 22.40…\n$ max_monthly_temperature  &lt;dbl&gt; 25.30000, 24.90000, 24.90000, 25.80000, 26.50…\n$ monthly_rainfall         &lt;dbl&gt; 98.8000, 15.8000, 120.0000, 261.4000, 301.000…\n$ year                     &lt;dbl&gt; 2014, 2014, 2014, 2014, 2014, 2014, 2014, 201…\n$ month                    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 1, 2, 3, 4…\n\n\nSaving it as a csv file for analysis:\n\nwrite_csv(weather_data_detailed, \"data/weather_data_detailed.csv\")\n\n\nweather_data_detailed %&gt;%\n  group_by(station) %&gt;%\n  summarise(\"Mean Temp\" = mean(mean_monthly_temperature),\n            \"Max Temp\" = max(max_monthly_temperature),\n            \"Min Temp\" = min(min_monthly_temperature),\n            \"Total Rainfall\" = sum(monthly_rainfall))\n\n# A tibble: 13 × 5\n   station               `Mean Temp` `Max Temp` `Min Temp` `Total Rainfall`\n   &lt;chr&gt;                       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;            &lt;dbl&gt;\n 1 Admiralty                    27.7       28.5       21.4           23190.\n 2 Ang Mo Kio                   28.0       29         21.2           24737.\n 3 Changi                       28.0       29         21.1           19207.\n 4 Choa Chu Kang (South)        27.8       28.5       21.2           26331.\n 5 Clementi                     27.8       28.5       21.1           24455.\n 6 East Coast Parkway           28.2       29.7       21.1           17311.\n 7 Jurong (West)                27.5       28.7       20.4           25619.\n 8 Jurong Island                28.3       29         21.4           21888.\n 9 Newton                       27.7       28.5       21.1           22389.\n10 Pasir Panjang                28.3       29.4       21.1           21811.\n11 Sentosa Island               28.3       29         21.5           19897.\n12 Tai Seng                     28.4       29.4       21.7           23564.\n13 Tuas South                   28.2       29         21.7           24599."
  },
  {
    "objectID": "Analysis/CDA.html#confirmatory-data-analysis-cda",
    "href": "Analysis/CDA.html#confirmatory-data-analysis-cda",
    "title": "Prototype - Confirmatory Data Analysis",
    "section": "4. Confirmatory Data Analysis (CDA)",
    "text": "4. Confirmatory Data Analysis (CDA)"
  },
  {
    "objectID": "Analysis/CDA.html#cda-1---are-the-changes-in-rainfall-and-temperature-over-the-years-statistically-significant",
    "href": "Analysis/CDA.html#cda-1---are-the-changes-in-rainfall-and-temperature-over-the-years-statistically-significant",
    "title": "Confirmatory Data Analysis",
    "section": "4.1 CDA #1 - Are the changes in rainfall and temperature over the years statistically significant? ",
    "text": "4.1 CDA #1 - Are the changes in rainfall and temperature over the years statistically significant?"
  },
  {
    "objectID": "Analysis/CDA.html#rainfall",
    "href": "Analysis/CDA.html#rainfall",
    "title": "Confirmatory Data Analysis",
    "section": "4.1.1 Rainfall",
    "text": "4.1.1 Rainfall\n\n\nShow the code\nrainfall_data_year &lt;- weather_data_detailed %&gt;%\n  group_by(year) %&gt;%\n  summarise(yearly_rainfall = sum(monthly_rainfall))\n\nrainfall_data_month &lt;- weather_data_detailed %&gt;%\n  group_by(year,month) %&gt;%\n  summarise(monthly_rainfall = sum(monthly_rainfall))\n\nDT::datatable(rainfall_data_year,class = \"compact\")\n\n\n\n\n\n\nShow the code\nDT::datatable(rainfall_data_month,class = \"compact\")\n\n\n\n\n\n\nSaving as a csv files:\n\n\nShow the code\nwrite_csv(rainfall_data_year, \"data/rainfall_data_year.csv\")\nwrite_csv(rainfall_data_month, \"data/rainfall_data_month.csv\")\n\n\n\n4.1.1.1 Overview of rainfall over the years\n\np1 &lt;- ggplot(rainfall_data_year,\n             aes(y=yearly_rainfall,\n                 x = year))+\n  geom_point()+\n  geom_line() +\n  labs(title=\"Rainfall from 2014 to 2023\",\n       y = \"Rainfall volume (mm)\",\n       x = \"Year\") +\n  scale_x_continuous(breaks =seq(2014,2023,1)) +\n  theme_minimal() +\n  theme(axis.text.x=element_text(angle=90,hjust=1),panel.spacing.y = unit(5,\"lines\"),legend.position = \"none\")\n\nggplotly(p1)\n\n\n\n\n\nOver the years, the rainfall volume is generally observed to have increased. We need to examine if the differences are statistically different.\nBefore we do so, we will need to determine whether the rainfall for each year follows a normal or non-normal distribution and we visualise the distribution of rainfall using ridgeline plots, using the code chunk below.\n\n\n4.1.1.2 Distribution of Rainfall within the year from 2014 to 2023\n\np2 &lt;- ggplot(weather_data_detailed,\n       aes(x = monthly_rainfall,\n           y = as.factor(year), \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1,\n                       option=\"turbo\")+\n  theme_ridges()+\n  labs(title=\"Distribution of Rainfall from 2014 to 2023\",\n       y=\"Year\",\n       x=\"Rainfall Volume (mm)\")\n\np2\n\n\n\n\n\n\n\n\n\n\n4.1.1.3 Normality Test - Shapiro-Wilk Normality Test\n\nH0: Sample distribution is normal\nH1: Sample distribution is non-normal\n\nWe test whether the distribution of rainfall within the year from the period of 2014 to 2023 is normal. As the p-values are &lt; 0.05, we reject null hypothesis. There is sufficient evidence to indicate that the distribution of rainfall within the year from the period of 2014 to 2023 is non-normal.\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2014))$monthly_rainfall)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2014))$monthly_rainfall\nW = 0.9544, p-value = 7.735e-05\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2015))$monthly_rainfall)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2015))$monthly_rainfall\nW = 0.90846, p-value = 2.953e-08\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2016))$monthly_rainfall)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2016))$monthly_rainfall\nW = 0.96784, p-value = 0.001211\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2017))$monthly_rainfall)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2017))$monthly_rainfall\nW = 0.977, p-value = 0.01075\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2018))$monthly_rainfall)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2018))$monthly_rainfall\nW = 0.95739, p-value = 0.0001022\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2019))$monthly_rainfall)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2019))$monthly_rainfall\nW = 0.9572, p-value = 9.825e-05\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2020))$monthly_rainfall)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2020))$monthly_rainfall\nW = 0.97613, p-value = 0.008258\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2021))$monthly_rainfall)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2021))$monthly_rainfall\nW = 0.97156, p-value = 0.002593\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2022))$monthly_rainfall)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2022))$monthly_rainfall\nW = 0.95165, p-value = 3.158e-05\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2023))$monthly_rainfall)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2023))$monthly_rainfall\nW = 0.96388, p-value = 0.0004215\n\n\n\n\n4.1.1.4 Equal Variance Assumption Test\n\nH0: Groups (different years) have equal variances\nH1: Groups (different years) have different variances\n\n\n\nShow the code\nleveneTest(monthly_rainfall ~ as.factor(year), data = weather_data_detailed)\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n        Df F value    Pr(&gt;F)    \ngroup    9  6.3242 7.792e-09 ***\n      1538                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nFrom the above result, we can observe that p-value &lt; 0.05. We have enough evidence to reject the null hypothesis. So the variance across the samples is not equal at 0.05 significance level.\n\nGiven the above, a non-parametric test will be utilised:\n\n\n4.1.1.5 Statistical Test for Rainfall across years\nThe hypothesis is as follows:\nH0: There is no difference between rainfall per year across 10 years.\nH1: There is a difference between rainfall per year across 10 years.\n\np3 &lt;- ggbetweenstats(\n  data = weather_data_detailed,\n  x = year, \n  y = monthly_rainfall,\n  type = \"np\",\n  pairwise.display = \"significant\",\n  conf.level = 0.95,\n  messages = FALSE,\n  title=\"Distribution of Rainfall across 10 years (2014 to 2023)\",\n  ylab = \"Rainfall volume (mm)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 2)\n) +\n  theme(text = element_text(size = 10), plot.title=element_text(size=10))\n\np3\n\n\n\n\n\n\n\n\nThe plot above shows that the p-value&lt; 0.05 and for which the null hypothesis will be rejected at alpha = 0.05. There is sufficient evidence to indicate that there is a difference in the rainfall across the years from 2014 to 2023."
  },
  {
    "objectID": "Analysis/CDA.html#overview-of-rainfall-over-the-years",
    "href": "Analysis/CDA.html#overview-of-rainfall-over-the-years",
    "title": "Prototype - Confirmatory Data Analysis",
    "section": "Overview of rainfall over the years",
    "text": "Overview of rainfall over the years\n\np1 &lt;- ggplot(rainfall_data_year,\n             aes(y=yearly_rainfall,\n                 x = year))+\n  geom_point()+\n  geom_line() +\n  labs(title=\"Rainfall from 2014 to 2023\",\n       y = \"Rainfall volume (mm)\",\n       x = \"Year\") +\n  scale_x_continuous(breaks =seq(2014,2023,1)) +\n  theme_minimal() +\n  theme(axis.text.x=element_text(angle=90,hjust=1),panel.spacing.y = unit(5,\"lines\"),legend.position = \"none\")\n\nggplotly(p1)\n\n\n\n\n\nOver the years, the rainfall volume is generally observed to have increased. We need to examine if the differences are statistically different.\nBefore we do so, we will need to determine whether the rainfall for each year follows a normal or non-normal distribution and we visualise the distribution of rainfall using ridgeline plots, using the code chunk below.\n\n4.1.1.2 Distribution of Rainfall within the year from 2014 to 2023\n\np2 &lt;- ggplot(weather_data_detailed,\n       aes(x = monthly_rainfall,\n           y = as.factor(year), \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1,\n                       option=\"turbo\")+\n  theme_ridges()+\n  labs(title=\"Distribution of Rainfall from 2014 to 2023\",\n       y=\"Year\",\n       x=\"Rainfall Volume (mm)\")\n\np2\n\n\n\n\n\n\n\n\n\n\n4.1.1.3 Normality Test - Shapiro-Wilk Normality Test\n\nH0: Sample distribution is normal\nH1: Sample distribution is non-normal\n\nWe test whether the distribution of rainfall within the year from the period of 2014 to 2023 is normal. As the p-values are &lt; 0.05, we reject null hypothesis. There is sufficient evidence to indicate that the distribution of rainfall within the year from the period of 2014 to 2023 is non-normal.\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2014))$monthly_rainfall)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2014))$monthly_rainfall\nW = 0.9544, p-value = 7.735e-05\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2015))$monthly_rainfall)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2015))$monthly_rainfall\nW = 0.90846, p-value = 2.953e-08\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2016))$monthly_rainfall)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2016))$monthly_rainfall\nW = 0.96784, p-value = 0.001211\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2017))$monthly_rainfall)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2017))$monthly_rainfall\nW = 0.977, p-value = 0.01075\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2018))$monthly_rainfall)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2018))$monthly_rainfall\nW = 0.95739, p-value = 0.0001022\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2019))$monthly_rainfall)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2019))$monthly_rainfall\nW = 0.9572, p-value = 9.825e-05\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2020))$monthly_rainfall)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2020))$monthly_rainfall\nW = 0.97613, p-value = 0.008258\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2021))$monthly_rainfall)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2021))$monthly_rainfall\nW = 0.97156, p-value = 0.002593\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2022))$monthly_rainfall)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2022))$monthly_rainfall\nW = 0.95165, p-value = 3.158e-05\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2023))$monthly_rainfall)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2023))$monthly_rainfall\nW = 0.96388, p-value = 0.0004215\n\n\n\n\n4.1.1.4 Equal Variance Assumption Test\n\nH0: Groups (different years) have equal variances\nH1: Groups (different years) have different variances\n\n\nleveneTest(monthly_rainfall ~ as.factor(year), data = weather_data_detailed)\n\nLevene's Test for Homogeneity of Variance (center = median)\n        Df F value    Pr(&gt;F)    \ngroup    9  6.3242 7.792e-09 ***\n      1538                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nFrom the above result, we can observe that p-value &lt; 0.05. We have enough evidence to reject the null hypothesis. So the variance across the samples is not equal at 0.05 significance level.\n\nGiven the above, a non-parametric test will be utilised:"
  },
  {
    "objectID": "Analysis/CDA.html#rainfall-across-years",
    "href": "Analysis/CDA.html#rainfall-across-years",
    "title": "Prototype - Confirmatory Data Analysis",
    "section": "Rainfall across years",
    "text": "Rainfall across years\nThe hypothesis is as follows:\nH0: There is no difference between rainfall per year across 10 years.\nH1: There is a difference between rainfall per year across 10 years.\n\np3 &lt;- ggbetweenstats(\n  data = weather_data_detailed,\n  x = year, \n  y = monthly_rainfall,\n  type = \"np\",\n  pairwise.display = \"significant\",\n  conf.level = 0.95,\n  messages = FALSE,\n  title=\"Distribution of Rainfall across 10 years (2014 to 2023)\",\n  ylab = \"Rainfall volume (mm)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 2)\n) +\n  theme(text = element_text(size = 10), plot.title=element_text(size=10))\n\np3\n\n\n\n\n\n\n\n\nThe plot above shows that the p-value&lt; 0.05 and for which the null hypothesis will be rejected at alpha = 0.05. There is sufficient evidence to indicate that there is a difference in the rainfall across the years from 2014 to 2023."
  },
  {
    "objectID": "Analysis/CDA.html#temperature",
    "href": "Analysis/CDA.html#temperature",
    "title": "Confirmatory Data Analysis",
    "section": "4.1.2 Temperature",
    "text": "4.1.2 Temperature\n\n\nShow the code\ntemp_year &lt;- weather_data_detailed %&gt;%\n  group_by(year) %&gt;%\n  summarise(meantemp = median(mean_monthly_temperature),\n            maxtemp = max(max_monthly_temperature),\n            mintemp = min(min_monthly_temperature))\nDT::datatable(temp_year,class = \"compact\")\n\n\n\n\n\n\n\n\nShow the code\ntemp_month &lt;- weather_data_detailed %&gt;%\n  group_by(year,month) %&gt;%\n  summarise(meantemp = median(mean_monthly_temperature),\n            maxtemp = max(max_monthly_temperature),\n            mintemp = min(min_monthly_temperature))\nDT::datatable(temp_month,class = \"compact\")\n\n\n\n\n\n\nSaving it as a csv file:\n\n\nShow the code\nwrite_csv(temp_year, \"data/temp_year.csv\")\nwrite_csv(temp_month, \"data/temp_month.csv\")\n\n\n\n4.1.2.1 Overview of temperature over the years\n\ncombined_data &lt;- reshape2::melt(temp_year, id.vars = \"year\", variable.name = \"temperature_type\")\n\np4 &lt;- ggplot(combined_data, \n             aes(x = year, \n                 y = value, \n                 color = temperature_type)) +\n  geom_line() +\n  labs(title = \"Temperature Trends from 2014 to 2023\",\n       y = \"Temperature (°C)\",\n       x = \"Year\",\n       color=\"Temperature Type\") +\n  scale_x_continuous(breaks = seq(2014, 2023, 1)) +\n  scale_color_manual(values = c(\"turquoise\", \"violetred2\", \"steelblue2\"), \n                      labels = c(\"Mean\", \"Max\", \"Min\")) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n        \n\np4 &lt;- ggplotly(p4, tooltip=\"all\") %&gt;%\n  layout(legend = list(x = 0.6, y = 0.2))\n\np4\n\n\n\n\n\nBased on observation, it seems like mean, max and min temperature did not undergo significant changes over the years from 2014 to 2023.\n\n\n4.1.2.2 Distribution of Temperature (Mean, Max and Min) from 2014 to 2023\nLikewise, to determine whether the changes in the mean, maximum and minimum temperatures are significant, we will need to determine whether the temperature data within each year follows a normal or non-normal distribution. We visualise the distribution using ridgeline plots, using the code chunks below.\n\nDistribution of Mean TemperatureDistribution of Maximum TemperatureDistribution of Minimum Temperature\n\n\n\np5 &lt;- ggplot(weather_data_detailed, \n       aes(x = mean_monthly_temperature, \n           y = as.factor(year), \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1,\n                       option=\"turbo\")+\n  theme_ridges(font_size = 25)+\n  scale_color_discrete(name = \"Year\") +\n  labs(title=\"Distribution of Mean Temperature from 2014 to 2023\",\n       y=\"Year\",\n       x=\"Temperature (°C)\")\n\np5\n\n\n\n\n\n\n\n\n\n\n\np6 &lt;- ggplot(weather_data_detailed, \n       aes(x = max_monthly_temperature, \n           y = as.factor(year), \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1,\n                       option=\"turbo\")+\n  theme_ridges(font_size = 25)+\n  scale_color_discrete(name = \"Year\") +\n  labs(title=\"Distribution of Max Temperature from 2014 to 2023\",\n       y=\"Year\",\n       x=\"Temperature (°C)\")\n\np6\n\n\n\n\n\n\n\n\n\n\n\np7 &lt;- ggplot(weather_data_detailed, \n       aes(x = min_monthly_temperature, \n           y = as.factor(year), \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1,\n                       option=\"turbo\")+\n  theme_ridges(font_size = 25)+\n  scale_color_discrete(name = \"Year\") +\n  labs(title=\"Distribution of Min Temperature from 2014 to 2023\",\n       y=\"Year\",\n       x=\"Temperature (°C)\")\n\np7\n\n\n\n\n\n\n\n\nFrom the plots above, it seems like the distribution of mean, highest maximum and lowest minimum temperature within each year is not normal.\n\n\n\n\n\n4.1.2.3 Normality Test - Shapiro-Wilk Normality Test\n\nH0: Sample distribution is normal\nH1: Sample distribution is non-normal\n\nWe test whether the distribution of mean, highest max and lowest min temperature within the years are normal:\n\nMean TemperatureHighest Max TemperatureLowest Min Temperature\n\n\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2014))$mean_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2014))$mean_monthly_temperature\nW = 0.97207, p-value = 0.003767\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2015))$mean_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2015))$mean_monthly_temperature\nW = 0.97073, p-value = 0.002304\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2016))$mean_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2016))$mean_monthly_temperature\nW = 0.99053, p-value = 0.3977\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2017))$mean_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2017))$mean_monthly_temperature\nW = 0.98704, p-value = 0.1593\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2018))$mean_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2018))$mean_monthly_temperature\nW = 0.97207, p-value = 0.002946\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2019))$mean_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2019))$mean_monthly_temperature\nW = 0.98731, p-value = 0.1679\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2020))$mean_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2020))$mean_monthly_temperature\nW = 0.98896, p-value = 0.2595\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2021))$mean_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2021))$mean_monthly_temperature\nW = 0.95964, p-value = 0.0001652\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2022))$mean_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2022))$mean_monthly_temperature\nW = 0.98295, p-value = 0.05131\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2023))$mean_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2023))$mean_monthly_temperature\nW = 0.92823, p-value = 4.848e-07\n\n\nAs the p-values for 2016, 2017, 2019 and 2020 above are &gt; 0.05, we do not reject null hypothesis. There is insufficient evidence to indicate that the distribution of mean temperature within the years is non-normal.\n\n\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2014))$max_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2014))$max_monthly_temperature\nW = 0.96936, p-value = 0.001975\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2015))$max_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2015))$max_monthly_temperature\nW = 0.97661, p-value = 0.01007\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2016))$max_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2016))$max_monthly_temperature\nW = 0.97864, p-value = 0.01766\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2017))$max_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2017))$max_monthly_temperature\nW = 0.99384, p-value = 0.7559\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2018))$max_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2018))$max_monthly_temperature\nW = 0.97442, p-value = 0.005317\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2019))$max_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2019))$max_monthly_temperature\nW = 0.98503, p-value = 0.09055\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2020))$max_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2020))$max_monthly_temperature\nW = 0.98539, p-value = 0.1\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2021))$max_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2021))$max_monthly_temperature\nW = 0.96506, p-value = 0.0005522\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2022))$max_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2022))$max_monthly_temperature\nW = 0.99089, p-value = 0.4173\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2023))$max_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2023))$max_monthly_temperature\nW = 0.94233, p-value = 5.394e-06\n\n\nThe p-values for 2017, 2019, 2020 and 2022 are &gt; 0.05, , we do not reject null hypothesis. There is insufficient evidence to indicate that the distribution of max temperature within the years is non-normal.\n\n\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2014))$min_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2014))$min_monthly_temperature\nW = 0.98877, p-value = 0.2719\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2015))$min_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2015))$min_monthly_temperature\nW = 0.98348, p-value = 0.06236\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2016))$min_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2016))$min_monthly_temperature\nW = 0.97812, p-value = 0.01542\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2017))$min_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2017))$min_monthly_temperature\nW = 0.99338, p-value = 0.7014\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2018))$min_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2018))$min_monthly_temperature\nW = 0.98093, p-value = 0.02955\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2019))$min_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2019))$min_monthly_temperature\nW = 0.99246, p-value = 0.5871\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2020))$min_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2020))$min_monthly_temperature\nW = 0.98523, p-value = 0.09576\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2021))$min_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2021))$min_monthly_temperature\nW = 0.98108, p-value = 0.03081\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2022))$min_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2022))$min_monthly_temperature\nW = 0.98104, p-value = 0.0305\n\n\nShow the code\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2023))$min_monthly_temperature)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2023))$min_monthly_temperature\nW = 0.98459, p-value = 0.08024\n\n\nThe p-values for 2014, 2015, 2017, 2019, 2020.and 2023 are &gt; 0.05, , we do not reject null hypothesis. There is insufficient evidence to indicate that the distribution of min temperature within the years is non-normal.\n\n\n\n\n\n4.1.2.4 Equal Variance Assumption Test\n\nH0: Groups (different years) have equal variances\nH1: Groups (different years) have different variances\n\n\nMean TemperatureMax TemperatureMin Temperature\n\n\n\nleveneTest(mean_monthly_temperature ~ as.factor(year), data = weather_data_detailed)\n\nLevene's Test for Homogeneity of Variance (center = median)\n        Df F value    Pr(&gt;F)    \ngroup    9  13.274 &lt; 2.2e-16 ***\n      1538                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nleveneTest(max_monthly_temperature ~ as.factor(year), data = weather_data_detailed)\n\nLevene's Test for Homogeneity of Variance (center = median)\n        Df F value    Pr(&gt;F)    \ngroup    9  10.751 2.501e-16 ***\n      1538                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nleveneTest(min_monthly_temperature ~ as.factor(year), data = weather_data_detailed)\n\nLevene's Test for Homogeneity of Variance (center = median)\n        Df F value    Pr(&gt;F)    \ngroup    9  7.4888 8.757e-11 ***\n      1538                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nBased on the Levene Test, p-value of &lt; 0.05 were observed, we can reject null hypothesis and that there is sufficient evidence to indicate that the groups (different years) have different variances.\nTaking in results from the normality test and Levene test, non-parametric tests will be used for the CDA of mean, max and min temperatures.\n\n\n4.1.2.5 Statistical Test for Temperature across years\n\nMean Temperature by yearMax Temperature by yearMin Temperature by year\n\n\nThe hypothesis is as follows:\nH0: There is no difference between mean temperature of each year across 10 years.\nH1: There is a difference between mean temperature of each year across 10 years.\n\np8 &lt;- ggbetweenstats(\n  data = weather_data_detailed,\n  x = year, \n  y = mean_monthly_temperature,\n  type = \"np\",\n  pairwise.display = \"significant\",\n  conf.level = 0.95,\n  messages = FALSE,\n  title=\"Distribution of Mean Temperature of each year across 10 years (2014 to 2023)\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 5)\n) +\n  theme(text = element_text(size = 20),plot.title=element_text(size=20))\np8\n\n\n\n\n\n\n\n\nThe plot above shows that the p-value of the test &lt; 0.05, for which we reject the null hypothesis at alpha = 0.05. There is sufficient evidence to indicate that there is a difference in the mean temperature across the years from 2014 to 2023.\n\n\nThe hypothesis is as follows:\nH0: There is no difference between max temperature of each year across 10 years.\nH1: There is a difference between max temperature of each year across 10 years.\n\np9 &lt;- ggbetweenstats(\n  data = weather_data_detailed,\n  x = year, \n  y = max_monthly_temperature,\n  type = \"np\",\n  pairwise.display = \"signficant\",\n  conf.level = 0.95,\n  messages = FALSE,\n  title=\"Distribution of Max Temperature of each year across 10 years (2014 to 2023)\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 5)\n) +\n  theme(text = element_text(size = 20),plot.title=element_text(size=20))\np9\n\n\n\n\n\n\n\n\nThe plot above shows that the p-value of the test &lt; 0.05, for which we reject the null hypothesis at alpha = 0.05. There is sufficient evidence to indicate that there is a difference in the highest max temperature across the years from 2014 to 2023.\n\n\nThe hypothesis is as follows:\nH0: There is no difference between min temperature per year across 10 years.\nH1: There is a difference between min temperature per year across 10 years.\n\np10 &lt;- ggbetweenstats(\n  data = weather_data_detailed,\n  x = year, \n  y = min_monthly_temperature,\n  type = \"np\",\n  pairwise.display = \"significant\",\n  conf.level = 0.95,\n  messages = FALSE,\n  title=\"Distribution of Min Temperature of each year across 10 years (2014 to 2023)\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 5)\n) +\n  theme(text = element_text(size = 20),plot.title=element_text(size=20))\np10\n\n\n\n\n\n\n\n\nThe plot above shows that the p-value of the test &lt; 0.05, for which we reject the null hypothesis at alpha = 0.05. There is sufficient evidence to indicate that there is a difference in the min temperature across the years from 2014 to 2023."
  },
  {
    "objectID": "Analysis/CDA.html#overview-of-temperature-over-the-years",
    "href": "Analysis/CDA.html#overview-of-temperature-over-the-years",
    "title": "Prototype - Confirmatory Data Analysis",
    "section": "Overview of temperature over the years",
    "text": "Overview of temperature over the years\n\ncombined_data &lt;- reshape2::melt(temp_year, id.vars = \"year\", variable.name = \"temperature_type\")\n\np4 &lt;- ggplot(combined_data, \n             aes(x = year, \n                 y = value, \n                 color = temperature_type)) +\n  geom_line() +\n  labs(title = \"Temperature Trends from 2014 to 2023\",\n       y = \"Temperature (°C)\",\n       x = \"Year\",\n       color=\"Temperature Type\") +\n  scale_x_continuous(breaks = seq(2014, 2023, 1)) +\n  scale_color_manual(values = c(\"turquoise\", \"violetred2\", \"steelblue2\"), \n                      labels = c(\"Mean\", \"Max\", \"Min\")) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n        \n\np4 &lt;- ggplotly(p4, tooltip=\"all\") %&gt;%\n  layout(legend = list(x = 0.6, y = 0.2))\n\np4\n\n\n\n\n\nBased on observation, it seems like mean, max and min temperature did not undergo significant changes over the years from 2014 to 2023.\n\n4.1.2.2 Distribution of Temperature (Mean, Max and Min) from 2014 to 2023\nLikewise, to determine whether the changes in the mean, maximum and minimum temperatures are significant, we will need to determine whether the temperature data within each year follows a normal or non-normal distribution. We visualise the distribution using ridgeline plots, using the code chunks below.\n\nDistribution of Mean TemperatureDistribution of Maximum TemperatureDistribution of Minimum Temperature\n\n\n\np5 &lt;- ggplot(weather_data_detailed, \n       aes(x = mean_monthly_temperature, \n           y = as.factor(year), \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1,\n                       option=\"turbo\")+\n  theme_ridges(font_size = 25)+\n  scale_color_discrete(name = \"Year\") +\n  labs(title=\"Distribution of Mean Temperature from 2014 to 2023\",\n       y=\"Year\",\n       x=\"Temperature (°C)\")\n\np5\n\n\n\n\n\n\n\n\n\n\n\np6 &lt;- ggplot(weather_data_detailed, \n       aes(x = max_monthly_temperature, \n           y = as.factor(year), \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1,\n                       option=\"turbo\")+\n  theme_ridges(font_size = 25)+\n  scale_color_discrete(name = \"Year\") +\n  labs(title=\"Distribution of Max Temperature from 2014 to 2023\",\n       y=\"Year\",\n       x=\"Temperature (°C)\")\n\np6\n\n\n\n\n\n\n\n\n\n\n\np7 &lt;- ggplot(weather_data_detailed, \n       aes(x = min_monthly_temperature, \n           y = as.factor(year), \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1,\n                       option=\"turbo\")+\n  theme_ridges(font_size = 25)+\n  scale_color_discrete(name = \"Year\") +\n  labs(title=\"Distribution of Min Temperature from 2014 to 2023\",\n       y=\"Year\",\n       x=\"Temperature (°C)\")\n\np7\n\n\n\n\n\n\n\n\nFrom the plots above, it seems like the distribution of mean, highest maximum and lowest minimum temperature within each year is not normal.\n\n\n\n\n\n4.1.2.3 Normality Test - Shapiro-Wilk Normality Test\n\nH0: Sample distribution is normal\nH1: Sample distribution is non-normal\n\nWe test whether the distribution of mean, highest max and lowest min temperature within the years are normal:\n\nMean TemperatureHighest Max TemperatureLowest Min Temperature\n\n\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2014))$mean_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2014))$mean_monthly_temperature\nW = 0.97207, p-value = 0.003767\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2015))$mean_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2015))$mean_monthly_temperature\nW = 0.97073, p-value = 0.002304\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2016))$mean_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2016))$mean_monthly_temperature\nW = 0.99053, p-value = 0.3977\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2017))$mean_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2017))$mean_monthly_temperature\nW = 0.98704, p-value = 0.1593\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2018))$mean_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2018))$mean_monthly_temperature\nW = 0.97207, p-value = 0.002946\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2019))$mean_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2019))$mean_monthly_temperature\nW = 0.98731, p-value = 0.1679\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2020))$mean_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2020))$mean_monthly_temperature\nW = 0.98896, p-value = 0.2595\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2021))$mean_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2021))$mean_monthly_temperature\nW = 0.95964, p-value = 0.0001652\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2022))$mean_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2022))$mean_monthly_temperature\nW = 0.98295, p-value = 0.05131\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2023))$mean_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2023))$mean_monthly_temperature\nW = 0.92823, p-value = 4.848e-07\n\n\nAs the p-values for 2016, 2017, 2019 and 2020 above are &gt; 0.05, we do not reject null hypothesis. There is insufficient evidence to indicate that the distribution of mean temperature within the years is non-normal.\n\n\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2014))$max_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2014))$max_monthly_temperature\nW = 0.96936, p-value = 0.001975\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2015))$max_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2015))$max_monthly_temperature\nW = 0.97661, p-value = 0.01007\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2016))$max_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2016))$max_monthly_temperature\nW = 0.97864, p-value = 0.01766\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2017))$max_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2017))$max_monthly_temperature\nW = 0.99384, p-value = 0.7559\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2018))$max_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2018))$max_monthly_temperature\nW = 0.97442, p-value = 0.005317\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2019))$max_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2019))$max_monthly_temperature\nW = 0.98503, p-value = 0.09055\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2020))$max_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2020))$max_monthly_temperature\nW = 0.98539, p-value = 0.1\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2021))$max_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2021))$max_monthly_temperature\nW = 0.96506, p-value = 0.0005522\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2022))$max_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2022))$max_monthly_temperature\nW = 0.99089, p-value = 0.4173\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2023))$max_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2023))$max_monthly_temperature\nW = 0.94233, p-value = 5.394e-06\n\n\nThe p-values for 2017, 2019, 2020 and 2022 are &gt; 0.05, , we do not reject null hypothesis. There is insufficient evidence to indicate that the distribution of max temperature within the years is non-normal.\n\n\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2014))$min_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2014))$min_monthly_temperature\nW = 0.98877, p-value = 0.2719\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2015))$min_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2015))$min_monthly_temperature\nW = 0.98348, p-value = 0.06236\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2016))$min_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2016))$min_monthly_temperature\nW = 0.97812, p-value = 0.01542\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2017))$min_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2017))$min_monthly_temperature\nW = 0.99338, p-value = 0.7014\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2018))$min_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2018))$min_monthly_temperature\nW = 0.98093, p-value = 0.02955\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2019))$min_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2019))$min_monthly_temperature\nW = 0.99246, p-value = 0.5871\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2020))$min_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2020))$min_monthly_temperature\nW = 0.98523, p-value = 0.09576\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2021))$min_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2021))$min_monthly_temperature\nW = 0.98108, p-value = 0.03081\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2022))$min_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2022))$min_monthly_temperature\nW = 0.98104, p-value = 0.0305\n\nshapiro.test((weather_data_detailed %&gt;%\n  filter(year == 2023))$min_monthly_temperature)\n\n\n    Shapiro-Wilk normality test\n\ndata:  (weather_data_detailed %&gt;% filter(year == 2023))$min_monthly_temperature\nW = 0.98459, p-value = 0.08024\n\n\nThe p-values for 2014, 2015, 2017, 2019, 2020.and 2023 are &gt; 0.05, , we do not reject null hypothesis. There is insufficient evidence to indicate that the distribution of min temperature within the years is non-normal.\n\n\n\n\n\n4.1.2.4 Equal Variance Assumption Test\n\nH0: Groups (different years) have equal variances\nH1: Groups (different years) have different variances\n\n\nMean TemperatureMax TemperatureMin Temperature\n\n\n\nleveneTest(mean_monthly_temperature ~ as.factor(year), data = weather_data_detailed)\n\nLevene's Test for Homogeneity of Variance (center = median)\n        Df F value    Pr(&gt;F)    \ngroup    9  13.274 &lt; 2.2e-16 ***\n      1538                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nleveneTest(max_monthly_temperature ~ as.factor(year), data = weather_data_detailed)\n\nLevene's Test for Homogeneity of Variance (center = median)\n        Df F value    Pr(&gt;F)    \ngroup    9  10.751 2.501e-16 ***\n      1538                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nleveneTest(min_monthly_temperature ~ as.factor(year), data = weather_data_detailed)\n\nLevene's Test for Homogeneity of Variance (center = median)\n        Df F value    Pr(&gt;F)    \ngroup    9  7.4888 8.757e-11 ***\n      1538                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nBased on the Levene Test, p-value of &lt; 0.05 were observed, we can reject null hypothesis and that there is sufficient evidence to indicate that the groups (different years) have different variances.\nTaking in results from the normality test and Levene test, non-parametric tests will be used for the CDA of mean, max and min temperatures.\n\nMean Temperature by yearMax Temperature by yearMin Temperature by year\n\n\nThe hypothesis is as follows:\nH0: There is no difference between mean temperature of each year across 10 years.\nH1: There is a difference between mean temperature of each year across 10 years.\n\np8 &lt;- ggbetweenstats(\n  data = weather_data_detailed,\n  x = year, \n  y = mean_monthly_temperature,\n  type = \"np\",\n  pairwise.display = \"significant\",\n  conf.level = 0.95,\n  messages = FALSE,\n  title=\"Distribution of Mean Temperature of each year across 10 years (2014 to 2023)\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 5)\n) +\n  theme(text = element_text(size = 20),plot.title=element_text(size=20))\np8\n\n\n\n\n\n\n\n\nThe plot above shows that the p-value of the test &lt; 0.05, for which we reject the null hypothesis at alpha = 0.05. There is sufficient evidence to indicate that there is a difference in the mean temperature across the years from 2014 to 2023.\n\n\nThe hypothesis is as follows:\nH0: There is no difference between max temperature of each year across 10 years.\nH1: There is a difference between max temperature of each year across 10 years.\n\np9 &lt;- ggbetweenstats(\n  data = weather_data_detailed,\n  x = year, \n  y = max_monthly_temperature,\n  type = \"np\",\n  pairwise.display = \"signficant\",\n  conf.level = 0.95,\n  messages = FALSE,\n  title=\"Distribution of Max Temperature of each year across 10 years (2014 to 2023)\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 5)\n) +\n  theme(text = element_text(size = 20),plot.title=element_text(size=20))\np9\n\n\n\n\n\n\n\n\nThe plot above shows that the p-value of the test &lt; 0.05, for which we reject the null hypothesis at alpha = 0.05. There is sufficient evidence to indicate that there is a difference in the highest max temperature across the years from 2014 to 2023.\n\n\nThe hypothesis is as follows:\nH0: There is no difference between min temperature per year across 10 years.\nH1: There is a difference between min temperature per year across 10 years.\n\np10 &lt;- ggbetweenstats(\n  data = weather_data_detailed,\n  x = year, \n  y = min_monthly_temperature,\n  type = \"np\",\n  pairwise.display = \"significant\",\n  conf.level = 0.95,\n  messages = FALSE,\n  title=\"Distribution of Min Temperature of each year across 10 years (2014 to 2023)\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 5)\n) +\n  theme(text = element_text(size = 20),plot.title=element_text(size=20))\np10\n\n\n\n\n\n\n\n\nThe plot above shows that the p-value of the test &lt; 0.05, for which we reject the null hypothesis at alpha = 0.05. There is sufficient evidence to indicate that there is a difference in the min temperature across the years from 2014 to 2023."
  },
  {
    "objectID": "Analysis/CDA.html#cda-2---are-there-really-certain-months-drier-or-wetter-hotter-or-cooler",
    "href": "Analysis/CDA.html#cda-2---are-there-really-certain-months-drier-or-wetter-hotter-or-cooler",
    "title": "Confirmatory Data Analysis",
    "section": "4.2 CDA #2 - Are there really certain months “drier” or “wetter”/ “hotter” or “cooler”?",
    "text": "4.2 CDA #2 - Are there really certain months “drier” or “wetter”/ “hotter” or “cooler”?"
  },
  {
    "objectID": "Analysis/CDA.html#rainfall-1",
    "href": "Analysis/CDA.html#rainfall-1",
    "title": "Confirmatory Data Analysis",
    "section": "4.2.1 Rainfall",
    "text": "4.2.1 Rainfall\n\n4.2.1.1 Overview of Rainfall across different months\n\np11 &lt;- ggplot(rainfall_data_month,\n             aes(y=monthly_rainfall,\n                 x = as.factor(month),\n                 fill = as.factor(year))) +\n  geom_bar(stat = \"identity\")+\n  facet_wrap(~year, scales = \"free_x\") +\n  labs(title=\"Monthly rainfall each year from 2014 to 2023\",\n       y = \"Rainfall volume (mm)\",\n       x = \"Month\") +\n  theme_minimal()+\n  theme(panel.spacing.y = unit(10, \"lines\"))+\n  scale_fill_discrete(name = \"Year\")\n\nggplotly(p11)\n\n\n\n\n\nFrom the above plots, in 2014 and 2015, it can be seen that rainfall volume is higher in the later months of the year however this is less obvious after 2016. Notably, in 2021, a higher volume of rainfall was seen in January as compared to December.\nA cycle plot can also be used to visualise the monthly trend of rainfall over the years from 2014 to 2023:\n\n\nCycle plot\n\nhline.data &lt;- rainfall_data_month %&gt;%\n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(monthly_rainfall))\n\n\np12 &lt;- ggplot() +\n  geom_line(data = rainfall_data_month,\n            aes(x = year,\n                y = monthly_rainfall,\n                group = month,\n                colour = as.factor(month)))+\n              geom_hline(aes(yintercept=avgvalue),\n                         data=hline.data,\n                         linetype=6,\n                         colour=\"red\",\n                         size=0.5)+\n              facet_wrap(~month,scales = \"free_x\")+\n              labs(title = \"Rainfall by month from 2014 to 2023\",\n                   colour = \"Month\") +\n  xlab(\"Year\")+\n  ylab(\"Rainfall volume (mm)\")+\n              theme_tufte(base_family = \"Helvetica\")+ theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 1))\n\np12\n\n\n\n\n\n\n\n\nTo determine if there are certain months which are drier or wetter, we need to carry out statistical test to determine if there is a significant difference in the rainfall volume across months.\nAs data is aggregated at the monthly_rainfall level in the starting dataset weather_data, we will carry out the test below using non-parametric test however in the Shiny App, users will be given the flexibility to change the test type to parametric, robust or even bayes.\n\n\n4.2.1.2 Statistical Test for Rainfall across months\nThe hypothesis is as follows:\nH0: There is no difference between rainfall across months.\nH1: There is a difference between rainfall across months.\n\np13 &lt;- ggbetweenstats(\n  data = weather_data_detailed,\n  x = month, \n  y = monthly_rainfall,\n  type = \"np\",\n  pairwise.display = \"significant\",\n  messages = FALSE,\n  title=\"Distribution of Rainfall across months (2014 to 2023)\",\n  ylab = \"Rainfall volume (mm)\",\n  xlab = \"Month\",\n  ggsignif.args = list(textsize = 5)\n) +\n  theme(text = element_text(size = 20), plot.title=element_text(size=20))\np13\n\n\n\n\n\n\n\n\nThe p-value of the test is &lt; 0.05, for which the null hypothesis will be rejected at alpha = 0.05. There is sufficient evidence to indicate that there is a difference in the rainfall across the months."
  },
  {
    "objectID": "Analysis/CDA.html#rainfall-across-months",
    "href": "Analysis/CDA.html#rainfall-across-months",
    "title": "Prototype - Confirmatory Data Analysis",
    "section": "Rainfall across months",
    "text": "Rainfall across months\nThe hypothesis is as follows:\nH0: There is no difference between rainfall across months.\nH1: There is a difference between rainfall across months.\n\np13 &lt;- ggbetweenstats(\n  data = weather_data_detailed,\n  x = month, \n  y = monthly_rainfall,\n  type = \"np\",\n  pairwise.display = \"significant\",\n  messages = FALSE,\n  title=\"Distribution of Rainfall across months (2014 to 2023)\",\n  ylab = \"Rainfall volume (mm)\",\n  xlab = \"Month\",\n  ggsignif.args = list(textsize = 5)\n) +\n  theme(text = element_text(size = 20), plot.title=element_text(size=20))\np13\n\n\n\n\n\n\n\n\nThe p-value of the test is &lt; 0.05, for which the null hypothesis will be rejected at alpha = 0.05. There is sufficient evidence to indicate that there is a difference in the rainfall across the months."
  },
  {
    "objectID": "Analysis/CDA.html#temperature-1",
    "href": "Analysis/CDA.html#temperature-1",
    "title": "Confirmatory Data Analysis",
    "section": "4.2.2 Temperature",
    "text": "4.2.2 Temperature\n\n4.2.2.1 Overview of Temperature across different months\n\nMean TemperatureHighest Max TemperatureLowest Minimum Temperature\n\n\n\np14 &lt;- ggplot(temp_month,\n       aes(y = meantemp,\n           x = month,\n           colour = as.factor(year))) +\n  geom_line()+\n  facet_wrap(~ year,scales = \"free_x\") +\n  labs(title=\"Mean temperature from 2014 to 2023\",\n       y = \"Temperature (°C)\",\n       x = \"Year\")+\n  scale_x_continuous(breaks = seq(1,12,1))+\n  scale_color_discrete(name = \"Year\")+\n  theme_minimal() +\n  theme(panel.spacing.y = unit(5,\"lines\"),\n        axis.text.x = element_text(angle = 90))\n\nggplotly(p14)\n\n\n\n\n\n\n\n\np15 &lt;- ggplot(temp_month,\n       aes(y = maxtemp,\n           x = month,\n           colour = as.factor(year))) +\n  geom_line()+\n  facet_wrap(~year,scales = \"free_x\") +\n  labs(title=\"Max temperature from 2014 to 2023\",\n       y = \"Temperature (°C)\",\n       x = \"Year\") +\n  scale_x_continuous(breaks = 1:12, labels = 1:12)+\n  scale_color_discrete(name = \"Year\") +\n  theme_minimal() +\n  theme(panel.spacing.y = unit(5,\"lines\"))\n\nggplotly(p15)\n\n\n\n\n\n\n\n\np16 &lt;- ggplot(temp_month,\n       aes(y = mintemp,\n           x = month,\n           colour = as.factor(year))) +\n  geom_line()+\n  facet_wrap(~year,scales = \"free_x\") +\n  labs(title=\"Min temperature from 2014 to 2023\",\n       y = \"Temperature (°C)\",\n       x = \"Year\") +\n  scale_x_continuous(breaks = 1:12, labels = 1:12)+\n  scale_color_discrete(name = \"Year\") +\n  theme_minimal() +\n  theme(panel.spacing.y = unit(5,\"lines\"))\n\nggplotly(p16)"
  },
  {
    "objectID": "Analysis/CDA.html#combined-view",
    "href": "Analysis/CDA.html#combined-view",
    "title": "Confirmatory Data Analysis",
    "section": "Combined view",
    "text": "Combined view\n\ncombined_data2 &lt;- reshape2::melt(temp_month, id.vars = c(\"year\", \"month\"), variable.name = \"temperature_type\")\n\np17 &lt;- ggplot(combined_data2, aes(x = month, \n                                 y = value,\n                                 color = temperature_type)) +\n  geom_line() +\n  facet_wrap(~ year,scales = \"free_x\")+\n  labs(title = \"Detailed Temperature Trends from 2014 to 2023\",\n       y = \"Temperature (°C)\",\n       x = \"Month\",\n       color = \"Temperature Type\") +\n  scale_x_continuous(breaks = seq(1,12, 1)) +\n  scale_color_manual(values = c(\"turquoise\", \"violetred2\", \"steelblue2\"), \n                      labels = c(\"Mean\", \"Max\", \"Min\")) +\n  theme_minimal() +\n  theme(panel.border = element_rect(color = \"lightgrey\",linetype = \"dashed\", fill = NA, size = 1))\n\np17 &lt;- ggplotly(p17, tooltip = \"all\")%&gt;%\n  layout(legend = list(x = 0.6, y = -0.1))\n\np17\n\n\n\n\n\nA cycle plot can be used to visualise the monthly trend of temperature over the years from 2014 to 2023:\n\nCycle plot\n\nhline_mean_temp.data &lt;- temp_month %&gt;%\n  group_by(year) %&gt;%\n  summarise(avgvalue = mean(meantemp))\n\nhline_max_temp.data &lt;- temp_month %&gt;%\n  group_by(year) %&gt;%\n  summarise(avgvalue = mean(maxtemp))\n\nhline_min_temp.data &lt;- temp_month %&gt;%\n  group_by(year) %&gt;%\n  summarise(avgvalue = mean(mintemp))\n\n\np18 &lt;- ggplot() +\n  geom_line(data = temp_month,\n            aes(x = as.factor(month),\n                y = meantemp,\n                group = year,\n                colour = as.factor(year)))+\n              geom_hline(aes(yintercept=avgvalue),\n                         data=hline_mean_temp.data,\n                         linetype=6,\n                         colour=\"red\",\n                         size=0.5)+\n              facet_wrap(~year,scales = \"free_x\")+\n              labs(axis.text.x=element_blank(),\n                   title = \"Mean temperature by year from 2014 to 2023\")+\n              xlab(\"\")+\n              ylab(\"Degrees (°C)\")+\n              scale_color_discrete(name = \"Year\")+\n              theme_tufte(base_family = \"Helvetica\")\n\np18\n\n\n\n\n\n\n\n\n\np19 &lt;- ggplot() +\n  geom_line(data = temp_month,\n            aes(x = as.factor(month),\n                y = maxtemp,\n                group = year,\n                colour = as.factor(year)))+\n              geom_hline(aes(yintercept=avgvalue),\n                         data=hline_max_temp.data,\n                         linetype=6,\n                         colour=\"red\",\n                         size=0.5)+\n              facet_wrap(~year,scales = \"free_x\")+\n              labs(axis.text.x=element_blank(),\n                   title = \"Max temperature by year from 2014 to 2023\")+\n              xlab(\"\")+\n              ylab(\"Degrees (°C)\")+\n              scale_color_discrete(name = \"Year\")+\n              theme_tufte(base_family = \"Helvetica\")\n\np19\n\n\n\n\n\n\n\n\n\np20 &lt;- ggplot() +\n  geom_line(data = temp_month,\n            aes(x = as.factor(month),\n                y = mintemp,\n                group = year,\n                colour = as.factor(year)))+\n              geom_hline(aes(yintercept=avgvalue),\n                         data=hline_min_temp.data,\n                         linetype=6,\n                         colour=\"red\",\n                         size=0.5)+\n              facet_wrap(~year,scales = \"free_x\")+\n              labs(axis.text.x=element_blank(),\n                   title = \"Min temperature by year from 2014 to 2023\")+\n              xlab(\"\")+\n              ylab(\"Degrees (°C)\")+\n              scale_color_discrete(name = \"Year\")+\n              theme_tufte(base_family = \"Helvetica\")\n\np20\n\n\n\n\n\n\n\n\nAs data is aggregated at the mean_monthly_temperature, max_monthly_temperature and min_monthly_temperature level in the starting dataset weather_data, we will carry out the test below using non-parametric test however in the Shiny App, users will be given the flexibility to change the test type to parametric, robust or even bayes.\n\n\n4.2.2.2 Statistical Test for Temperature across months\n\nMean temperature by monthMax Temperature by monthMin Temperature by month\n\n\nThe hypothesis is as follows:\nH0: There is no difference between mean temperature across months.\nH1: There is a difference between mean temperature across months.\n\np21 &lt;- ggbetweenstats(data = weather_data_detailed,\n                      x = month,\n                      y = mean_monthly_temperature,\n                      type = \"np\",\n                      pairwise.display = \"signficant\",\n                      conf.level = 0.95,\n                      messages = FALSE,\n                      title = \"Distribution of Mean Temperature by month (2014 to 2023)\",\n                      ylab = \"Temperature (°C)\",\n                      xlab = \"Month\",\n                      ggsignif.args = list(textsize =5)) +\n  theme(text = element_text(size = 20),plot.title = element_text(size = 20))\np21\n\n\n\n\n\n\n\n\nThe p-value was found to be &lt; 0.05, for which the null hypothesis will be rejected at alpha = 0.05. There is sufficient evidence to indicate that there is a difference in the mean temperature across the months.\n\n\nThe hypothesis is as follows:\nH0: There is no difference between max temperature across months.\nH1: There is a difference between max temperature across months.\n\np22 &lt;- ggbetweenstats(data = weather_data_detailed,\n                      x = month,\n                      y = max_monthly_temperature,\n                      type = \"np\",\n                      pairwise.display = \"signficant\",\n                      conf.level = 0.95,\n                      messages = FALSE,\n                      title = \"Distribution of Max Temperature by month (2014 to 2023)\",\n                      ylab = \"Temperature (°C)\",\n                      xlab = \"Month\",\n                      ggsignif.args = list(textsize =5)) +\n  theme(text = element_text(size = 20),plot.title = element_text(size = 20))\np22\n\n\n\n\n\n\n\n\nThe plot above shows p-value &lt; 0.05, for which the null hypothesis will be rejected at alpha = 0.05. There is sufficient evidence to indicate that there is a difference in the max temperature across the months.\n\n\nThe hypothesis is as follows:\nH0: There is no difference between min temperature across months.\nH1: There is a difference between min temperature across months.\n\np23 &lt;- ggbetweenstats(data = weather_data_detailed,\n                      x = month,\n                      y = min_monthly_temperature,\n                      type = \"np\",\n                      pairwise.display = \"significant\",\n                      conf.level = 0.95,\n                      messages = FALSE,\n                      title = \"Distribution of Min Temperature by month (2014 to 2023)\",\n                      ylab = \"Temperature (°C)\",\n                      xlab = \"Month\",\n                      ggsignif.args = list(textsize =5)) +\n  theme(text = element_text(size = 20),plot.title = element_text(size = 20))\np23\n\n\n\n\n\n\n\n\nThe plot above shows that the p-value of the test is&lt; 0.05, for which we reject the null hypothesis at alpha = 0.05. There is sufficient evidence to indicate that there is a difference in the min temperature across the months from 2014 to 2023."
  },
  {
    "objectID": "Analysis/CDA.html#cycle-plot-1",
    "href": "Analysis/CDA.html#cycle-plot-1",
    "title": "Prototype - Confirmatory Data Analysis",
    "section": "Cycle plot",
    "text": "Cycle plot\n\nhline_mean_temp.data &lt;- temp_month %&gt;%\n  group_by(year) %&gt;%\n  summarise(avgvalue = mean(meantemp))\n\nhline_max_temp.data &lt;- temp_month %&gt;%\n  group_by(year) %&gt;%\n  summarise(avgvalue = mean(maxtemp))\n\nhline_min_temp.data &lt;- temp_month %&gt;%\n  group_by(year) %&gt;%\n  summarise(avgvalue = mean(mintemp))\n\n\np18 &lt;- ggplot() +\n  geom_line(data = temp_month,\n            aes(x = as.factor(month),\n                y = meantemp,\n                group = year,\n                colour = as.factor(year)))+\n              geom_hline(aes(yintercept=avgvalue),\n                         data=hline_mean_temp.data,\n                         linetype=6,\n                         colour=\"red\",\n                         size=0.5)+\n              facet_wrap(~year,scales = \"free_x\")+\n              labs(axis.text.x=element_blank(),\n                   title = \"Mean temperature by year from 2014 to 2023\")+\n              xlab(\"\")+\n              ylab(\"Degrees (°C)\")+\n              scale_color_discrete(name = \"Year\")+\n              theme_tufte(base_family = \"Helvetica\")\n\np18\n\n\n\n\n\n\n\n\n\np19 &lt;- ggplot() +\n  geom_line(data = temp_month,\n            aes(x = as.factor(month),\n                y = maxtemp,\n                group = year,\n                colour = as.factor(year)))+\n              geom_hline(aes(yintercept=avgvalue),\n                         data=hline_max_temp.data,\n                         linetype=6,\n                         colour=\"red\",\n                         size=0.5)+\n              facet_wrap(~year,scales = \"free_x\")+\n              labs(axis.text.x=element_blank(),\n                   title = \"Max temperature by year from 2014 to 2023\")+\n              xlab(\"\")+\n              ylab(\"Degrees (°C)\")+\n              scale_color_discrete(name = \"Year\")+\n              theme_tufte(base_family = \"Helvetica\")\n\np19\n\n\n\n\n\n\n\n\n\np20 &lt;- ggplot() +\n  geom_line(data = temp_month,\n            aes(x = as.factor(month),\n                y = mintemp,\n                group = year,\n                colour = as.factor(year)))+\n              geom_hline(aes(yintercept=avgvalue),\n                         data=hline_min_temp.data,\n                         linetype=6,\n                         colour=\"red\",\n                         size=0.5)+\n              facet_wrap(~year,scales = \"free_x\")+\n              labs(axis.text.x=element_blank(),\n                   title = \"Min temperature by year from 2014 to 2023\")+\n              xlab(\"\")+\n              ylab(\"Degrees (°C)\")+\n              scale_color_discrete(name = \"Year\")+\n              theme_tufte(base_family = \"Helvetica\")\n\np20\n\n\n\n\n\n\n\n\nAs data is aggregated at the mean_monthly_temperature, max_monthly_temperature and min_monthly_temperature level in the starting dataset weather_data, we will carry out the test below using non-parametric test however in the Shiny App, users will be given the flexibility to change the test type to parametric, robust or even bayes.\n\nMean temperature by monthMax Temperature by monthMin Temperature by month\n\n\nThe hypothesis is as follows:\nH0: There is no difference between mean temperature across months.\nH1: There is a difference between mean temperature across months.\n\np21 &lt;- ggbetweenstats(data = weather_data_detailed,\n                      x = month,\n                      y = mean_monthly_temperature,\n                      type = \"np\",\n                      pairwise.display = \"signficant\",\n                      conf.level = 0.95,\n                      messages = FALSE,\n                      title = \"Distribution of Mean Temperature by month (2014 to 2023)\",\n                      ylab = \"Temperature (°C)\",\n                      xlab = \"Month\",\n                      ggsignif.args = list(textsize =5)) +\n  theme(text = element_text(size = 20),plot.title = element_text(size = 20))\np21\n\n\n\n\n\n\n\n\nThe p-value was found to be &lt; 0.05, for which the null hypothesis will be rejected at alpha = 0.05. There is sufficient evidence to indicate that there is a difference in the mean temperature across the months.\n\n\nThe hypothesis is as follows:\nH0: There is no difference between max temperature across months.\nH1: There is a difference between max temperature across months.\n\np22 &lt;- ggbetweenstats(data = weather_data_detailed,\n                      x = month,\n                      y = max_monthly_temperature,\n                      type = \"np\",\n                      pairwise.display = \"signficant\",\n                      conf.level = 0.95,\n                      messages = FALSE,\n                      title = \"Distribution of Max Temperature by month (2014 to 2023)\",\n                      ylab = \"Temperature (°C)\",\n                      xlab = \"Month\",\n                      ggsignif.args = list(textsize =5)) +\n  theme(text = element_text(size = 20),plot.title = element_text(size = 20))\np22\n\n\n\n\n\n\n\n\nThe plot above shows p-value &lt; 0.05, for which the null hypothesis will be rejected at alpha = 0.05. There is sufficient evidence to indicate that there is a difference in the max temperature across the months.\n\n\nThe hypothesis is as follows:\nH0: There is no difference between min temperature across months.\nH1: There is a difference between min temperature across months.\n\np23 &lt;- ggbetweenstats(data = weather_data_detailed,\n                      x = month,\n                      y = min_monthly_temperature,\n                      type = \"np\",\n                      pairwise.display = \"significant\",\n                      conf.level = 0.95,\n                      messages = FALSE,\n                      title = \"Distribution of Min Temperature by month (2014 to 2023)\",\n                      ylab = \"Temperature (°C)\",\n                      xlab = \"Month\",\n                      ggsignif.args = list(textsize =5)) +\n  theme(text = element_text(size = 20),plot.title = element_text(size = 20))\np23\n\n\n\n\n\n\n\n\nThe plot above shows that the p-value of the test is&lt; 0.05, for which we reject the null hypothesis at alpha = 0.05. There is sufficient evidence to indicate that there is a difference in the min temperature across the months from 2014 to 2023."
  },
  {
    "objectID": "Analysis/CDA.html#cda-3---are-there-certain-locations-drier-or-wetter-hotter-or-cooler",
    "href": "Analysis/CDA.html#cda-3---are-there-certain-locations-drier-or-wetter-hotter-or-cooler",
    "title": "Confirmatory Data Analysis",
    "section": "4.3 CDA #3 - Are there certain locations “drier” or “wetter”/ “hotter” or “cooler”?",
    "text": "4.3 CDA #3 - Are there certain locations “drier” or “wetter”/ “hotter” or “cooler”?"
  },
  {
    "objectID": "Analysis/CDA.html#rainfall-2",
    "href": "Analysis/CDA.html#rainfall-2",
    "title": "Confirmatory Data Analysis",
    "section": "4.3.1 Rainfall",
    "text": "4.3.1 Rainfall\n\n\nShow the code\nrainfall_data_stn &lt;- weather_data_detailed %&gt;%   \n  group_by(station,year) %&gt;%   \n  summarise(yearly_rainfall = sum(monthly_rainfall))  \nDT::datatable(rainfall_data_stn,class = \"compact\")\n\n\n\n\n\n\nSaving it as a csv file:\n\n\nShow the code\nwrite_csv(rainfall_data_stn, \"data/rainfall_data_stn.csv\")\n\n\n\n4.3.1.1 Overview of Rainfall across different weather stations\n\np24 &lt;- ggplot(rainfall_data_stn,\n             aes(y=yearly_rainfall,\n                 x = year,\n                 group = station,\n                 color = station)) +\n  geom_line() +\n  facet_wrap(~station,scales = \"free_x\") +\n  labs(title=\"Yearly rainfall across weather stations from 2014 to 2023\",\n       y = \"Rainfall volume (mm)\",\n       x = \"Year\") +\n  theme_minimal() +\n  theme(axis.text.x=element_text(angle=90,hjust=1),panel.spacing.y = unit(5,\"lines\") )\n\nggplotly(p24)\n\n\n\n\n\n\n\n4.3.1.2 Statistical Test for Rainfall across weather stations\nThe hypothesis is as follows:\nH0: There is no difference between rainfall across weather stations.\nH1: There is a difference between rainfall across weather stations.\n\np25 &lt;- ggbetweenstats(\n  data = weather_data_detailed,\n  x = station, \n  y = monthly_rainfall,\n  type = \"np\",\n  pairwise.display = \"significant\",\n  conf.level = 0.95,\n  messages = FALSE,\n  title=\"Distribution of Rainfall by Station\",\n  ylab = \"Rainfall volume (mm)\",\n  xlab = \"Station\",\n  ggsignif.args = list(textsize = 3)\n) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1),\n        plot.title = element_text(size = 15),\n        text = element_text(size = 15))\np25\n\n\n\n\n\n\n\n\nThe plot above shows that the p-value of the test is &lt; 0.05, for which we reject the null hypothesis at alpha = 0.05. There is sufficient evidence to indicate that there is differences in rainfall across stations."
  },
  {
    "objectID": "Analysis/CDA.html#rainfall-across-weather-stations",
    "href": "Analysis/CDA.html#rainfall-across-weather-stations",
    "title": "Prototype - Confirmatory Data Analysis",
    "section": "Rainfall across Weather Stations",
    "text": "Rainfall across Weather Stations\nThe hypothesis is as follows:\nH0: There is no difference between rainfall across weather stations.\nH1: There is a difference between rainfall across weather stations.\n\np25 &lt;- ggbetweenstats(\n  data = weather_data_detailed,\n  x = station, \n  y = monthly_rainfall,\n  type = \"np\",\n  pairwise.display = \"significant\",\n  conf.level = 0.95,\n  messages = FALSE,\n  title=\"Distribution of Rainfall by Station\",\n  ylab = \"Rainfall volume (mm)\",\n  xlab = \"Station\",\n  ggsignif.args = list(textsize = 3)\n) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1),\n        plot.title = element_text(size = 15),\n        text = element_text(size = 15))\np25\n\n\n\n\n\n\n\n\nThe plot above shows that the p-value of the test is &lt; 0.05, for which we reject the null hypothesis at alpha = 0.05. There is sufficient evidence to indicate that there is differences in rainfall across stations.\n\n4.3.1.2 Temperature across different weather stations\n\ntemp_stn &lt;- weather_data_detailed %&gt;%\n  group_by(station,year) %&gt;%\n  summarise(meantemp = median(mean_monthly_temperature),\n            maxtemp = max(max_monthly_temperature),\n            mintemp = min(min_monthly_temperature))\n\n\nDT::datatable(temp_stn,class = \"compact\")\n\n\n\n\n\nSaving it as a csv file:\n\nwrite_csv(temp_stn, \"data/temp_stn.csv\")\n\n\nMean TemperatureMaximum TemperatureMinimum Temperature\n\n\n\np26 &lt;- ggplot(temp_stn,\n             aes(y = meantemp,\n                 x = year,\n                 group = station,\n                 color = station)) +\n  geom_line() +\n  facet_wrap(~station,scales = \"free_x\") +\n  labs(title=\"Mean temperature across weather stations from 2014 to 2023\",\n       y = \"Temperature (°C)\",\n       x = \"Year\") +\n  theme_minimal() +\n  theme(axis.text.x=element_text(angle=90,hjust=1))\n\np26 &lt;- ggplotly(p26, tooltip=\"all\",width = 800,height = 600) %&gt;% \n  layout(width = 800, height = 600)\n\np26\n\n\n\n\n\n\n\n\np27 &lt;- ggplot(temp_stn,\n             aes(y = maxtemp,\n                 x = year,\n                 group = station,\n                 color = station)) +\n  geom_line() +\n  facet_wrap(~station,scales = \"free_x\") +\n  labs(title=\"Max temperature across weather stations from 2014 to 2023\",\n       y = \"Temperature (°C)\",\n       x = \"Year\") +\n  theme_minimal() +\n  theme(axis.text.x=element_text(angle=90,hjust=1))\n\np27 &lt;- ggplotly(p27, tooltip=\"all\",width = 800,height = 600) %&gt;% \n  layout(width = 800, height = 600)\n\np27\n\n\n\n\n\nBased on observation, it seems like max temperature for each weather station did not undergo significant changes over the years from 2014 to 2023.\n\n\n\np28 &lt;- ggplot(temp_stn,\n             aes(y = mintemp,\n                 x = year,\n                 group = station,\n                 color = station)) +\n  geom_line() +\n  facet_wrap(~station,scales = \"free_x\") +\n  labs(title=\"Min temperature across weather stations from 2014 to 2023\",\n       y = \"Temperature (°C)\",\n       x = \"Year\") +\n  theme_minimal() +\n  theme(axis.text.x=element_text(angle=90,hjust=1))\n\np28 &lt;- ggplotly(p28, tooltip=\"all\",width = 800,height = 600) %&gt;% \n  layout(width = 800, height = 600)\n\np28\n\n\n\n\n\n\n\n\n\ncombined_data3 &lt;- reshape2::melt(temp_stn, id.vars = c(\"station\", \"year\"), variable.name = \"temperature_type\")\n\np29 &lt;- ggplot(combined_data3, aes(x = year, \n                                 y = value,\n                                 color = temperature_type)) +\n  geom_line() +\n  facet_wrap(~ station,scales = \"free_x\")+\n  labs(title = \"Detailed Temperature Trends across stations from 2014 to 2023\",\n       y = \"Temperature (°C)\",\n       x = \"Year\",\n       color = \"Temperature Type\") +\n  scale_x_continuous(breaks = seq(2014,2023, 1)) +\n  scale_color_manual(values = c(\"turquoise\", \"violetred2\", \"steelblue2\"), \n                      labels = c(\"Mean\", \"Max\", \"Min\")) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1),\n        panel.border = element_rect(color = \"lightgrey\",linetype = \"dashed\", fill = NA, size = 1))\n\np29 &lt;- ggplotly(p29, tooltip = \"all\", width = 800, height = 600) %&gt;% \n  layout(width = 800, height = 600)\n\np29\n\n\n\n\n\nSaving combined_data, combined_data2 and combined_data3 as csv files:\n\nwrite_csv(combined_data, \"data/combined_data.csv\")\nwrite_csv(combined_data2, \"data/combined_data2.csv\")\nwrite_csv(combined_data3, \"data/combined_data3.csv\")\n\n\nMean TemperatureMaximum TemperatureMinimum Temperature\n\n\nThe hypothesis is as follows:\nH0: There is no difference between mean temperature across weather stations.\nH1: There is a difference between mean temperature across weather stations.\n\np30 &lt;- ggbetweenstats(\n  data = weather_data_detailed,\n  x = station, \n  y = mean_monthly_temperature,\n  type = \"np\",\n  pairwise.display = \"significant\",\n  conf.level = 0.95,\n  messages = FALSE,\n  title=\"Distribution of Mean Temperature by Station\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Station\",\n  ggsignif.args = list(textsize = 3)\n) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1),\n        plot.title = element_text(size = 15),\n        text = element_text(size = 15))\np30\n\n\n\n\n\n\n\n\nThe plot above shows p-value &lt; 0.05, for which the null hypothesis will be rejected at alpha = 0.05. There is sufficient evidence to indicate that there is a difference in the mean temperature across stations. This suggests that different regions of Singapore are hotter/cooler.\n\n\nThe hypothesis is as follows:\nH0: There is no difference between maximum temperature across weather stations.\nH1: There is a difference between maximum temperature across weather stations.\n\np31 &lt;- ggbetweenstats(\n  data = weather_data_detailed,\n  x = station, \n  y = max_monthly_temperature,\n  type = \"np\",\n  pairwise.display = \"significant\",\n  conf.level = 0.95,\n  messages = FALSE,\n  title=\"Distribution of Max Temperature by Station\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Station\",\n  ggsignif.args = list(textsize = 3)\n) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1),\n        plot.title = element_text(size = 15),\n        text = element_text(size = 15))\np31\n\n\n\n\n\n\n\n\nThe plot above shows p-value of the test &lt; 0.05, for which the null hypothesis will be rejected at alpha = 0.05. There is sufficient evidence to indicate that there is a difference in the max temperature across stations. This suggests that different regions of Singapore are hotter/cooler.\n\n\nThe hypothesis is as follows:\nH0: There is no difference between minimum temperature across weather stations.\nH1: There is a difference between minimum temperature across weather stations.\n\np32 &lt;- ggbetweenstats(\n  data = weather_data_detailed,\n  x = station, \n  y = min_monthly_temperature,\n  type = \"np\",\n  pairwise.display = \"significant\",\n  conf.level = 0.95,\n  messages = FALSE,\n  title=\"Distribution of Min Temperature by Station\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Station\",\n  ggsignif.args = list(textsize = 3)\n) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1),\n        plot.title = element_text(size = 15),\n        text = element_text(size = 15))\np32\n\n\n\n\n\n\n\n\nThe plot above shows p-value of the test is &lt; 0.05, for which the null hypothesis will be rejected at alpha = 0.05. There is sufficient evidence to indicate that there is a difference in the min temperature across stations. This suggests that different regions of Singapore are hotter/cooler."
  },
  {
    "objectID": "Analysis/CDA.html#cda-summary-table",
    "href": "Analysis/CDA.html#cda-summary-table",
    "title": "Confirmatory Data Analysis",
    "section": "4.4 CDA Summary Table",
    "text": "4.4 CDA Summary Table\n\n\n\n\n\n\n\n\nS/N\nCDA\nFindings\n\n\n\n\n1.1\nAre the changes in rainfall over the years statistically significant?\n\nOver the years, the rainfall volume is generally observed to have increased.\nBased on statistical analysis, we determined that there is sufficient evidence to indicate that there is a difference in the rainfall across the years from 2014 to 2023.\n\n\n\n1.2\nAre the changes in temperature over the years statistically significant?\n\nBased on observation, it seemed like mean, max and min temperature did not undergo significant changes over the years from 2014 to 2023.\nHowever, based on statistical tests, we determined that there is sufficient evidence to indicate that there is a difference in the mean, max and min temperature across the years from 2014 to 2023.\n\n\n\n2.1\nAre there really certain months “drier” or “wetter”?\n\nYes, there is sufficient evidence to indicate that there is a difference in the rainfall across the months.\n\n\n\n2.2\nAre there really certain months “hotter” or “cooler”?\n\nYes, there is sufficient evidence to indicate that there is a difference in the mean, max and min temperatures across the months.\n\n\n\n3.1\nAre there certain locations “drier” or “wetter”?\n\nYes, there is sufficient evidence to indicate that there is differences in rainfall across stations, indicating different locations vary in degree of dryness/wetness.\n\n\n\n3.2\nAre there certain locations “hotter” or “cooler”?\n\nYes, there is sufficient evidence to indicate that there is a difference in the mean, max and min temperatures across stations. This suggests that different regions of Singapore are hotter/cooler."
  },
  {
    "objectID": "Analysis/Forecasting.html",
    "href": "Analysis/Forecasting.html",
    "title": "Forecasting",
    "section": "",
    "text": "To carry out decomposition of time series data\nTo plot time series data\nTo carry out forecasting of time series data"
  },
  {
    "objectID": "Analysis/Forecasting.html#installing-and-launching-the-packages",
    "href": "Analysis/Forecasting.html#installing-and-launching-the-packages",
    "title": "Prototype - Forecasting",
    "section": "Installing and launching the packages",
    "text": "Installing and launching the packages\n\npacman::p_load(tidyverse, lubridate, DT, ggplot2, plotly, ggthemes, timetk, modeltime, tidymodels, xgboost, recipes, parsnip, earth)"
  },
  {
    "objectID": "Analysis/Forecasting.html#importing-the-data",
    "href": "Analysis/Forecasting.html#importing-the-data",
    "title": "Prototype - Forecasting",
    "section": "Importing the data",
    "text": "Importing the data\nWe use read_csv() function of readr to import the daily_historical csv file into R then we will use glimpse() of dplyr to learn about the associated attribute information in the dataframe.\n\n\nShow the code\ndata &lt;- read_csv(\"data/daily_historical.csv\")\nglimpse(data)\n\n\nRows: 329,156\nColumns: 13\n$ station                  &lt;chr&gt; \"Macritchie Reservoir\", \"Macritchie Reservoir…\n$ year                     &lt;dbl&gt; 1980, 1980, 1980, 1980, 1980, 1980, 1980, 198…\n$ month                    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ day                      &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14…\n$ daily_rainfall_total     &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 22.6, 49.6, 2.4, 0.0, 0.0…\n$ highest_30_min_rainfall  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ highest_60_min_rainfall  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ highest_120_min_rainfall &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ mean_temperature         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ maximum_temperature      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ minimum_temperature      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ mean_wind_speed          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ max_wind_speed           &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…"
  },
  {
    "objectID": "Analysis/Forecasting.html#creating-a-date-column",
    "href": "Analysis/Forecasting.html#creating-a-date-column",
    "title": "Prototype - Forecasting",
    "section": "Creating a date column",
    "text": "Creating a date column\n\n\nShow the code\ndata$DATE &lt;- paste(data$year, \"-\", data$month, \"-\", data$day)\ndata &lt;- data %&gt;%\n  mutate(DATE = ymd(DATE))\n\nglimpse(data)\n\n\nRows: 329,156\nColumns: 14\n$ station                  &lt;chr&gt; \"Macritchie Reservoir\", \"Macritchie Reservoir…\n$ year                     &lt;dbl&gt; 1980, 1980, 1980, 1980, 1980, 1980, 1980, 198…\n$ month                    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ day                      &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14…\n$ daily_rainfall_total     &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 22.6, 49.6, 2.4, 0.0, 0.0…\n$ highest_30_min_rainfall  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ highest_60_min_rainfall  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ highest_120_min_rainfall &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ mean_temperature         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ maximum_temperature      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ minimum_temperature      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ mean_wind_speed          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ max_wind_speed           &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ DATE                     &lt;date&gt; 1980-01-01, 1980-01-02, 1980-01-03, 1980-01-…\n\n\n\n\nShow the code\ndatacleaned &lt;- data %&gt;%\n  select(station, DATE, mean_temperature, maximum_temperature, minimum_temperature, daily_rainfall_total) %&gt;%\n  drop_na(DATE)\n\nstr(datacleaned)\n\n\ntibble [329,098 × 6] (S3: tbl_df/tbl/data.frame)\n $ station             : chr [1:329098] \"Macritchie Reservoir\" \"Macritchie Reservoir\" \"Macritchie Reservoir\" \"Macritchie Reservoir\" ...\n $ DATE                : Date[1:329098], format: \"1980-01-01\" \"1980-01-02\" ...\n $ mean_temperature    : num [1:329098] NA NA NA NA NA NA NA NA NA NA ...\n $ maximum_temperature : num [1:329098] NA NA NA NA NA NA NA NA NA NA ...\n $ minimum_temperature : num [1:329098] NA NA NA NA NA NA NA NA NA NA ...\n $ daily_rainfall_total: num [1:329098] 0 0 0 0 22.6 49.6 2.4 0 0 0 ...\n\n\n\n\nShow the code\nstationstoremove &lt;- c(\"Botanic Garden\",\"Bukit Panjang\",\"Bukit Timah\",\"Choa Chu Kang (Central)\",\"Jurong Pier\",\"Kent Ridge\", \"Kranji Reservoir\", \"Lim Chu Kang\", \"Lower Peirce Reservoir\", \"Macritchie Reservoir\",\"Mandai\", \"Marine Parade\",\"Nicoll Highway\", \"Pasir Ris (Central)\", \"Punggol\", \"Queenstown\",\"Simei\", \"Somerset (Road)\",\"Tanjong Katong\", \"Toa Payoh\", \"Tuas\", \"Ulu Pandan\", \"Upper Peirce Reservoir\",\"Whampoa\")\n\n#create a operator to exclude things \n'%!in%' &lt;- function(x,y)!('%in%'(x,y))\n\n#excluded stations that have no temp data at all \ndatacleaned &lt;- datacleaned %&gt;%\n  filter(station %!in% stationstoremove) \n\nglimpse(datacleaned)\n\n\nRows: 120,139\nColumns: 6\n$ station              &lt;chr&gt; \"Admiralty\", \"Admiralty\", \"Admiralty\", \"Admiralty…\n$ DATE                 &lt;date&gt; 2009-01-01, 2009-01-02, 2009-01-03, 2009-01-04, …\n$ mean_temperature     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ maximum_temperature  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ minimum_temperature  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ daily_rainfall_total &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…"
  },
  {
    "objectID": "Analysis/Forecasting.html#period-summarisation",
    "href": "Analysis/Forecasting.html#period-summarisation",
    "title": "Prototype - Forecasting",
    "section": "Period Summarisation",
    "text": "Period Summarisation\n\nmean_monthly_temp &lt;- datacleaned %&gt;%\n  group_by(station) %&gt;%\n  summarise_by_time(\n    DATE,\n    .by = \"month\", \n    value = mean(mean_temperature),\n    .type = \"ceiling\"\n  ) %&gt;% rename(mean_monthly_temperature = value)\n\nmean_monthly_temp\n\n# A tibble: 3,947 × 3\n# Groups:   station [13]\n   station   DATE       mean_monthly_temperature\n   &lt;chr&gt;     &lt;date&gt;                        &lt;dbl&gt;\n 1 Admiralty 2009-02-01                     NA  \n 2 Admiralty 2009-03-01                     26.8\n 3 Admiralty 2009-04-01                     NA  \n 4 Admiralty 2009-05-01                     28.1\n 5 Admiralty 2009-06-01                     28.5\n 6 Admiralty 2009-07-01                     28.9\n 7 Admiralty 2009-08-01                     28.1\n 8 Admiralty 2009-09-01                     28.1\n 9 Admiralty 2009-10-01                     28.3\n10 Admiralty 2009-11-01                     28.0\n# ℹ 3,937 more rows\n\n\n\nmin_monthly_temp &lt;- datacleaned %&gt;%\n  group_by(station) %&gt;%\n  summarise_by_time(\n    DATE,\n    .by = \"month\", \n    value = min(minimum_temperature),\n    .type = \"ceiling\"\n  ) %&gt;% rename(min_monthly_temperature = value)\n\nmin_monthly_temp\n\n# A tibble: 3,947 × 3\n# Groups:   station [13]\n   station   DATE       min_monthly_temperature\n   &lt;chr&gt;     &lt;date&gt;                       &lt;dbl&gt;\n 1 Admiralty 2009-02-01                    NA  \n 2 Admiralty 2009-03-01                    23  \n 3 Admiralty 2009-04-01                    NA  \n 4 Admiralty 2009-05-01                    23.7\n 5 Admiralty 2009-06-01                    21.8\n 6 Admiralty 2009-07-01                    23.7\n 7 Admiralty 2009-08-01                    22.5\n 8 Admiralty 2009-09-01                    22.7\n 9 Admiralty 2009-10-01                    23.1\n10 Admiralty 2009-11-01                    22.2\n# ℹ 3,937 more rows\n\n\n\nmax_monthly_temp &lt;- datacleaned %&gt;%\n  group_by(station) %&gt;%\n  summarise_by_time(\n    DATE,\n    .by = \"month\", \n    value = max(minimum_temperature),\n    .type      = \"ceiling\"\n  ) %&gt;% rename(max_monthly_temperature = value)\n\nmax_monthly_temp\n\n# A tibble: 3,947 × 3\n# Groups:   station [13]\n   station   DATE       max_monthly_temperature\n   &lt;chr&gt;     &lt;date&gt;                       &lt;dbl&gt;\n 1 Admiralty 2009-02-01                    NA  \n 2 Admiralty 2009-03-01                    26  \n 3 Admiralty 2009-04-01                    NA  \n 4 Admiralty 2009-05-01                    27.7\n 5 Admiralty 2009-06-01                    27  \n 6 Admiralty 2009-07-01                    27.9\n 7 Admiralty 2009-08-01                    27.6\n 8 Admiralty 2009-09-01                    27.4\n 9 Admiralty 2009-10-01                    27.7\n10 Admiralty 2009-11-01                    26.7\n# ℹ 3,937 more rows\n\n\n\nmonthly_rf &lt;- datacleaned %&gt;%\n  group_by(station) %&gt;%\n  summarise_by_time(\n    DATE,\n    .by = \"month\", \n    value = sum(daily_rainfall_total)\n  ) %&gt;% rename(monthly_rainfall = value)\n\nmonthly_rf\n\n# A tibble: 3,947 × 3\n# Groups:   station [13]\n   station   DATE       monthly_rainfall\n   &lt;chr&gt;     &lt;date&gt;                &lt;dbl&gt;\n 1 Admiralty 2009-01-01             NA  \n 2 Admiralty 2009-02-01            148  \n 3 Admiralty 2009-03-01             NA  \n 4 Admiralty 2009-04-01            149. \n 5 Admiralty 2009-05-01            206. \n 6 Admiralty 2009-06-01             92  \n 7 Admiralty 2009-07-01            103  \n 8 Admiralty 2009-08-01             90.2\n 9 Admiralty 2009-09-01             67.6\n10 Admiralty 2009-10-01            160  \n# ℹ 3,937 more rows"
  },
  {
    "objectID": "Analysis/Forecasting.html#joining-the-data-tables",
    "href": "Analysis/Forecasting.html#joining-the-data-tables",
    "title": "Prototype - Forecasting",
    "section": "Joining the data tables",
    "text": "Joining the data tables\n\nweatherdata &lt;- left_join(mean_monthly_temp, min_monthly_temp)\nweatherdata\n\n# A tibble: 3,947 × 4\n# Groups:   station [13]\n   station   DATE       mean_monthly_temperature min_monthly_temperature\n   &lt;chr&gt;     &lt;date&gt;                        &lt;dbl&gt;                   &lt;dbl&gt;\n 1 Admiralty 2009-02-01                     NA                      NA  \n 2 Admiralty 2009-03-01                     26.8                    23  \n 3 Admiralty 2009-04-01                     NA                      NA  \n 4 Admiralty 2009-05-01                     28.1                    23.7\n 5 Admiralty 2009-06-01                     28.5                    21.8\n 6 Admiralty 2009-07-01                     28.9                    23.7\n 7 Admiralty 2009-08-01                     28.1                    22.5\n 8 Admiralty 2009-09-01                     28.1                    22.7\n 9 Admiralty 2009-10-01                     28.3                    23.1\n10 Admiralty 2009-11-01                     28.0                    22.2\n# ℹ 3,937 more rows\n\n\n\nweatherdata &lt;- left_join(weatherdata, max_monthly_temp)\nweatherdata\n\n# A tibble: 3,947 × 5\n# Groups:   station [13]\n   station   DATE       mean_monthly_temperature min_monthly_temperature\n   &lt;chr&gt;     &lt;date&gt;                        &lt;dbl&gt;                   &lt;dbl&gt;\n 1 Admiralty 2009-02-01                     NA                      NA  \n 2 Admiralty 2009-03-01                     26.8                    23  \n 3 Admiralty 2009-04-01                     NA                      NA  \n 4 Admiralty 2009-05-01                     28.1                    23.7\n 5 Admiralty 2009-06-01                     28.5                    21.8\n 6 Admiralty 2009-07-01                     28.9                    23.7\n 7 Admiralty 2009-08-01                     28.1                    22.5\n 8 Admiralty 2009-09-01                     28.1                    22.7\n 9 Admiralty 2009-10-01                     28.3                    23.1\n10 Admiralty 2009-11-01                     28.0                    22.2\n# ℹ 3,937 more rows\n# ℹ 1 more variable: max_monthly_temperature &lt;dbl&gt;\n\n\n\nweatherdata &lt;- left_join(weatherdata, monthly_rf)\nsummary(weatherdata)\n\n   station               DATE            mean_monthly_temperature\n Length:3947        Min.   :1980-02-01   Min.   :25.23           \n Class :character   1st Qu.:1996-07-01   1st Qu.:27.34           \n Mode  :character   Median :2011-04-01   Median :27.94           \n                    Mean   :2007-01-17   Mean   :27.88           \n                    3rd Qu.:2017-10-01   3rd Qu.:28.47           \n                    Max.   :2024-01-01   Max.   :29.78           \n                                         NA's   :1750            \n min_monthly_temperature max_monthly_temperature monthly_rainfall\n Min.   :20.00           Min.   :24.00           Min.   :  0.2   \n 1st Qu.:22.30           1st Qu.:26.30           1st Qu.:120.8   \n Median :22.80           Median :27.20           Median :186.6   \n Mean   :22.77           Mean   :27.12           Mean   :199.8   \n 3rd Qu.:23.30           3rd Qu.:28.00           3rd Qu.:263.0   \n Max.   :26.20           Max.   :30.00           Max.   :765.9   \n NA's   :1699            NA's   :1699            NA's   :251     \n\n\n\nweatherdata &lt;- weatherdata %&gt;%\n  filter_by_time(DATE, .start_date = \"2014-01\", .end_date = \"2023-12\")\n\n\nsummary(weatherdata)\n\n   station               DATE            mean_monthly_temperature\n Length:1548        Min.   :2014-01-01   Min.   :25.46           \n Class :character   1st Qu.:2016-07-01   1st Qu.:27.54           \n Mode  :character   Median :2019-01-01   Median :28.13           \n                    Mean   :2018-12-25   Mean   :28.05           \n                    3rd Qu.:2021-07-01   3rd Qu.:28.63           \n                    Max.   :2023-12-01   Max.   :29.78           \n                                         NA's   :227             \n min_monthly_temperature max_monthly_temperature monthly_rainfall\n Min.   :20.40           Min.   :24.20           Min.   :  0.2   \n 1st Qu.:22.40           1st Qu.:26.60           1st Qu.:115.4   \n Median :22.90           Median :27.50           Median :182.0   \n Mean   :22.91           Mean   :27.34           Mean   :192.4   \n 3rd Qu.:23.40           3rd Qu.:28.10           3rd Qu.:253.2   \n Max.   :26.20           Max.   :29.70           Max.   :692.8   \n NA's   :198             NA's   :198             NA's   :159     \n\n\n\nwrite_rds(weatherdata, \"data/weather_data.rds\")"
  },
  {
    "objectID": "Analysis/Forecasting.html#missing-value-imputation",
    "href": "Analysis/Forecasting.html#missing-value-imputation",
    "title": "Prototype - Forecasting",
    "section": "Missing value imputation",
    "text": "Missing value imputation\n\nunique(weatherdata$DATE)\n\n  [1] \"2014-01-01\" \"2014-02-01\" \"2014-03-01\" \"2014-04-01\" \"2014-05-01\"\n  [6] \"2014-06-01\" \"2014-07-01\" \"2014-08-01\" \"2014-09-01\" \"2014-11-01\"\n [11] \"2014-12-01\" \"2015-01-01\" \"2015-02-01\" \"2015-03-01\" \"2015-04-01\"\n [16] \"2015-05-01\" \"2015-06-01\" \"2015-07-01\" \"2015-08-01\" \"2015-09-01\"\n [21] \"2015-10-01\" \"2015-11-01\" \"2015-12-01\" \"2016-01-01\" \"2016-02-01\"\n [26] \"2016-03-01\" \"2016-04-01\" \"2016-05-01\" \"2016-06-01\" \"2016-07-01\"\n [31] \"2016-08-01\" \"2016-09-01\" \"2016-10-01\" \"2016-11-01\" \"2016-12-01\"\n [36] \"2017-01-01\" \"2017-02-01\" \"2017-03-01\" \"2017-04-01\" \"2017-05-01\"\n [41] \"2017-06-01\" \"2017-07-01\" \"2017-08-01\" \"2017-09-01\" \"2017-10-01\"\n [46] \"2017-11-01\" \"2017-12-01\" \"2018-01-01\" \"2018-02-01\" \"2018-03-01\"\n [51] \"2018-04-01\" \"2018-05-01\" \"2018-06-01\" \"2018-07-01\" \"2018-08-01\"\n [56] \"2018-09-01\" \"2018-10-01\" \"2018-11-01\" \"2018-12-01\" \"2019-01-01\"\n [61] \"2019-02-01\" \"2019-03-01\" \"2019-04-01\" \"2019-05-01\" \"2019-06-01\"\n [66] \"2019-07-01\" \"2019-08-01\" \"2019-09-01\" \"2019-10-01\" \"2019-11-01\"\n [71] \"2019-12-01\" \"2020-01-01\" \"2020-02-01\" \"2020-03-01\" \"2020-04-01\"\n [76] \"2020-05-01\" \"2020-06-01\" \"2020-07-01\" \"2020-08-01\" \"2020-09-01\"\n [81] \"2020-10-01\" \"2020-11-01\" \"2020-12-01\" \"2021-01-01\" \"2021-02-01\"\n [86] \"2021-03-01\" \"2021-04-01\" \"2021-05-01\" \"2021-06-01\" \"2021-07-01\"\n [91] \"2021-08-01\" \"2021-09-01\" \"2021-10-01\" \"2021-11-01\" \"2021-12-01\"\n [96] \"2022-01-01\" \"2022-02-01\" \"2022-03-01\" \"2022-04-01\" \"2022-05-01\"\n[101] \"2022-06-01\" \"2022-07-01\" \"2022-08-01\" \"2022-09-01\" \"2022-10-01\"\n[106] \"2022-11-01\" \"2022-12-01\" \"2023-01-01\" \"2023-02-01\" \"2023-03-01\"\n[111] \"2023-04-01\" \"2023-05-01\" \"2023-06-01\" \"2023-07-01\" \"2023-08-01\"\n[116] \"2023-09-01\" \"2023-10-01\" \"2023-11-01\" \"2023-12-01\" \"2014-10-01\"\n\n\n\nweatherdata$mean_monthly_temperature &lt;- weatherdata$mean_monthly_temperature %&gt;%\n  ts_impute_vec(period = 2, lambda = \"auto\")\n\nsummary(weatherdata)\n\n   station               DATE            mean_monthly_temperature\n Length:1548        Min.   :2014-01-01   Min.   :25.46           \n Class :character   1st Qu.:2016-07-01   1st Qu.:27.54           \n Mode  :character   Median :2019-01-01   Median :28.09           \n                    Mean   :2018-12-25   Mean   :28.03           \n                    3rd Qu.:2021-07-01   3rd Qu.:28.57           \n                    Max.   :2023-12-01   Max.   :29.78           \n                                                                 \n min_monthly_temperature max_monthly_temperature monthly_rainfall\n Min.   :20.40           Min.   :24.20           Min.   :  0.2   \n 1st Qu.:22.40           1st Qu.:26.60           1st Qu.:115.4   \n Median :22.90           Median :27.50           Median :182.0   \n Mean   :22.91           Mean   :27.34           Mean   :192.4   \n 3rd Qu.:23.40           3rd Qu.:28.10           3rd Qu.:253.2   \n Max.   :26.20           Max.   :29.70           Max.   :692.8   \n NA's   :198             NA's   :198             NA's   :159     \n\n\n\nweatherdata %&gt;%\n  group_by(station) %&gt;%\n  plot_time_series(DATE, mean_monthly_temperature, .facet_ncol = 3)\n\n\n\n\n\n\nweatherdata$min_monthly_temperature &lt;- weatherdata$min_monthly_temperature %&gt;%\n  ts_impute_vec(period = 2, lambda = \"auto\")\n\nsummary(weatherdata)\n\n   station               DATE            mean_monthly_temperature\n Length:1548        Min.   :2014-01-01   Min.   :25.46           \n Class :character   1st Qu.:2016-07-01   1st Qu.:27.54           \n Mode  :character   Median :2019-01-01   Median :28.09           \n                    Mean   :2018-12-25   Mean   :28.03           \n                    3rd Qu.:2021-07-01   3rd Qu.:28.57           \n                    Max.   :2023-12-01   Max.   :29.78           \n                                                                 \n min_monthly_temperature max_monthly_temperature monthly_rainfall\n Min.   :20.40           Min.   :24.20           Min.   :  0.2   \n 1st Qu.:22.40           1st Qu.:26.60           1st Qu.:115.4   \n Median :22.90           Median :27.50           Median :182.0   \n Mean   :22.91           Mean   :27.34           Mean   :192.4   \n 3rd Qu.:23.40           3rd Qu.:28.10           3rd Qu.:253.2   \n Max.   :26.20           Max.   :29.70           Max.   :692.8   \n                         NA's   :198             NA's   :159     \n\n\n\nweatherdata %&gt;%\n  group_by(station) %&gt;%\n  plot_time_series(DATE, min_monthly_temperature, .facet_ncol = 3)\n\n\n\n\n\n\nweatherdata$max_monthly_temperature &lt;- weatherdata$max_monthly_temperature %&gt;%\n  ts_impute_vec(period = 2, lambda = \"auto\")\n\nsummary(weatherdata)\n\n   station               DATE            mean_monthly_temperature\n Length:1548        Min.   :2014-01-01   Min.   :25.46           \n Class :character   1st Qu.:2016-07-01   1st Qu.:27.54           \n Mode  :character   Median :2019-01-01   Median :28.09           \n                    Mean   :2018-12-25   Mean   :28.03           \n                    3rd Qu.:2021-07-01   3rd Qu.:28.57           \n                    Max.   :2023-12-01   Max.   :29.78           \n                                                                 \n min_monthly_temperature max_monthly_temperature monthly_rainfall\n Min.   :20.40           Min.   :24.20           Min.   :  0.2   \n 1st Qu.:22.40           1st Qu.:26.60           1st Qu.:115.4   \n Median :22.90           Median :27.40           Median :182.0   \n Mean   :22.91           Mean   :27.32           Mean   :192.4   \n 3rd Qu.:23.40           3rd Qu.:28.10           3rd Qu.:253.2   \n Max.   :26.20           Max.   :29.70           Max.   :692.8   \n                                                 NA's   :159     \n\n\n\nweatherdata %&gt;%\n  group_by(station) %&gt;%\n  plot_time_series(DATE, max_monthly_temperature, .facet_ncol = 3)\n\n\n\n\n\n\nweatherdata$monthly_rainfall &lt;- weatherdata$monthly_rainfall%&gt;%\n  ts_impute_vec(period = 2, lambda = \"auto\")\n\nsummary(weatherdata)\n\n   station               DATE            mean_monthly_temperature\n Length:1548        Min.   :2014-01-01   Min.   :25.46           \n Class :character   1st Qu.:2016-07-01   1st Qu.:27.54           \n Mode  :character   Median :2019-01-01   Median :28.09           \n                    Mean   :2018-12-25   Mean   :28.03           \n                    3rd Qu.:2021-07-01   3rd Qu.:28.57           \n                    Max.   :2023-12-01   Max.   :29.78           \n min_monthly_temperature max_monthly_temperature monthly_rainfall\n Min.   :20.40           Min.   :24.20           Min.   :  0.2   \n 1st Qu.:22.40           1st Qu.:26.60           1st Qu.:116.8   \n Median :22.90           Median :27.40           Median :180.9   \n Mean   :22.91           Mean   :27.32           Mean   :190.6   \n 3rd Qu.:23.40           3rd Qu.:28.10           3rd Qu.:248.2   \n Max.   :26.20           Max.   :29.70           Max.   :692.8   \n\n\n\nweatherdata %&gt;%\n  group_by(station) %&gt;%\n  plot_time_series(DATE, monthly_rainfall, .facet_ncol = 3)\n\n\n\n\n\n\nwrite_rds(weatherdata, \"data/weather_data_imputed.rds\")"
  },
  {
    "objectID": "Analysis/Forecasting.html#decomposition-of-time-series-object",
    "href": "Analysis/Forecasting.html#decomposition-of-time-series-object",
    "title": "Prototype - Forecasting",
    "section": "Decomposition of Time Series Object",
    "text": "Decomposition of Time Series Object\n\nweatherdata &lt;- read_rds(\"data/weather_data_imputed.rds\")\n\n\nweatherdata %&gt;%\n  filter(station == \"Admiralty\") %&gt;%\n  plot_seasonal_diagnostics(DATE, mean_monthly_temperature)\n\n\n\n\n\n\nweatherdata %&gt;%\n  filter(station == \"Admiralty\") %&gt;%\n  plot_seasonal_diagnostics(DATE, monthly_rainfall)\n\n\n\n\n\n\nweatherdata %&gt;%\n  filter(station == \"Admiralty\") %&gt;%\n  plot_stl_diagnostics(DATE, mean_monthly_temperature,\n                       .frequency = \"auto\", .trend = \"auto\",\n                        .feature_set = c(\"observed\", \"season\", \"trend\", \"remainder\"))\n\n\n\n\n\n\nweatherdata %&gt;%\n  filter(station == \"Admiralty\") %&gt;%\n  plot_stl_diagnostics(DATE, min_monthly_temperature,\n                       .frequency = \"auto\", .trend = \"auto\",\n                        .feature_set = c(\"observed\", \"season\", \"trend\", \"remainder\"))\n\n\n\n\n\n\nweatherdata %&gt;%\n  filter(station == \"Admiralty\") %&gt;%\n  plot_stl_diagnostics(DATE, max_monthly_temperature,\n                       .frequency = \"auto\", .trend = \"auto\",\n                        .feature_set = c(\"observed\", \"season\", \"trend\", \"remainder\"))\n\n\n\n\n\n\nweatherdata %&gt;%\n  filter(station == \"Admiralty\") %&gt;%\n  plot_stl_diagnostics(DATE, monthly_rainfall,\n                       .frequency = \"auto\", .trend = \"auto\",\n                        .feature_set = c(\"observed\", \"season\", \"trend\", \"remainder\"))"
  },
  {
    "objectID": "Analysis/Forecasting.html#selecting-the-data",
    "href": "Analysis/Forecasting.html#selecting-the-data",
    "title": "Forecasting",
    "section": "5.1 Selecting the data",
    "text": "5.1 Selecting the data\nWe use mean monthly temperature of Admiralty station as an example.\nFirst we will select the relevant data column\n\nglimpse(weatherdata)\n\nRows: 1,548\nColumns: 6\nGroups: station [13]\n$ station                  &lt;chr&gt; \"Admiralty\", \"Admiralty\", \"Admiralty\", \"Admir…\n$ DATE                     &lt;date&gt; 2014-01-01, 2014-02-01, 2014-03-01, 2014-04-…\n$ mean_monthly_temperature &lt;dbl&gt; 26.22903, 25.79355, 26.76071, 27.35484, 27.81…\n$ min_monthly_temperature  &lt;dbl&gt; 21.70000, 22.40000, 21.80000, 23.50000, 22.40…\n$ max_monthly_temperature  &lt;dbl&gt; 25.30000, 24.90000, 24.90000, 25.80000, 26.50…\n$ monthly_rainfall         &lt;dbl&gt; 98.8000, 15.8000, 120.0000, 261.4000, 301.000…\n\n\n\nweatherdata_meantemp &lt;- weatherdata %&gt;%\n  filter(station == \"Admiralty\") %&gt;%\n  select(date = DATE, value = mean_monthly_temperature)\n\nweatherdata_meantemp \n\n# A tibble: 119 × 3\n# Groups:   station [1]\n   station   date       value\n   &lt;chr&gt;     &lt;date&gt;     &lt;dbl&gt;\n 1 Admiralty 2014-01-01  26.2\n 2 Admiralty 2014-02-01  25.8\n 3 Admiralty 2014-03-01  26.8\n 4 Admiralty 2014-04-01  27.4\n 5 Admiralty 2014-05-01  27.8\n 6 Admiralty 2014-06-01  28.2\n 7 Admiralty 2014-07-01  28.9\n 8 Admiralty 2014-08-01  28.6\n 9 Admiralty 2014-09-01  28.0\n10 Admiralty 2014-11-01  27.8\n# ℹ 109 more rows"
  },
  {
    "objectID": "Analysis/Forecasting.html#visualise-the-dataset",
    "href": "Analysis/Forecasting.html#visualise-the-dataset",
    "title": "Forecasting",
    "section": "5.2 Visualise the dataset",
    "text": "5.2 Visualise the dataset\n\nweatherdata_meantemp %&gt;%\n  plot_time_series(date, value)"
  },
  {
    "objectID": "Analysis/Forecasting.html#traintest",
    "href": "Analysis/Forecasting.html#traintest",
    "title": "Forecasting",
    "section": "5.3 Train/Test",
    "text": "5.3 Train/Test\n\nsplits &lt;- weatherdata_meantemp %&gt;%\n  initial_time_split(prop = 0.8)\n\nsplits\n\n&lt;Training/Testing/Total&gt;\n&lt;95/24/119&gt;\n\ntraining(splits)\n\n# A tibble: 95 × 3\n# Groups:   station [1]\n   station   date       value\n   &lt;chr&gt;     &lt;date&gt;     &lt;dbl&gt;\n 1 Admiralty 2014-01-01  26.2\n 2 Admiralty 2014-02-01  25.8\n 3 Admiralty 2014-03-01  26.8\n 4 Admiralty 2014-04-01  27.4\n 5 Admiralty 2014-05-01  27.8\n 6 Admiralty 2014-06-01  28.2\n 7 Admiralty 2014-07-01  28.9\n 8 Admiralty 2014-08-01  28.6\n 9 Admiralty 2014-09-01  28.0\n10 Admiralty 2014-11-01  27.8\n# ℹ 85 more rows\n\ntesting(splits)\n\n# A tibble: 24 × 3\n# Groups:   station [1]\n   station   date       value\n   &lt;chr&gt;     &lt;date&gt;     &lt;dbl&gt;\n 1 Admiralty 2022-01-01  27.2\n 2 Admiralty 2022-02-01  27.0\n 3 Admiralty 2022-03-01  26.8\n 4 Admiralty 2022-04-01  27.7\n 5 Admiralty 2022-05-01  27.7\n 6 Admiralty 2022-06-01  28.8\n 7 Admiralty 2022-07-01  27.5\n 8 Admiralty 2022-08-01  28.4\n 9 Admiralty 2022-09-01  27.6\n10 Admiralty 2022-10-01  27.5\n# ℹ 14 more rows"
  },
  {
    "objectID": "Analysis/Forecasting.html#creating-and-fitting-models",
    "href": "Analysis/Forecasting.html#creating-and-fitting-models",
    "title": "Forecasting",
    "section": "5.4 Creating and Fitting Models",
    "text": "5.4 Creating and Fitting Models\n\n5.4.1 Model 1 - Auto ARIMA\n\nmodel_fit_arima_no_boost &lt;- arima_reg() %&gt;%\n  set_engine(engine = \"auto_arima\") %&gt;%\n  fit(value ~ date, data = training(splits))\n\n\n\n5.4.2 Boosted Auto ARIMA\nCreate a boosted ARIMA. Boosting uses XGBOost to model the ARIMA errors.\n\nmodel_fit_arima_boosted &lt;- arima_boost(\n    min_n = 2,\n    learn_rate = 0.015\n) %&gt;%\n    set_engine(engine = \"auto_arima_xgboost\") %&gt;%\n    fit(value ~ date + as.numeric(date) + factor(month(date, label = TRUE), ordered = F),\n        data = training(splits))\n\n\n\n5.4.3 Exponential Smoothing\n\nmodel_fit_ets &lt;- exp_smoothing() %&gt;%\n    set_engine(engine = \"ets\") %&gt;%\n    fit(value ~ date, data = training(splits))\n\n\nmodel_fit_ets\n\nparsnip model object\n\nETS(A,N,A) \n\nCall:\n forecast::ets(y = outcome, model = model_ets, damped = damping_ets,  \n\n Call:\n     alpha = alpha, beta = beta, gamma = gamma) \n\n  Smoothing parameters:\n    alpha = 0.3744 \n    gamma = 1e-04 \n\n  Initial states:\n    l = 27.4844 \n    s = -0.853 -0.4341 0.2104 0.2587 0.5635 0.6531\n           0.3323 0.5585 0.3482 0.0175 -0.7688 -0.8861\n\n  sigma:  0.4493\n\n     AIC     AICc      BIC \n295.4710 301.5470 333.7792 \n\n\n\ncalibration_ets &lt;- model_fit_ets %&gt;%\n    modeltime_calibrate(new_data = testing(splits))\n\ncalibration_ets\n\n# Modeltime Table\n# A tibble: 1 × 5\n  .model_id .model   .model_desc .type .calibration_data\n      &lt;int&gt; &lt;list&gt;   &lt;chr&gt;       &lt;chr&gt; &lt;list&gt;           \n1         1 &lt;fit[+]&gt; ETS(A,N,A)  Test  &lt;tibble [24 × 4]&gt;\n\n\n\nforecast_results &lt;- calibration_ets %&gt;%\n    modeltime_forecast(\n        new_data    = testing(splits),\n        actual_data = weatherdata_meantemp\n    ) \n\ndatatable(forecast_results)\n\n\n\n\n\n\ncalibration_ets %&gt;%\n    modeltime_forecast(\n        new_data    = testing(splits),\n        actual_data = weatherdata_meantemp\n    ) %&gt;%\n    plot_modeltime_forecast(\n      .legend_max_width = 25\n    )\n\n\n\n\n\n\n\n5.4.4 Accuracy Metrics\n\naccuracy_metrics &lt;- calibration_ets %&gt;%\n  modeltime_accuracy() \n\n\naccuracy_metrics$mae\n\n[1] 0.4177054\n\naccuracy_metrics$mape\n\n[1] 1.510336\n\naccuracy_metrics$rmse\n\n[1] 0.5062106\n\n\n\n\n5.4.5 Prophet\n\nmodel_fit_prophet &lt;- prophet_reg() %&gt;%\n    set_engine(engine = \"prophet\") %&gt;%\n    fit(value ~ date, data = training(splits))\n\n\n\n5.4.6 Linear Regression\n\nmodel_fit_lm &lt;- linear_reg() %&gt;%\n    set_engine(\"lm\") %&gt;%\n    fit(value ~ as.numeric(date) + factor(month(date, label = TRUE), ordered = FALSE),\n        data = training(splits))\n\n\n\n5.4.7 MARS\n\nmodel_spec_mars &lt;- mars(mode = \"regression\") %&gt;%\n    set_engine(\"earth\") \n\nrecipe_spec &lt;- recipe(value ~ date, data = training(splits)) %&gt;%\n    step_date(date, features = \"month\", ordinal = FALSE) %&gt;%\n    step_mutate(date_num = as.numeric(date)) %&gt;%\n    step_normalize(date_num) %&gt;%\n    step_rm(date)\n  \nwflw_fit_mars &lt;- workflow() %&gt;%\n    add_recipe(recipe_spec) %&gt;%\n    add_model(model_spec_mars) %&gt;%\n    fit(training(splits))"
  },
  {
    "objectID": "Analysis/Forecasting.html#add-fitted-models-to-a-model-table",
    "href": "Analysis/Forecasting.html#add-fitted-models-to-a-model-table",
    "title": "Forecasting",
    "section": "5.5 Add Fitted Models to a Model table",
    "text": "5.5 Add Fitted Models to a Model table\n\nmodels_tbl &lt;- modeltime_table(\n    model_fit_arima_no_boost,\n    model_fit_arima_boosted,\n    model_fit_ets,\n    model_fit_prophet,\n    model_fit_lm,\n    wflw_fit_mars\n)\n\nmodels_tbl\n\n# Modeltime Table\n# A tibble: 6 × 3\n  .model_id .model     .model_desc                              \n      &lt;int&gt; &lt;list&gt;     &lt;chr&gt;                                    \n1         1 &lt;fit[+]&gt;   ARIMA(1,0,0)(2,1,0)[12]                  \n2         2 &lt;fit[+]&gt;   ARIMA(1,0,0)(2,1,0)[12] W/ XGBOOST ERRORS\n3         3 &lt;fit[+]&gt;   ETS(A,N,A)                               \n4         4 &lt;fit[+]&gt;   PROPHET                                  \n5         5 &lt;fit[+]&gt;   LM                                       \n6         6 &lt;workflow&gt; EARTH"
  },
  {
    "objectID": "Analysis/Forecasting.html#calibrate-the-model-to-a-testing-set",
    "href": "Analysis/Forecasting.html#calibrate-the-model-to-a-testing-set",
    "title": "Forecasting",
    "section": "5.6 Calibrate the model to a testing set",
    "text": "5.6 Calibrate the model to a testing set\n\ncalibration_tbl &lt;- models_tbl %&gt;%\n    modeltime_calibrate(new_data = testing(splits))\n\ncalibration_tbl\n\n# Modeltime Table\n# A tibble: 6 × 5\n  .model_id .model     .model_desc                       .type .calibration_data\n      &lt;int&gt; &lt;list&gt;     &lt;chr&gt;                             &lt;chr&gt; &lt;list&gt;           \n1         1 &lt;fit[+]&gt;   ARIMA(1,0,0)(2,1,0)[12]           Test  &lt;tibble [24 × 4]&gt;\n2         2 &lt;fit[+]&gt;   ARIMA(1,0,0)(2,1,0)[12] W/ XGBOO… Test  &lt;tibble [24 × 4]&gt;\n3         3 &lt;fit[+]&gt;   ETS(A,N,A)                        Test  &lt;tibble [24 × 4]&gt;\n4         4 &lt;fit[+]&gt;   PROPHET                           Test  &lt;tibble [24 × 4]&gt;\n5         5 &lt;fit[+]&gt;   LM                                Test  &lt;tibble [24 × 4]&gt;\n6         6 &lt;workflow&gt; EARTH                             Test  &lt;tibble [24 × 4]&gt;"
  },
  {
    "objectID": "Analysis/Forecasting.html#testing-set-forecast-accuracy-evaluation",
    "href": "Analysis/Forecasting.html#testing-set-forecast-accuracy-evaluation",
    "title": "Forecasting",
    "section": "5.7 Testing Set Forecast & Accuracy Evaluation",
    "text": "5.7 Testing Set Forecast & Accuracy Evaluation\n\n5.7.1 Visualising forecast test\n\ncalibration_tbl %&gt;%\n    modeltime_forecast(\n        new_data    = testing(splits),\n        actual_data = weatherdata_meantemp\n    ) %&gt;%\n    plot_modeltime_forecast(\n      .legend_max_width = 25\n    )\n\n\n\n\n\n\n\n5.7.2 Accuracy Metrics\n\ncalibration_tbl %&gt;%\n    modeltime_accuracy() %&gt;%\n    table_modeltime_accuracy()"
  },
  {
    "objectID": "Analysis/Forecasting.html#refit-to-full-dataset-and-forecast-forward",
    "href": "Analysis/Forecasting.html#refit-to-full-dataset-and-forecast-forward",
    "title": "Forecasting",
    "section": "5.8 Refit to full dataset and forecast forward",
    "text": "5.8 Refit to full dataset and forecast forward\n\nrefit_tbl &lt;- calibration_tbl %&gt;%\n    modeltime_refit(data = weatherdata_meantemp)\n\nrefit_tbl %&gt;%\n    modeltime_forecast(h = \"36 months\", actual_data = weatherdata_meantemp) %&gt;%\n    plot_modeltime_forecast(\n      .legend_max_width = 25\n\n    )"
  },
  {
    "objectID": "Analysis/Forecasting.html#selecting-the-data-1",
    "href": "Analysis/Forecasting.html#selecting-the-data-1",
    "title": "Forecasting",
    "section": "6.1 Selecting the data",
    "text": "6.1 Selecting the data\nWe use mean monthly temperature of Admiralty station as an example.\nFirst we will select the relevant data column\n\nweatherdata_rf &lt;- weatherdata %&gt;%\n  filter(station == \"Admiralty\") %&gt;%\n  select(date = DATE, value = monthly_rainfall)\n\nweatherdata_rf \n\n# A tibble: 119 × 3\n# Groups:   station [1]\n   station   date       value\n   &lt;chr&gt;     &lt;date&gt;     &lt;dbl&gt;\n 1 Admiralty 2014-01-01  98.8\n 2 Admiralty 2014-02-01  15.8\n 3 Admiralty 2014-03-01 120  \n 4 Admiralty 2014-04-01 261. \n 5 Admiralty 2014-05-01 301  \n 6 Admiralty 2014-06-01 196  \n 7 Admiralty 2014-07-01 238. \n 8 Admiralty 2014-08-01 264. \n 9 Admiralty 2014-09-01 207. \n10 Admiralty 2014-11-01 236. \n# ℹ 109 more rows"
  },
  {
    "objectID": "Analysis/Forecasting.html#visualise-the-dataset-1",
    "href": "Analysis/Forecasting.html#visualise-the-dataset-1",
    "title": "Forecasting",
    "section": "6.2 Visualise the dataset",
    "text": "6.2 Visualise the dataset\n\nweatherdata_rf %&gt;%\n  plot_time_series(date, value)"
  },
  {
    "objectID": "Analysis/Forecasting.html#traintest-1",
    "href": "Analysis/Forecasting.html#traintest-1",
    "title": "Forecasting",
    "section": "6.3 Train/Test",
    "text": "6.3 Train/Test\n\nsplits &lt;- weatherdata_rf %&gt;%\n  initial_time_split(prop = 0.8)"
  },
  {
    "objectID": "Analysis/Forecasting.html#creating-and-fitting-models-1",
    "href": "Analysis/Forecasting.html#creating-and-fitting-models-1",
    "title": "Forecasting",
    "section": "6.4 Creating and Fitting Models",
    "text": "6.4 Creating and Fitting Models\n\n6.4.1 Model 1 - Auto ARIMA\n\nmodel_fit_arima_no_boost &lt;- arima_reg() %&gt;%\n  set_engine(engine = \"auto_arima\") %&gt;%\n  fit(value ~ date, data = training(splits))\n\n\n\n6.4.2 Boosted Auto ARIMA\nCreate a boosted ARIMA. Boosting uses XGBOost to model the ARIMA errors.\n\nmodel_fit_arima_boosted &lt;- arima_boost(\n    min_n = 2,\n    learn_rate = 0.015\n) %&gt;%\n    set_engine(engine = \"auto_arima_xgboost\") %&gt;%\n    fit(value ~ date + as.numeric(date) + factor(month(date, label = TRUE), ordered = F),\n        data = training(splits))\n\n\n\n6.4.3 Exponential Smoothing\n\nmodel_fit_ets &lt;- exp_smoothing() %&gt;%\n    set_engine(engine = \"ets\") %&gt;%\n    fit(value ~ date, data = training(splits))\n\n\n\n6.4.4 Prophet\n\nmodel_fit_prophet &lt;- prophet_reg() %&gt;%\n    set_engine(engine = \"prophet\") %&gt;%\n    fit(value ~ date, data = training(splits))\n\n\n\n6.4.5 Linear Regression\n\nmodel_fit_lm &lt;- linear_reg() %&gt;%\n    set_engine(\"lm\") %&gt;%\n    fit(value ~ as.numeric(date) + factor(month(date, label = TRUE), ordered = FALSE),\n        data = training(splits))\n\n\n\n6.4.6 MARS\n\nmodel_spec_mars &lt;- mars(mode = \"regression\") %&gt;%\n    set_engine(\"earth\") \n\nrecipe_spec &lt;- recipe(value ~ date, data = training(splits)) %&gt;%\n    step_date(date, features = \"month\", ordinal = FALSE) %&gt;%\n    step_mutate(date_num = as.numeric(date)) %&gt;%\n    step_normalize(date_num) %&gt;%\n    step_rm(date)\n  \nwflw_fit_mars &lt;- workflow() %&gt;%\n    add_recipe(recipe_spec) %&gt;%\n    add_model(model_spec_mars) %&gt;%\n    fit(training(splits))"
  },
  {
    "objectID": "Analysis/Forecasting.html#add-fitted-models-to-a-model-table-1",
    "href": "Analysis/Forecasting.html#add-fitted-models-to-a-model-table-1",
    "title": "Forecasting",
    "section": "6.5 Add Fitted Models to a Model table",
    "text": "6.5 Add Fitted Models to a Model table\n\nmodels_tbl &lt;- modeltime_table(\n    model_fit_arima_no_boost,\n    model_fit_arima_boosted,\n    model_fit_ets,\n    model_fit_prophet,\n    model_fit_lm,\n    wflw_fit_mars\n)\n\nmodels_tbl\n\n# Modeltime Table\n# A tibble: 6 × 3\n  .model_id .model     .model_desc                                      \n      &lt;int&gt; &lt;list&gt;     &lt;chr&gt;                                            \n1         1 &lt;fit[+]&gt;   ARIMA(1,0,0) WITH NON-ZERO MEAN                  \n2         2 &lt;fit[+]&gt;   ARIMA(1,0,0) WITH NON-ZERO MEAN W/ XGBOOST ERRORS\n3         3 &lt;fit[+]&gt;   ETS(A,N,N)                                       \n4         4 &lt;fit[+]&gt;   PROPHET                                          \n5         5 &lt;fit[+]&gt;   LM                                               \n6         6 &lt;workflow&gt; EARTH"
  },
  {
    "objectID": "Analysis/Forecasting.html#calibrate-the-model-to-a-testing-set-1",
    "href": "Analysis/Forecasting.html#calibrate-the-model-to-a-testing-set-1",
    "title": "Forecasting",
    "section": "6.6 Calibrate the model to a testing set",
    "text": "6.6 Calibrate the model to a testing set\n\ncalibration_tbl &lt;- models_tbl %&gt;%\n    modeltime_calibrate(new_data = testing(splits))\n\ncalibration_tbl\n\n# Modeltime Table\n# A tibble: 6 × 5\n  .model_id .model     .model_desc                       .type .calibration_data\n      &lt;int&gt; &lt;list&gt;     &lt;chr&gt;                             &lt;chr&gt; &lt;list&gt;           \n1         1 &lt;fit[+]&gt;   ARIMA(1,0,0) WITH NON-ZERO MEAN   Test  &lt;tibble [24 × 4]&gt;\n2         2 &lt;fit[+]&gt;   ARIMA(1,0,0) WITH NON-ZERO MEAN … Test  &lt;tibble [24 × 4]&gt;\n3         3 &lt;fit[+]&gt;   ETS(A,N,N)                        Test  &lt;tibble [24 × 4]&gt;\n4         4 &lt;fit[+]&gt;   PROPHET                           Test  &lt;tibble [24 × 4]&gt;\n5         5 &lt;fit[+]&gt;   LM                                Test  &lt;tibble [24 × 4]&gt;\n6         6 &lt;workflow&gt; EARTH                             Test  &lt;tibble [24 × 4]&gt;"
  },
  {
    "objectID": "Analysis/Forecasting.html#testing-set-forecast-accuracy-evaluation-1",
    "href": "Analysis/Forecasting.html#testing-set-forecast-accuracy-evaluation-1",
    "title": "Forecasting",
    "section": "6.7 Testing Set Forecast & Accuracy Evaluation",
    "text": "6.7 Testing Set Forecast & Accuracy Evaluation\n\n6.7.1 Visualising forecast test\n\ncalibration_tbl %&gt;%\n    modeltime_forecast(\n        new_data    = testing(splits),\n        actual_data = weatherdata_rf\n    ) %&gt;%\n    plot_modeltime_forecast(\n      .legend_max_width = 25\n    )\n\n\n\n\n\n\n\n6.7.2 Accuracy Metrics\n\ncalibration_tbl %&gt;%\n    modeltime_accuracy() %&gt;%\n    table_modeltime_accuracy()"
  },
  {
    "objectID": "Analysis/Forecasting.html#refit-to-full-dataset-and-forecast-forward-1",
    "href": "Analysis/Forecasting.html#refit-to-full-dataset-and-forecast-forward-1",
    "title": "Forecasting",
    "section": "6.8 Refit to full dataset and forecast forward",
    "text": "6.8 Refit to full dataset and forecast forward\n\nrefit_tbl &lt;- calibration_tbl %&gt;%\n    modeltime_refit(data = weatherdata_rf)\n\nrefit_tbl %&gt;%\n    modeltime_forecast(h = \"36 months\", actual_data = weatherdata_rf) %&gt;%\n    plot_modeltime_forecast(\n      .legend_max_width = 25)"
  },
  {
    "objectID": "Analysis/Forecasting.html#removing-anomalies",
    "href": "Analysis/Forecasting.html#removing-anomalies",
    "title": "Forecasting",
    "section": "6.9 Removing anomalies",
    "text": "6.9 Removing anomalies\n\nanomalize_tbl &lt;- weatherdata %&gt;%\n  group_by(station) %&gt;%\n  anomalize(\n    .date_var = DATE,\n    .value = monthly_rainfall,\n    .iqr_alpha = 0.05,\n    .max_anomalies = 0.20,\n    .message = FALSE\n  )\n\nglimpse(anomalize_tbl)\n\nRows: 1,548\nColumns: 13\nGroups: station [13]\n$ station           &lt;chr&gt; \"Admiralty\", \"Admiralty\", \"Admiralty\", \"Admiralty\", …\n$ DATE              &lt;date&gt; 2014-01-01, 2014-02-01, 2014-03-01, 2014-04-01, 201…\n$ observed          &lt;dbl&gt; 98.8000, 15.8000, 120.0000, 261.4000, 301.0000, 196.…\n$ season            &lt;dbl&gt; -61.968335, 5.379484, -3.716316, 57.531905, -24.3441…\n$ trend             &lt;dbl&gt; 141.0973, 155.1798, 169.2622, 180.8267, 192.3911, 20…\n$ remainder         &lt;dbl&gt; 19.6710109, -144.7592543, -45.5458998, 23.0414366, 1…\n$ seasadj           &lt;dbl&gt; 160.76834, 10.42052, 123.71632, 203.86810, 325.34418…\n$ anomaly           &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ anomaly_direction &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ anomaly_score     &lt;dbl&gt; 14.471962, 149.958304, 50.744949, 17.842387, 127.754…\n$ recomposed_l1     &lt;dbl&gt; -176.51789, -95.08763, -90.10098, -17.28832, -87.599…\n$ recomposed_l2     &lt;dbl&gt; 345.1740, 426.6042, 431.5909, 504.4035, 434.0919, 46…\n$ observed_clean    &lt;dbl&gt; 98.8000, 15.8000, 120.0000, 261.4000, 301.0000, 196.…\n\n\n\nanomalize_tbl %&gt;%\n  group_by(station) %&gt;%\n  filter(station == c(\"Admiralty\", \"Ang Mo Kio\", \"Changi\")) %&gt;%\n    plot_anomalies_decomp(\n        .date_var = DATE\n    )\n\n\n\n\n\n\nanomalize_tbl %&gt;%\n  group_by(station) %&gt;%\n  filter(station == c(\"Clementi\", \"Ang Mo Kio\", \"Changi\")) %&gt;%\n  plot_anomalies(\n        DATE,\n        .facet_ncol = 3\n    )\n\n\n\n\n\n\nanomalize_tbl %&gt;%\n    group_by(station) %&gt;%\n   filter(station == c(\"Admiralty\", \"Ang Mo Kio\", \"Changi\")) %&gt;%\n    plot_anomalies_cleaned(\n        DATE,\n        .facet_ncol = 2\n    )"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Finley Malloc",
    "section": "",
    "text": "University of California, San Diego | San Diego, CA PhD in Mathematics | Sept 2011 - June 2015\nMacalester College | St. Paul MA B.A in Economics | Sept 2007 - June 2011"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Finley Malloc",
    "section": "",
    "text": "Wengo Analytics | Head Data Scientist | April 2018 - present\nGeoScynce | Chief Analyst | Sept 2012 - April 2018"
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Rain or Shine: Unveiling The Mysteries of Singapore Weather",
    "section": "",
    "text": "Introduction\n\n\n1. The Motivation\nAs a small, low-lying city-state, Singapore is vulnerable to the effects of climate change which has brought about more extreme weather patterns - rising sea levels, dry spells and intense rainfall which at times can lead to flash floods.\n\nAccording to an infographic above by the National Climate Change Secretariat Singapore:\n\nDaily mean temperatures are projected to increase by 1.4 to 4.6 degrees celsius; and\nThe contrast between the wet months (November to January) and dry months (February and June to September) is likely to be more pronounced.\n\nIn Jan 2024, the Centre for Climate Research Singapore (CCRS) announced the Third National Climate Change Study (V3) which provided potential scenarios of our future based on low, medium, and high global greenhouse gas emissions.\n\nVery hot days will become more frequent.\nExtreme daily rainfall is projected to intensify.\nThe mean sea level around Singapore is projected to rise up to 1.15m by end century, and up to around 2m by 2150 under the high emissions scenario.\n\nIt is important that we better understand how climate change has been affecting Singapore, by understanding the trends in our daily temperatures and rainfall over the years, and utilise historical data to forecast future climate data. It will provide guidance on whether and how Singapore will need to urgently develop ways to mitigate and adapt.\n\n\n2. Objectives\nOur group utilised data from weather.gov.sg to carry out the analysis of temperature and rainfall over a 10-year period from 2014 to 2023 and across 13 different weather stations. Our aim was to:\n\nUnderstand the trend of mean, maximum, minimum temperature and rainfall across the years, months and weather stations.\nUnderstand if the changes, if any, in mean, maximum, minimum temperature and rainfall across the years were statistically significant.\nUnderstand if certain months were drier or wetter/hotter or cooler than others.\nUnderstand if certain locations (weather stations) were drier or wetter/hotter or cooler than others.\nTo conduct a time-series forecasting of temperature and rainfall in the next 10 years\n\n\n\n3. The Application\nThe group showcased our discoveries through our Shiny Application to enable users such as analysts and policymakers to grasp the impacts of climate change on Singapore. Users can gain insights from the historical trends of temperatures and rainfall, and the forecasts of our future climate conditions."
  },
  {
    "objectID": "index.html#group-12---rain-or-shine-unveiling-the-mysteries-of-singapore-weather",
    "href": "index.html#group-12---rain-or-shine-unveiling-the-mysteries-of-singapore-weather",
    "title": "Rain or Shine: Unveiling The Mysteries of Singapore Weather",
    "section": "Group 12 - Rain or Shine: Unveiling The Mysteries of Singapore Weather",
    "text": "Group 12 - Rain or Shine: Unveiling The Mysteries of Singapore Weather"
  },
  {
    "objectID": "ShinyApp/ShinyApp.html",
    "href": "ShinyApp/ShinyApp.html",
    "title": "Shiny Application",
    "section": "",
    "text": "Click on the link below for our Shiny Application:\n\n\n\n\n\nClick below for the user guide to the Shiny Application:\n\n\n&lt;p&gt;This is an embedded &lt;a target=\"_blank\" href=\"https://office.com\"&gt;Microsoft Office&lt;/a&gt; presentation, powered by &lt;a target=\"_blank\" href=\"https://office.com/webapps\"&gt;Office&lt;/a&gt;.&lt;/p&gt;"
  },
  {
    "objectID": "Analysis/Dataprep.html",
    "href": "Analysis/Dataprep.html",
    "title": "Data Preparation",
    "section": "",
    "text": "pacman::p_load(tidyverse, lubridate, DT, ggplot2, plotly, ggthemes, timetk, modeltime, tidymodels, xgboost, recipes, parsnip, earth)"
  },
  {
    "objectID": "Analysis/Dataprep.html#installing-and-launching-required-r-packages",
    "href": "Analysis/Dataprep.html#installing-and-launching-required-r-packages",
    "title": "Data Preparation",
    "section": "",
    "text": "autoplotly: to automatically generate interactive visualizations for statistical results supported by ‘ggfortify’, such as time series, PCA, clustering and survival analysis.\ndplyr: to allow for data manipulation\nDT: to provide an R interface to the JavaScript Library DataTables. R data objects can be displayed as tables on HTML pages and DataTables provides filtering, pagination, sorting and many other features in the tables.\nforecast: to display and analyse univariate time series forecasts including exponential smoothing via state space models and automatic ARIMA modelling.\nggplot2: to plot charts in order to visualise our data\nggthemes: additional themes to complete ggplot2\nggridges: to plot ridgeline plots which are useful in visualising changes in distribution over time or space\nggstatsplot: To create graphics with details from statistical tests included in the plots themselves - generate information-rich plots for statistical analysis of continuous (violin plots, scatterplots, histograms, dot plots, dot-and-whisker plots) or categorical (pie and bar charts) data.\nggiraph: to create dynamic ggplot graphs\nggfortify: Unified plotting tools for statistics commonly used, such as GLM, time series, PCA families, clustering and survival analysis. The package offers a single plotting interface for these analysis results and plots in a unified style using ‘ggplot2’.\nhrbrthemes: additional themes to complete ggplot2\nimputeTS: to allow us to impute missing values in our time series objects\nknitr: Provides a general-purpose tool for dynamic report generation in R using Literate Programming techniques.\nlubridate: to manipulate and handle date-times.\nMLmetrics: a collection of evaluation metrics, including loss, score and utility functions, that measure regression, classification and ranking performance.\nplotly: to create interactive charts to explore our data\ntidyverse: to manipulate and wrangle data\ntsbox: to allow us to handle time series as plain data frames, thus making it easy to deal with time series in a dplyr or data.table workflow.\ntseries: Time series analysis and computational finance.\nxts: provides an extensible time series class, enabling uniform handling of many R time series classes by extending zoo, which is the package that is the creator for an S3 class of indexed totally ordered observations which includes irregular time series.\n\n\n\nShow the code\npacman::p_load(autoplotly, dplyr, DT, forecast, ggplot2, ggthemes, ggridges, ggstatsplot, ggiraph, ggfortify, hrbrthemes, imputeTS, knitr, lubridate, MLmetrics, plotly,tidyverse, tsbox, tseries, xts)"
  },
  {
    "objectID": "Analysis/Dataprep.html#importing-data-into-r",
    "href": "Analysis/Dataprep.html#importing-data-into-r",
    "title": "Data Preparation",
    "section": "2. Importing Data Into R",
    "text": "2. Importing Data Into R\nWe used historical daily weather records from weather.gov.sg, and retrieved the daily records data from Jan 1980 to Dec 2023 via data.gov.sg’s API. The daily historical weather records is in csv file format.\n\n\nShow the code\ndata &lt;- read_csv(\"data/daily_historical.csv\")\nglimpse(data)\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nThere is no date but there are columns year, month and day. In addition, we also note that R read columns year, month and day as numeric data.\nThere are different columns for rainfall and temperature so we will select and filter the relevant columns that we want in subsequent steps.\nThe entire dataset daily_historical.csv is very large. We should save the filtered data into an R data format (RDS) so that we can easily retrieve it in future without importing the entire daily_historical.csv dataset again."
  },
  {
    "objectID": "Analysis/Dataprep.html#creating-a-date-column",
    "href": "Analysis/Dataprep.html#creating-a-date-column",
    "title": "Data Preparation",
    "section": "3.1 Creating a date column",
    "text": "3.1 Creating a date column\n\n\nShow the code\ndata$DATE &lt;- paste(data$year, \"-\", data$month, \"-\", data$day)\ndata &lt;- data %&gt;%\n  mutate(DATE = ymd(DATE))\n\nglimpse(data)\n\n\nRows: 329,156\nColumns: 14\n$ station                  &lt;chr&gt; \"Macritchie Reservoir\", \"Macritchie Reservoir…\n$ year                     &lt;dbl&gt; 1980, 1980, 1980, 1980, 1980, 1980, 1980, 198…\n$ month                    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ day                      &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14…\n$ daily_rainfall_total     &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 22.6, 49.6, 2.4, 0.0, 0.0…\n$ highest_30_min_rainfall  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ highest_60_min_rainfall  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ highest_120_min_rainfall &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ mean_temperature         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ maximum_temperature      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ minimum_temperature      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ mean_wind_speed          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ max_wind_speed           &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ DATE                     &lt;date&gt; 1980-01-01, 1980-01-02, 1980-01-03, 1980-01-…"
  },
  {
    "objectID": "Analysis/Dataprep.html#investigating-missing-values",
    "href": "Analysis/Dataprep.html#investigating-missing-values",
    "title": "Data Preparation",
    "section": "Investigating missing values",
    "text": "Investigating missing values\nFirst, let us use summary to have a sense of the missing data.\n\n\nShow the code\nsummary(temp)\n\n\n   station              tdate            mean_temperature maximum_temperature\n Length:329156      Min.   :1980-01-01   Min.   :22.20    Min.   :22.80      \n Class :character   1st Qu.:1997-04-29   1st Qu.:27.10    1st Qu.:30.50      \n Mode  :character   Median :2011-09-18   Median :27.90    Median :31.70      \n                    Mean   :2007-07-02   Mean   :27.87    Mean   :31.49      \n                    3rd Qu.:2017-11-27   3rd Qu.:28.80    3rd Qu.:32.60      \n                    Max.   :2023-12-31   Max.   :31.50    Max.   :38.00      \n                    NA's   :58           NA's   :255645   NA's   :255282     \n minimum_temperature\n Min.   :20.0       \n 1st Qu.:24.3       \n Median :25.2       \n Mean   :25.3       \n 3rd Qu.:26.3       \n Max.   :30.0       \n NA's   :255283     \n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nThe observations ranged from 1 Jan 1980 to 31 Dec 2023. There are 58 rows with missing dates. We should drop these rows since they are unable to tell us which day the observations were made (even if they have temperature readings).\nThere are 255,645 rows of NAs in daily mean temperature.\nThere are 255,282 rows of NAs in daily maximum temperature.\nThere are 255,283 rows of NAs in daily minimum temperature.\nWe noted that there are a lot of missing values. As the aim of this task is to forecast future temperatures, missing value treatment is not so straight-forward. Imputation using mean, median & mode might hide trends or seasonal patterns whereas removing missing data points altogether might reduce information contained in other features. Let’s understand more about the missing values before we proceed to do imputation for missing values.\n\n\n\nFirst, let us drop those rows where date is missing because we would not be able to definitively identify when the temperature(s) were collected (even if there were temperature readings for these rows.\n\n\nShow the code\ntemp &lt;- temp %&gt;%\n  drop_na(tdate)\n\nsummary(temp)\n\n\n   station              tdate            mean_temperature maximum_temperature\n Length:329098      Min.   :1980-01-01   Min.   :22.20    Min.   :22.80      \n Class :character   1st Qu.:1997-04-29   1st Qu.:27.10    1st Qu.:30.50      \n Mode  :character   Median :2011-09-18   Median :27.90    Median :31.70      \n                    Mean   :2007-07-02   Mean   :27.87    Mean   :31.49      \n                    3rd Qu.:2017-11-27   3rd Qu.:28.80    3rd Qu.:32.60      \n                    Max.   :2023-12-31   Max.   :31.50    Max.   :38.00      \n                                         NA's   :255587   NA's   :255224     \n minimum_temperature\n Min.   :20.0       \n 1st Qu.:24.3       \n Median :25.2       \n Mean   :25.3       \n 3rd Qu.:26.3       \n Max.   :30.0       \n NA's   :255225"
  },
  {
    "objectID": "Analysis/Dataprep.html#further-investigation-of-missing-temperatures-using-plotly",
    "href": "Analysis/Dataprep.html#further-investigation-of-missing-temperatures-using-plotly",
    "title": "Data Preparation",
    "section": "Further investigation of missing temperatures using plotly",
    "text": "Further investigation of missing temperatures using plotly\nWe noted that there are many weather stations in the temp dataframe. Hence, we will make use of plotly to further explore the missing temperatures.\n\nDaily Mean Temperatures\nLet us first explore the daily mean temperatures by selecting the relevant columns and pivot the dataframe wider.\n\n\nShow the code\ntemp_mean_wide &lt;- temp %&gt;%\n  select(tdate, station, mean_temperature) %&gt;%\n  pivot_wider(names_from = station, values_from = mean_temperature)\n\nsummary(temp_mean_wide)\n\n\n     tdate            Macritchie Reservoir Lower Peirce Reservoir\n Min.   :1980-01-01   Min.   : NA          Min.   : NA           \n 1st Qu.:1990-12-31   1st Qu.: NA          1st Qu.: NA           \n Median :2001-12-31   Median : NA          Median : NA           \n Mean   :2001-12-31   Mean   :NaN          Mean   :NaN           \n 3rd Qu.:2012-12-30   3rd Qu.: NA          3rd Qu.: NA           \n Max.   :2023-12-31   Max.   : NA          Max.   : NA           \n                      NA's   :16071        NA's   :16071         \n   Admiralty     East Coast Parkway   Ang Mo Kio        Newton     \n Min.   :22.50   Min.   :23.40      Min.   :22.50   Min.   :22.20  \n 1st Qu.:26.80   1st Qu.:27.50      1st Qu.:26.90   1st Qu.:26.80  \n Median :27.60   Median :28.20      Median :27.80   Median :27.70  \n Mean   :27.66   Mean   :28.13      Mean   :27.82   Mean   :27.58  \n 3rd Qu.:28.50   3rd Qu.:28.90      3rd Qu.:28.80   3rd Qu.:28.40  \n Max.   :30.80   Max.   :30.80      Max.   :31.20   Max.   :30.60  \n NA's   :10821   NA's   :10806      NA's   :10918   NA's   :11148  \n  Lim Chu Kang   Marine Parade   Choa Chu Kang (Central)   Tuas South   \n Min.   : NA     Min.   : NA     Min.   : NA             Min.   :23.10  \n 1st Qu.: NA     1st Qu.: NA     1st Qu.: NA             1st Qu.:27.40  \n Median : NA     Median : NA     Median : NA             Median :28.20  \n Mean   :NaN     Mean   :NaN     Mean   :NaN             Mean   :28.19  \n 3rd Qu.: NA     3rd Qu.: NA     3rd Qu.: NA             3rd Qu.:29.00  \n Max.   : NA     Max.   : NA     Max.   : NA             Max.   :31.00  \n NA's   :16071   NA's   :16071   NA's   :16071           NA's   :11609  \n Pasir Panjang   Jurong Island   Nicoll Highway  Botanic Garden \n Min.   :23.20   Min.   :23.40   Min.   : NA     Min.   : NA    \n 1st Qu.:27.50   1st Qu.:27.60   1st Qu.: NA     1st Qu.: NA    \n Median :28.30   Median :28.40   Median : NA     Median : NA    \n Mean   :28.25   Mean   :28.29   Mean   :NaN     Mean   :NaN    \n 3rd Qu.:29.10   3rd Qu.:29.10   3rd Qu.: NA     3rd Qu.: NA    \n Max.   :31.30   Max.   :31.10   Max.   : NA     Max.   : NA    \n NA's   :11049   NA's   :11748   NA's   :16071   NA's   :16071  \n Choa Chu Kang (South)    Whampoa          Changi       Jurong Pier   \n Min.   :22.70         Min.   : NA     Min.   :22.80   Min.   : NA    \n 1st Qu.:26.80         1st Qu.: NA     1st Qu.:26.90   1st Qu.: NA    \n Median :27.70         Median : NA     Median :27.70   Median : NA    \n Mean   :27.68         Mean   :NaN     Mean   :27.69   Mean   :NaN    \n 3rd Qu.:28.60         3rd Qu.: NA     3rd Qu.:28.60   3rd Qu.: NA    \n Max.   :31.00         Max.   : NA     Max.   :30.90   Max.   : NA    \n NA's   :11558         NA's   :16071   NA's   :731     NA's   :16071  \n   Ulu Pandan        Mandai         Tai Seng     Jurong (West)  \n Min.   : NA     Min.   : NA     Min.   :23.2    Min.   :22.20  \n 1st Qu.: NA     1st Qu.: NA     1st Qu.:27.6    1st Qu.:26.60  \n Median : NA     Median : NA     Median :28.4    Median :27.40  \n Mean   :NaN     Mean   :NaN     Mean   :28.4    Mean   :27.41  \n 3rd Qu.: NA     3rd Qu.: NA     3rd Qu.:29.3    3rd Qu.:28.30  \n Max.   : NA     Max.   : NA     Max.   :31.5    Max.   :30.60  \n NA's   :16071   NA's   :16071   NA's   :11454   NA's   :10995  \n    Clementi     Sentosa Island  Bukit Panjang   Kranji Reservoir\n Min.   :22.80   Min.   :23.00   Min.   : NA     Min.   : NA     \n 1st Qu.:26.90   1st Qu.:27.40   1st Qu.: NA     1st Qu.: NA     \n Median :27.70   Median :28.20   Median : NA     Median : NA     \n Mean   :27.63   Mean   :28.12   Mean   :NaN     Mean   :NaN     \n 3rd Qu.:28.50   3rd Qu.:28.90   3rd Qu.: NA     3rd Qu.: NA     \n Max.   :30.60   Max.   :31.10   Max.   : NA     Max.   : NA     \n NA's   :11258   NA's   :11317   NA's   :16071   NA's   :16071   \n Upper Peirce Reservoir   Kent Ridge      Queenstown    Tanjong Katong \n Min.   : NA            Min.   : NA     Min.   : NA     Min.   : NA    \n 1st Qu.: NA            1st Qu.: NA     1st Qu.: NA     1st Qu.: NA    \n Median : NA            Median : NA     Median : NA     Median : NA    \n Mean   :NaN            Mean   :NaN     Mean   :NaN     Mean   :NaN    \n 3rd Qu.: NA            3rd Qu.: NA     3rd Qu.: NA     3rd Qu.: NA    \n Max.   : NA            Max.   : NA     Max.   : NA     Max.   : NA    \n NA's   :16071          NA's   :16071   NA's   :16071   NA's   :16071  \n Somerset (Road)    Punggol          Simei         Toa Payoh    \n Min.   : NA     Min.   : NA     Min.   : NA     Min.   : NA    \n 1st Qu.: NA     1st Qu.: NA     1st Qu.: NA     1st Qu.: NA    \n Median : NA     Median : NA     Median : NA     Median : NA    \n Mean   :NaN     Mean   :NaN     Mean   :NaN     Mean   :NaN    \n 3rd Qu.: NA     3rd Qu.: NA     3rd Qu.: NA     3rd Qu.: NA    \n Max.   : NA     Max.   : NA     Max.   : NA     Max.   : NA    \n NA's   :16071   NA's   :16071   NA's   :16071   NA's   :16071  \n      Tuas        Bukit Timah    Pasir Ris (Central)\n Min.   : NA     Min.   : NA     Min.   : NA        \n 1st Qu.: NA     1st Qu.: NA     1st Qu.: NA        \n Median : NA     Median : NA     Median : NA        \n Mean   :NaN     Mean   :NaN     Mean   :NaN        \n 3rd Qu.: NA     3rd Qu.: NA     3rd Qu.: NA        \n Max.   : NA     Max.   : NA     Max.   : NA        \n NA's   :16071   NA's   :16071   NA's   :16071      \n\n\nWe will make use of plotly to explore the missing daily temperatures for each station using a dropdown list.\n\n\nShow the code\nplot_ly(data = temp_mean_wide, \n        x = ~tdate, \n        y = ~ Admiralty, \n        type = \"scatter\", \n        mode = \"lines\") |&gt; \n  layout(title = \"Temperature observed by Weather Stations\", \n       xaxis = list(title = \"Date\"), \n       yaxis = list(title = \"\", range = c(0,40)), \n      theme_ipsum_rc(plot_title_size = 13, plot_title_margin=4, subtitle_size=11, subtitle_margin=4,  \n                 axis_title_size = 8, axis_text_size=8, axis_title_face= \"bold\", plot_margin = margin(4, 4, 4, 4)),  \n       updatemenus = list(list(type = 'dropdown', \n                               xref = \"paper\", \n                               yref = \"paper\", \n                               xanchor = \"left\",\n                               x = 0.04,\n                               y = 0.95, \n                               buttons = list(\n                                 list(method = \"update\",\n                                      args = list(list(y = list(temp_mean_wide$Admiralty)), \n                                                    list(yaxis = list(title = \"Temperature in Admiralty\", range = c(0,40)))),label = \"Admiralty\"),\n                                 list(method = \"update\",\n                                      args = list(list(y = list(temp_mean_wide$`East Coast Parkway`)), \n                                                    list(yaxis = list(title = \"Temperature in East Coast Parkway\", range = c(0,40)))),label = \"East Coast Parkway\"), \n                                 list(method = \"update\",\n                                      args = list(list(y = list(temp_mean_wide$`Ang Mo Kio`)), \n                                                    list(yaxis = list(title = \"Temperature in Ang Mo Kio\", range = c(0,40)))),label = \"Ang Mo Kio\"), \n                                 list(method = \"update\",\n                                      args = list(list(y = list(temp_mean_wide$Newton)), \n                                                    list(yaxis = list(title = \"Temperature in Newton\", range = c(0,40)))),label = \"Newton\"), \n                                 list(method = \"update\",\n                                      args = list(list(y = list(temp_mean_wide$`Tuas South`)), \n                                                    list(yaxis = list(title = \"Temperature in Tuas South\", range = c(0,40)))),label = \"Tuas South\"),\n                                  list(method = \"update\",\n                                      args = list(list(y = list(temp_mean_wide$`Pasir Panjang`)), \n                                                    list(yaxis = list(title = \"Temperature in Pasir Panjang\", range = c(0,40)))),label = \"Pasir Panjang\"), \n                                  list(method = \"update\",\n                                      args = list(list(y = list(temp_mean_wide$`Jurong Island`)), \n                                                    list(yaxis = list(title = \"Temperature in Jurong Island\", range = c(0,40)))),label = \"Jurong Island\"), \n                                 list(method = \"update\",\n                                      args = list(list(y = list(temp_mean_wide$`Choa Chu Kang (South)`)), \n                                                    list(yaxis = list(title = \"Temperature in Choa Chu Kang (South)\", range = c(0,40)))),label = \"Choa Chu Kang (South)\"), \n                                 list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$Changi)), \n                                                    list(yaxis = list(title = \"Temperature in Changi\", range = c(0,40)))),label = \"Changi\"),\n                                  list(method = \"update\",\n                                      args = list(list(y = list(temp_mean_wide$`Tai Seng`)), \n                                                    list(yaxis = list(title = \"Temperature in Tai Seng\", range = c(0,40)))),label = \"Tai Seng\"),\n                                  list(method = \"update\",\n                                      args = list(list(y = list(temp_mean_wide$`Jurong (West)`)), \n                                                    list(yaxis = list(title = \"Temperature in Jurong West\", range = c(0,40)))),label = \"Jurong West\"), \n                                   list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$Clementi)), \n                                                    list(yaxis = list(title = \"Temperature  in Clementi\", range = c(0,40)))),label = \"Clementi\"), \n                                   list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$`Sentosa Island`)), \n                                                    list(yaxis = list(title = \"Temperature  in Sentosa\", range = c(0,40)))),label = \"Sentosa\"), \n                                 list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$`Macritchie Reservoir`)), \n                                                    list(yaxis = list(title = \"Temperature  at Macritchie Reservoir\", range = c(0,40)))),label = \"Macritchie Reservoir\"), \n                                list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$`Lower Peirce Reservoir`)), \n                                                    list(yaxis = list(title = \"Temperature  at Lower Peirce Reservoir\", range = c(0,40)))),label = \"Lower Peirce Reservoir\"),\n                                 list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$`Lim Chu Kang`)), \n                                                    list(yaxis = list(title = \"Temperature at Lim Chu Kang\", range = c(0,40)))),label = \"Lim Chu Kang\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$`Marine Parade`)), \n                                                    list(yaxis = list(title = \"Temperature at Marine Parade\", range = c(0,40)))),label = \"Marine Parade\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$`Choa Chu Kang (Central)`)), \n                                                    list(yaxis = list(title = \"Temperature at Choa Chu Kang (Central)\", range = c(0,40)))),label = \"Choa Chu Kang (Central)\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$`Choa Chu Kang (Central)`)), \n                                                    list(yaxis = list(title = \"Temperature at Choa Chu Kang (Central)\", range = c(0,40)))),label = \"Choa Chu Kang (Central)\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$`Nicoll Highway`)), \n                                                    list(yaxis = list(title = \"Temperature at Nicoll Highway\", range = c(0,40)))),label = \"Nicoll Highway\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$`Botanic Garden`)), \n                                                    list(yaxis = list(title = \"Temperature at Botanic Garden\", range = c(0,40)))),label = \"Botanic Garden\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$Whampoa)), \n                                                    list(yaxis = list(title = \"Temperature at Whampoa\", range = c(0,40)))),label = \"Whampoa\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$`Jurong Pier`)), \n                                                    list(yaxis = list(title = \"Temperature at Jurong Pier\", range = c(0,40)))),label = \"Jurong Pier\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$`Ulu Pandan`)), \n                                                    list(yaxis = list(title = \"Temperature at Ulu Pandan\", range = c(0,40)))),label = \"Ulu Pandan\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$Mandai)), \n                                                    list(yaxis = list(title = \"Temperature at Mandai\", range = c(0,40)))),label = \"Mandai\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$`Bukit Panjang`)), \n                                                    list(yaxis = list(title = \"Temperature at Bukit Panjang\", range = c(0,40)))),label = \"Bukit Panjang\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$`Kranji Reservoir`)), \n                                                    list(yaxis = list(title = \"Temperature at Kranji Reservoir\", range = c(0,40)))),label = \"Kranji Reservoir\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$`Upper Peirce Reservoir`)), \n                                                    list(yaxis = list(title = \"Temperature at Upper Peirce Reservoir\", range = c(0,40)))),label = \"Upper Peirce Reservoir\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$`Kent Ridge`)), \n                                                    list(yaxis = list(title = \"Temperature at Kent Ridge\", range = c(0,40)))),label = \"Kent Ridge\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$Queenstown)), \n                                                    list(yaxis = list(title = \"Temperature at Queenstown\", range = c(0,40)))),label = \"Queenstown\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$`Tanjong Katong`)), \n                                                    list(yaxis = list(title = \"Temperature at Tanjong Katong\", range = c(0,40)))),label = \"Tanjong Katong\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$`Somerset (Road)`)), \n                                                    list(yaxis = list(title = \"Temperature at Somerset (Road)\", range = c(0,40)))),label = \"Somerset (Road)\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$`Punggol`)), \n                                                    list(yaxis = list(title = \"Temperature at Punggol\", range = c(0,40)))),label = \"Punggol\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$`Simei`)), \n                                                    list(yaxis = list(title = \"Temperature at Simei\", range = c(0,40)))),label = \"Simei\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$`Toa Payoh`)), \n                                                    list(yaxis = list(title = \"Temperature at Toa Payoh\", range = c(0,40)))),label = \"Toa Payoh\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$`Tuas`)), \n                                                    list(yaxis = list(title = \"Temperature at Tuas\", range = c(0,40)))),label = \"Tuas\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$`Bukit Timah`)), \n                                                    list(yaxis = list(title = \"Temperature at Bukit Timah\", range = c(0,40)))),label = \"Bukit Timah\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_wide$`Pasir Ris (Central)`)), \n                                                    list(yaxis = list(title = \"Temperature at Pasir Ris (Central)\", range = c(0,40)))),label = \"Pasir Ris (Central)\")\n                               ))))  \n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nIt seems like there are some weather stations with no temperature data at all. We should remove them from the temp dataframe.\nThere are some weather stations (e.g. Admiralty) have temperature data only from a certain year onwards (e.g. 2009), and some stations (e.g. Changi) have temperature data as early as 1980s.\nFor those weather stations with temperature data, they also have missing values over a given time period. So we will need to decide how to handle these missing values in subsequent sections.\n\n\n\nLet us identify the amount of missing values for each weather station using the following code chunk.\n\n\nShow the code\nmissing_values &lt;- temp_mean_wide %&gt;%\n  gather(key = \"key\", value = \"val\") %&gt;%\n  mutate(isna = is.na(val)) %&gt;%\n  group_by(key) %&gt;%\n  mutate(total = n()) %&gt;%\n  group_by(key, total, isna) %&gt;%\n  summarise(num.isna = n()) %&gt;%\n  mutate(pct = num.isna / total * 100)\n\nlevels &lt;-\n    (missing_values  %&gt;% filter(isna == T) %&gt;% arrange(desc(pct)))$key\n\npercentage_plot &lt;- missing_values %&gt;%\n      ggplot() +\n        geom_bar(aes(x = reorder(key, desc(pct)), \n                     y = pct, fill=isna), \n                 stat = 'identity', alpha=0.8) +\n      scale_x_discrete(limits = levels) +\n      scale_fill_manual(name = \"\", \n                        values = c('steelblue', 'tomato3'), labels = c(\"Present\", \"Missing\")) +\n      coord_flip() +\n      labs(title = \"Percentage of missing values\", x =\n             'Variable', y = \"% of missing values\")\n\npercentage_plot\n\n\n\n\n\n\n\n\n\nThe above output is consistent with what we observed when exploring the data using plotly. There are numerous stations without temperature readings throughout all years and there are certain stations with temperature readings during certain time periods.\nLet us find out which stations that have no temperature readings throughout the entire time period using filter().We will filter out those weather stations that have 100% NAs.\n\n\nShow the code\nnotempdata &lt;- missing_values %&gt;%\n  filter(isna == TRUE & pct==100)\n\nnotempdata$key\n\n\n [1] \"Botanic Garden\"          \"Bukit Panjang\"          \n [3] \"Bukit Timah\"             \"Choa Chu Kang (Central)\"\n [5] \"Jurong Pier\"             \"Kent Ridge\"             \n [7] \"Kranji Reservoir\"        \"Lim Chu Kang\"           \n [9] \"Lower Peirce Reservoir\"  \"Macritchie Reservoir\"   \n[11] \"Mandai\"                  \"Marine Parade\"          \n[13] \"Nicoll Highway\"          \"Pasir Ris (Central)\"    \n[15] \"Punggol\"                 \"Queenstown\"             \n[17] \"Simei\"                   \"Somerset (Road)\"        \n[19] \"Tanjong Katong\"          \"Toa Payoh\"              \n[21] \"Tuas\"                    \"Ulu Pandan\"             \n[23] \"Upper Peirce Reservoir\"  \"Whampoa\"                \n\n\nFrom the above output, we know that these 24 weather stations have no temperature readings. We will put them into a list and create an operator to exclude them from the temp data using filter().\n\n\nShow the code\nstationstoremove &lt;- c(\"Botanic Garden\",\"Bukit Panjang\",\"Bukit Timah\",\"Choa Chu Kang (Central)\",\"Jurong Pier\",\"Kent Ridge\", \"Kranji Reservoir\", \"Lim Chu Kang\", \"Lower Peirce Reservoir\", \"Macritchie Reservoir\",\"Mandai\", \"Marine Parade\",\"Nicoll Highway\", \"Pasir Ris (Central)\", \"Punggol\", \"Queenstown\",\"Simei\", \"Somerset (Road)\",\"Tanjong Katong\", \"Toa Payoh\", \"Tuas\", \"Ulu Pandan\", \"Upper Peirce Reservoir\",\"Whampoa\")\n\n#create a operator to exclude things \n'%!in%' &lt;- function(x,y)!('%in%'(x,y))\n\n#excluded stations that have no temp data at all \ntemp_clean &lt;- temp %&gt;%\n  filter(station %!in% stationstoremove)\n\nglimpse(temp_clean)\n\n\nRows: 120,139\nColumns: 5\n$ station             &lt;chr&gt; \"Admiralty\", \"Admiralty\", \"Admiralty\", \"Admiralty\"…\n$ tdate               &lt;date&gt; 2009-01-01, 2009-01-02, 2009-01-03, 2009-01-04, 2…\n$ mean_temperature    &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ maximum_temperature &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ minimum_temperature &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\nShow the code\n#write it into RDS for future usage, esp when building \nwrite_rds(temp_clean, \"data/temp_clean.rds\")\n\n\n\nunique(temp_clean$station)\n\n [1] \"Admiralty\"             \"East Coast Parkway\"    \"Ang Mo Kio\"           \n [4] \"Newton\"                \"Tuas South\"            \"Pasir Panjang\"        \n [7] \"Jurong Island\"         \"Choa Chu Kang (South)\" \"Changi\"               \n[10] \"Tai Seng\"              \"Jurong (West)\"         \"Clementi\"             \n[13] \"Sentosa Island\"       \n\n\nWe will then pivot the temp_clean dataframe wider and plot the daily temperature for the remaining weather stations using plotly.\n\n\nShow the code\ntemp_mean_widec &lt;- temp_clean %&gt;%\n  select(tdate, station, mean_temperature) %&gt;%\n  pivot_wider(names_from = station, values_from = mean_temperature)\n\nglimpse(temp_mean_widec)\n\n\nRows: 16,071\nColumns: 14\n$ tdate                   &lt;date&gt; 2009-01-01, 2009-01-02, 2009-01-03, 2009-01-0…\n$ Admiralty               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ `East Coast Parkway`    &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ `Ang Mo Kio`            &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ Newton                  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ `Tuas South`            &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ `Pasir Panjang`         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ `Jurong Island`         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ `Choa Chu Kang (South)` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ Changi                  &lt;dbl&gt; 26.6, 26.4, 26.5, 26.3, 27.0, 27.4, 27.1, 27.0…\n$ `Tai Seng`              &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ `Jurong (West)`         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ Clementi                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ `Sentosa Island`        &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\n\n\nShow the code\nplot_ly(data = temp_mean_widec, \n        x = ~tdate, \n        y = ~ Admiralty, \n        type = \"scatter\", \n        mode = \"lines+markers\") |&gt; \n  layout(title = \"Temperature observed by Weather Station\", \n       xaxis = list(title = \"Date\"), \n       yaxis = list(title = \"\", range = c(0,40)), \n      theme_ipsum_rc(plot_title_size = 13, plot_title_margin=4, subtitle_size=11, subtitle_margin=4,  \n                 axis_title_size = 8, axis_text_size=8, axis_title_face= \"bold\", plot_margin = margin(4, 4, 4, 4)),  \n       updatemenus = list(list(type = 'dropdown', \n                               xref = \"paper\", \n                               yref = \"paper\", \n                               xanchor = \"left\",\n                               x = 0.04,\n                               y = 0.95, \n                               buttons = list(\n                                 list(method = \"update\",\n                                      args = list(list(y = list(temp_mean_widec$Admiralty)), \n                                                    list(yaxis = list(title = \"Temperature in Admiralty\", range = c(0,40)))),label = \"Admiralty\"),\n                                 list(method = \"update\",\n                                      args = list(list(y = list(temp_mean_widec$`East Coast Parkway`)), \n                                                    list(yaxis = list(title = \"Temperature in East Coast Parkway\", range = c(0,40)))),label = \"East Coast Parkway\"), \n                                 list(method = \"update\",\n                                      args = list(list(y = list(temp_mean_widec$`Ang Mo Kio`)), \n                                                    list(yaxis = list(title = \"Temperature in Ang Mo Kio\", range = c(0,40)))),label = \"Ang Mo Kio\"), \n                                 list(method = \"update\",\n                                      args = list(list(y = list(temp_mean_widec$Newton)), \n                                                    list(yaxis = list(title = \"Temperature in Newton\", range = c(0,40)))),label = \"Newton\"), \n                                 list(method = \"update\",\n                                      args = list(list(y = list(temp_mean_widec$`Tuas South`)), \n                                                    list(yaxis = list(title = \"Temperature in Tuas South\", range = c(0,40)))),label = \"Tuas South\"),\n                                  list(method = \"update\",\n                                      args = list(list(y = list(temp_mean_widec$`Pasir Panjang`)), \n                                                    list(yaxis = list(title = \"Temperature in Pasir Panjang\", range = c(0,40)))),label = \"Pasir Panjang\"), \n                                  list(method = \"update\",\n                                      args = list(list(y = list(temp_mean_widec$`Jurong Island`)), \n                                                    list(yaxis = list(title = \"Temperature in Jurong Island\", range = c(0,40)))),label = \"Jurong Island\"), \n                                 list(method = \"update\",\n                                      args = list(list(y = list(temp_mean_widec$`Choa Chu Kang (South)`)), \n                                                    list(yaxis = list(title = \"Temperature in Choa Chu Kang\", range = c(0,40)))),label = \"Choa Chu Kang\"), \n                                 list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_widec$Changi)), \n                                                    list(yaxis = list(title = \"Temperature in Changi\", range = c(0,40)))),label = \"Changi\"),\n                                  list(method = \"update\",\n                                      args = list(list(y = list(temp_mean_widec$`Tai Seng`)), \n                                                    list(yaxis = list(title = \"Temperature in Tai Seng\", range = c(0,40)))),label = \"Tai Seng\"),\n                                  list(method = \"update\",\n                                      args = list(list(y = list(temp_mean_widec$`Jurong (West)`)), \n                                                    list(yaxis = list(title = \"Temperature in Jurong West\", range = c(0,40)))),label = \"Jurong West\"), \n                                   list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_widec$Clementi)), \n                                                    list(yaxis = list(title = \"Temperature  in Clementi\", range = c(0,40)))),label = \"Clementi\"), \n                                   list(method = \"update\", \n                                        args = list(list(y = list(temp_mean_widec$`Sentosa Island`)), \n                                                    list(yaxis = list(title = \"Temperature  in Sentosa\", range = c(0,40)))),label = \"Sentosa\")\n                                   \n                               ))))  \n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nFrom the above interactive chart, we note that some stations have a longer time period with temperature readings (e.g. Changi). Almost all stations have some missing time gaps/ values in the data, hence we will need to do imputation for this missing values to ensure better accuracy of our temperature forecasting.\nAlso, we noted that daily temperature readings that range more than 20 years is too frequent for time series forecasting. Hence, we will aggregate the daily temperature readings to monthly temperature readings by calculating the mean in subsequent section."
  },
  {
    "objectID": "Analysis/Dataprep.html#creating-time-series-object",
    "href": "Analysis/Dataprep.html#creating-time-series-object",
    "title": "Data Preparation",
    "section": "Creating Time Series Object",
    "text": "Creating Time Series Object\nIn the previous sections, we noted that the dataframes were all tibble dataframes. For us to make use of the time series forecasting packages and their functions, we would need to convert the tibble dataframe into a time series object.\nBefore we create the time series object, let us first aggregate the daily temperature readings to monthly temperature readings by (1) creating the year-month column for each observation using floor_date() and specifying it to derive the year and month of each observation, and (2) aggregate the temperature readings by station and year_month then use summarise() to compute the monthly averages for mean_temperature, maximum_temperature and minimum_temperature.\n\n\nShow the code\n#create year-month col\ntemp_clean$year_month &lt;- floor_date(temp_clean$tdate, \"month\")\nglimpse(temp_clean)\n\n\nRows: 120,139\nColumns: 6\n$ station             &lt;chr&gt; \"Admiralty\", \"Admiralty\", \"Admiralty\", \"Admiralty\"…\n$ tdate               &lt;date&gt; 2009-01-01, 2009-01-02, 2009-01-03, 2009-01-04, 2…\n$ mean_temperature    &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ maximum_temperature &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ minimum_temperature &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ year_month          &lt;date&gt; 2009-01-01, 2009-01-01, 2009-01-01, 2009-01-01, 2…\n\n\n\n\nShow the code\nmonthly_temp &lt;- temp_clean %&gt;%                         \n  group_by(station, year_month) %&gt;% \n  summarise(across(c(mean_temperature, maximum_temperature, minimum_temperature), mean))\n\nglimpse(monthly_temp)\n\n\nRows: 3,947\nColumns: 5\nGroups: station [13]\n$ station             &lt;chr&gt; \"Admiralty\", \"Admiralty\", \"Admiralty\", \"Admiralty\"…\n$ year_month          &lt;date&gt; 2009-01-01, 2009-02-01, 2009-03-01, 2009-04-01, 2…\n$ mean_temperature    &lt;dbl&gt; NA, 26.76786, NA, 28.12000, 28.48387, 28.89667, 28…\n$ maximum_temperature &lt;dbl&gt; NA, 31.44286, NA, 32.19667, 32.59032, 32.87000, 31…\n$ minimum_temperature &lt;dbl&gt; NA, 24.26071, NA, 25.06667, 25.09355, 25.95000, 25…\n\n\nShow the code\nwrite_rds(monthly_temp, \"data/monthly_temp.rds\")\n\n\nWith the monthly temperature of all weather stations, let us filter out one weather station (e.g. Admiralty) to create a tibble data frame adm so that we can convert it into an xts object, which is a type of time series object.\n\n\nShow the code\nmonthly_temp &lt;- read_rds(\"data/monthly_temp.rds\")\n\n#filter out Admiralty weather station \nadm &lt;- monthly_temp %&gt;%\n  filter(station == \"Admiralty\")\n\n#check the resultant dataframe\nsummary(adm)\n\n\n   station            year_month         mean_temperature maximum_temperature\n Length:179         Min.   :2009-01-01   Min.   :25.61    Min.   :28.86      \n Class :character   1st Qu.:2012-09-16   1st Qu.:27.10    1st Qu.:31.33      \n Mode  :character   Median :2016-07-01   Median :27.74    Median :31.85      \n                    Mean   :2016-06-19   Mean   :27.68    Mean   :31.83      \n                    3rd Qu.:2020-03-16   3rd Qu.:28.29    3rd Qu.:32.45      \n                    Max.   :2023-12-01   Max.   :29.15    Max.   :33.87      \n                                         NA's   :22       NA's   :18         \n minimum_temperature\n Min.   :23.63      \n 1st Qu.:24.52      \n Median :24.92      \n Mean   :24.98      \n 3rd Qu.:25.46      \n Max.   :26.45      \n NA's   :18         \n\n\nWe will use xts() from xts package to create a time series object. The order.by parameter uses the dates from the adm dataframe. We then use the ts_regular() function to give the time series object adm_xts a regular interval by adding NA values for missing dates.\nJust in case there are missing months which we did not detected, we use the na.fill() function fills in those missing dates by extending values from previous days.\n\n\nShow the code\nadm_xts &lt;- xts(adm[,c(\"mean_temperature\", \"maximum_temperature\", \"minimum_temperature\")], order.by=as.Date(adm$year_month))\nadm_xts&lt;- ts_regular(adm_xts)\nadm_xts &lt;- na.fill(adm_xts, \"extend\")\n\n\nLet us plot out the monthly mean temperature of Admiralty weather station using ggplotly.\n\n\nShow the code\np1 &lt;- ggplot(adm_xts, aes(x = Index, y = mean_temperature)) + \n  geom_line() + theme_clean() +\n  labs(title = \"Monthly Mean Temperature of Admiralty Weather Station\", caption = \"Data from Weather.gov.sg\") +\n  xlab(\"Month-Year\") +\n  ylab(\"Temperature in degrees celsius\") +\n  theme_ipsum_rc()\n\nggplotly(p1)\n\n\n\n\n\n\nFrom the above output, we see that there are missing temperatures for numerous time periods. As a result, the line for the above chart is not continuous.\nLet us investigate further using imputeTS package’s ggplot_na_distribution, which highlights the missing values in our data. For the following example, we focus on the mean temperature of the adm time series object.\n\n\nShow the code\nggplot_na_distribution(x = adm$mean_temperature,\n                       x_axis_labels = adm$year_month,\n                       ylab = \"Temperature in degrees celsius\")\n\n\n\n\n\n\n\n\n\nWe also use the imputeTS package’s statsNA to have a report on the number of missing mean temperature readings.\n\n\nShow the code\nstatsNA(adm_xts$mean_temperature)\n\n\n[1] \"Length of time series:\"\n[1] 180\n[1] \"-------------------------\"\n[1] \"Number of Missing Values:\"\n[1] 23\n[1] \"-------------------------\"\n[1] \"Percentage of Missing Values:\"\n[1] \"12.8%\"\n[1] \"-------------------------\"\n[1] \"Number of Gaps:\"\n[1] 12\n[1] \"-------------------------\"\n[1] \"Average Gap Size:\"\n[1] 1.916667\n[1] \"-------------------------\"\n[1] \"Stats for Bins\"\n[1] \"  Bin 1 (45 values from 1 to 45) :      3 NAs (6.67%)\"\n[1] \"  Bin 2 (45 values from 46 to 90) :      4 NAs (8.89%)\"\n[1] \"  Bin 3 (45 values from 91 to 135) :      11 NAs (24.4%)\"\n[1] \"  Bin 4 (45 values from 136 to 180) :      5 NAs (11.1%)\"\n[1] \"-------------------------\"\n[1] \"Longest NA gap (series of consecutive NAs)\"\n[1] \"6 in a row\"\n[1] \"-------------------------\"\n[1] \"Most frequent gap size (series of consecutive NA series)\"\n[1] \"1 NA in a row (occurring 7 times)\"\n[1] \"-------------------------\"\n[1] \"Gap size accounting for most NAs\"\n[1] \"1 NA in a row (occurring 7 times, making up for overall 7 NAs)\"\n[1] \"-------------------------\"\n[1] \"Overview NA series\"\n[1] \"  1 NA in a row: 7 times\"\n[1] \"  2 NA in a row: 2 times\"\n[1] \"  3 NA in a row: 2 times\"\n[1] \"  6 NA in a row: 1 times\"\n\n\n\nMissing Value Imputation\nThere are several ways to impute missing data in time series objects. We need to impute missing values because some of the models cannot handle NAs in Time Series objects.\n\nMoving Averages\nAs this function calculates moving averages based on the last n observations, it will generally be performing better than using mean, mode and median imputation. Moving averages work well when data has a linear trend. This function also allows us to use linear-weighted and exponentially-weighted moving averages.\n\n\nShow the code\nadm_imp_movingavg &lt;- na_ma(adm_xts, weighting = \"exponential\") #default is exponential. Other options are \"simple\" and \"linear\". We can allow users to choose if the option they want. \n\n#plot chart \n#ggplot(adm_imp_movingavg, aes(x = Index, y = mean_temperature)) + \n  #geom_line()\n\nplot_ma&lt;- ggplot(adm_imp_movingavg, aes(x = Index, y = mean_temperature)) + \n  geom_line() + theme_clean() +\n  labs(title = \"Monthly Mean Temperature of Admiralty Weather Station \\n(missing values imputed using moving average)\") +\n  xlab(\"Month-Year\") +\n  ylab(\"Temperature in degrees celsius\") +\n  theme_ipsum_rc()\n\nggplotly(plot_ma)\n\n\n\n\n\n\n\n\nKalman smoothing\nWe can also use Kalman Smoothing on ARIMA model to impute the missing values.\n\n\nShow the code\nadm_imp_kalman &lt;- na_kalman(adm_xts, model = \"auto.arima\")\n\n#plot chart \n\nggplot(adm_imp_kalman, aes(x = Index, y = mean_temperature)) + \n  geom_line()\n\n\n\n\n\n\n\n\n\nFrom the above output, we see that some of the imputed values are below 0 degrees celsius which is impossible in Singapore. As such, we will not be using this method to impute missing values for temperature readings.\nKalman Smoothing also has a “StrucTS” option. Let us try and see how it works for our temperature data.\n\n\nShow the code\nadm_imp_kalman_ts &lt;- na_kalman(adm_xts, model = \"StructTS\")\n\n#plot chart \n\nggplot(adm_imp_kalman_ts, aes(x = Index, y = mean_temperature)) + \n  geom_line()\n\n\n\n\n\n\n\n\n\nFrom the above output, it seems like using the “StrucTS” model works better than auto.arima model since the imputed results were reasonable. Again, we can also let users choose which model they want to use."
  },
  {
    "objectID": "Analysis/Dataprep.html#testing-if-the-time-series-is-stationary",
    "href": "Analysis/Dataprep.html#testing-if-the-time-series-is-stationary",
    "title": "Data Preparation",
    "section": "Testing if the time series is stationary",
    "text": "Testing if the time series is stationary\nBefore we model the time series forecasting model, let us test is our time series data is stationary. Stationarity signifies that the statistical properties of time series, such as mean, variance, and covariance, remain constant over time, which is the fundamental assumption for many time series modeling techniques.It simplifies the complex dynamics within the data, making it more amenable to analysis, modeling, and forecasting.\nThere are two tests we are use to test for stationarity: - Augmented Dickey-Fuller (ADF) Test; and - Kwiatkowski-Phillips-Schmidt-Shin (KPSS) Test\n\nAugmented Dickey-Fuller Test\nNull Hypothesis: Series is non-stationary, or series has a unit root. Alternative Hypothesis: Series is stationary, or series has no unit root.\nIf the null hypothesis fails to be rejected, this test may provide evidence that the series is non-stationary.\n\n\nShow the code\nadf.test(adm_imp_movingavg$mean_temperature)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  adm_imp_movingavg$mean_temperature\nDickey-Fuller = -7.3405, Lag order = 5, p-value = 0.01\nalternative hypothesis: stationary\n\n\nSince the p-value is 0.01, which is less than critical value of 0.05, we reject the null hypothesis. This means that the time series does not have a unit root, meaning it is stationary. It does not have a time-dependent structure.\n\n\nKwiatkowski-Phillips-Schmidt-Shin Test\nNull Hypothesis: Series is trend stationary or series has no unit root. Alternative Hypothesis: Series is non-stationary, or series has a unit root.\n\n\n\n\n\n\nNote\n\n\n\nNote: The hypothesis is reversed in the KPSS test compared to ADF Test.\n\n\n\n\nShow the code\nkpss.test(adm_imp_movingavg$mean_temperature)\n\n\n\n    KPSS Test for Level Stationarity\n\ndata:  adm_imp_movingavg$mean_temperature\nKPSS Level = 0.086074, Truncation lag parameter = 4, p-value = 0.1\n\n\nSince the p-value is 0.1, which is greater than the critical value of 0.05, we fail to reject the null hypothesis of the KPSS test.This means we can assume that the time series is trend stationary.\nBoth ADF and KPSS tests conclude that the given series is stationary. This means that we can make use of most of the time series forecasting models such as Exponential Smoothing and ARIMA."
  },
  {
    "objectID": "Analysis/Dataprep.html#decomposition-of-time-series-object",
    "href": "Analysis/Dataprep.html#decomposition-of-time-series-object",
    "title": "Data Preparation",
    "section": "Decomposition of Time Series Object",
    "text": "Decomposition of Time Series Object\nTime series data can exhibit a variety of patterns, and it is often helpful to split a time series into several component to help us improve our understanding of the time series and forecast accuracy.\nFirst, let us plot the monthly mean temperature of the Admiralty weather station.\n\n\nShow the code\np2 &lt;- ggplot(adm_imp_movingavg, aes(x = Index, y = mean_temperature)) + \n  geom_line() + \n  geom_smooth(method=lm) \n\nggplotly(p2)\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFrom the above output, it seems like there were fluctuations in monthly mean temperature but there was no increasing trend.\nIt also seems like for each year, the mean temperature would usually be the highest in May/Jun of each year as indicated by the peaks. Also, for each year, the lowest mean temperature would usually be around Dec/ Jan.\n\n\nTo find out if there is a seasonality, trend and cycle, we can decompose a time series object using stl()from xts package. STL is a versatile and robust method for decomposing time series. STL is an acronym for “Seasonal and Trend decomposition using Loess”, while Loess is a method for estimating nonlinear relationships. The STL method was developed by R. B. Cleveland, Cleveland, McRae, & Terpenning (1990).\nIn the following code chunk, we use: - stl() to decompose the time series object - ts_ts() function from the library converts an xts field to a ts object that can be used with stl().\n\n\nShow the code\nadm_decomposition &lt;- stl(ts_ts(adm_imp_movingavg$mean_temperature), s.window = \"periodic\")\n\n## plot out the decomposition results \nautoplot(adm_decomposition)+ \n  ggtitle(\"Decomposition for Monthly Mean Temperature\") +\n  xlab(\"Month-Year\") + \n  theme_clean()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nsummary(adm_decomposition)\n\n\n Call:\n stl(x = ts_ts(adm_imp_movingavg$mean_temperature), s.window = \"periodic\")\n\n Time.series components:\n    seasonal              trend            remainder         \n Min.   :-0.9176109   Min.   :27.30177   Min.   :-0.9341622  \n 1st Qu.:-0.5109855   1st Qu.:27.43056   1st Qu.:-0.2329592  \n Median : 0.1857624   Median :27.65282   Median :-0.0124042  \n Mean   : 0.0000000   Mean   :27.66756   Mean   :-0.0019506  \n 3rd Qu.: 0.4489919   3rd Qu.:27.85388   3rd Qu.: 0.2320894  \n Max.   : 0.7298073   Max.   :28.19072   Max.   : 0.9402058  \n IQR:\n     STL.seasonal STL.trend STL.remainder data  \n     0.9600       0.4233    0.4650        1.0218\n   %  94.0         41.4      45.5         100.0 \n\n Weights: all == 1\n\n Other components: List of 5\n $ win  : Named num [1:3] 1801 19 13\n $ deg  : Named int [1:3] 0 1 1\n $ jump : Named num [1:3] 181 2 2\n $ inner: int 2\n $ outer: int 0\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nFrom the above output, we noted that there is no clear linear trend for the monthly mean temperature over the years. However, we do note that the monthly mean temperature ranges from 27.3 degrees celsius to ~28.2 degree celsius.\nWe observed seasonality in the monthly mean temperature over the years."
  },
  {
    "objectID": "Analysis/Dataprep.html#building-models",
    "href": "Analysis/Dataprep.html#building-models",
    "title": "Data Preparation",
    "section": "Building Models",
    "text": "Building Models\nFirst we will split the data into training and validation data.\nWhen choosing models, it is common practice to separate the available data into two portions, training and test data, where the training data is used to estimate any parameters of a forecasting method and the test data is used to evaluate its accuracy. Because the test data is not used in determining the forecasts, it should provide a reliable indication of how well the model is likely to forecast on new data.\nThe size of the test set is typically about 20% of the total sample, although this value depends on how long the sample is and how far ahead you want to forecast. The test set should ideally be at least as large as the maximum forecast horizon required.\nFor this section, we will set the test set ~20% of the dataframe we have. However when building the Shiny dashboard, we should allow user input on the duration they want to forecast (e.g. next few months or next few years) because this would affect the size of the test dataset.\n\n\nShow the code\n# create samples \ntrainingtemp &lt;- ts_ts(head(adm_imp_movingavg$mean_temperature, (length(adm_imp_movingavg$mean_temperature)-24))) \nvalidationtemp &lt;- ts_ts(tail(adm_imp_movingavg$mean_temperature, 24)) # we are going to predict the \n\n\n\nBenchmark models\nSome forecasting methods are extremely simple and surprisingly effective. We will use the following two forecasting methods (i.e. naive and seasonal naive) as benchmarks.\n\nNaive method\nFor naïve forecasts, we simply set all forecasts to be the value of the last observation.\n\nData TableMean Absolute Percentage Error (MAPE)Plot of Forecasted Results\n\n\n\nnaive_model &lt;- naive(trainingtemp, h = length(validationtemp))\ndatatable(data.frame(naive_model))\n\n\n\n\n\n\n\nMean absolute percentage error (MAPE) is the percentage equivalent of mean absolute error (MAE). Mean absolute percentage error measures the average magnitude of error produced by a model, or how far off predictions are on average.\nTo measure the performance of how well the model’s forecasted values as compared to the test dataset, we use MAPE() of MLmetrics package to calculate the MAPE.\n\nMAPE(naive_model$mean, validationtemp) * 100\n\n[1] 2.79179\n\n\nFrom the above output, we have a MAPE of 2.79% meaning that the average difference between the forecasted value and the actual value is 2.79%.For a simple model, this forecasting accuracy is very good! It means that other models introduced would need to have a even lower MAPE in order for us to consider them.\n\n\n\nautoplot(naive_model) +\n  ggtitle(\"Naive Forecasts for Monthly Mean Temperature\") +\n  xlab(\"Month-Year\") + \n  ylab(\"Temperature (degree celsius)\") + \n  theme_ipsum_rc()\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeasonal naive method\nA similar method is useful for highly seasonal data. In this case, we set each forecast to be equal to the last observed value from the same season (e.g.,the same month of the previous year).\n\nData TableMAPEPlot of Forecasted Results\n\n\n\nsnaive_model &lt;- snaive(trainingtemp, h = length(validationtemp))\ndatatable(data.frame(snaive_model))\n\n\n\n\n\n\n\n\nMAPE(snaive_model$mean, validationtemp) * 100\n\n[1] 2.06697\n\n\nFrom the above output, we have a MAPE of 2.07% meaning that the average difference between the forecasted value and the actual value is 2.07%.For a simple model, this forecasting accuracy is even better than the naive model! It means that other models introduced would need to have a even lower MAPE in order for us to consider them.\n\n\n\nautoplot(trainingtemp) +\n  autolayer(snaive(trainingtemp, h = length(validationtemp),\n                   series=\"Seasonal Naive\", PI=FALSE)) +\n  ggtitle(\"Seasonal Naive Forecasts for Monthly Mean Temperature\") +\n  xlab(\"Month-Year\") + \n  ylab(\"Temperature (degree celsius)\") + \n  hrbrthemes::theme_ipsum_rc()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExponential Smoothing Methods\n\nSimple exponential smoothing\nThe simplest of the exponentially smoothing methods is naturally called simple exponential smoothing (SES). This method is suitable for forecasting data with no clear trend or seasonal pattern.\n\nData TableMAPEPlot of Forecasted Results\n\n\n\nses_modelT &lt;- ses(trainingtemp, h = length(validationtemp))\ndatatable(data.frame(ses_modelT))\n\n\n\n\n\n\n\n\nMAPE(ses_modelT$mean, validationtemp) * 100\n\n[1] 2.784014\n\n\nFrom the above output, we have a MAPE of 2.78% meaning that the average difference between the forecasted value and the actual value is 2.78%, which is slightly better than the naive model and poorer performance than the seasonal naive model.\n\n\n\nautoplot(ses_modelT) +\n  ggtitle(\"Simple exponential smoothing Forecasts for \\nMonthly Mean Temperature\") +\n  xlab(\"Month-Year\") + \n  ylab(\"Temperature (degree celsius)\") + \n  theme_ipsum_rc()\n\n\n\n\n\n\n\n\nThis output resembles the results from the naive model.\n\n\n\n\n\nState Space Model\nState space models provide a flexible framework for modeling time series data. They consist of two components: the state equation and the observation equation. The state equation describes how the underlying states of the system evolve over time, while the observation equation relates the observed data to the underlying states.\nState space models allow us to capture complex dynamics and dependencies in the data, making them suitable for a wide range of applications, including finance, economics and engineering.\n\nFitting the modelGetting the Forcasted ResultsMAPEPlotting the Forecasted Results\n\n\nWe use ets() from forecast package to find out the optimal model.\n\nets_modelT &lt;- ets(trainingtemp)\nsummary(ets_modelT)\n\nETS(M,N,A) \n\nCall:\n ets(y = trainingtemp) \n\n  Smoothing parameters:\n    alpha = 0.2716 \n    gamma = 1e-04 \n\n  Initial states:\n    l = 27.8746 \n    s = -0.8262 -0.4477 0.1394 0.235 0.4386 0.5042\n           0.6772 0.6073 0.3135 -0.0647 -0.631 -0.9455\n\n  sigma:  0.0158\n\n     AIC     AICc      BIC \n544.5750 548.0035 590.3228 \n\nTraining set error measures:\n                       ME      RMSE      MAE         MPE     MAPE      MASE\nTraining set -0.005080769 0.4168655 0.336926 -0.03791676 1.219642 0.7034614\n                  ACF1\nTraining set 0.1037638\n\n\nWe see ETS (M,N,A). This means we have an ets model with multiplicative errors, no trend and a additive seasonality. Additive seasonality means there aren’t any changes to widths or heights of seasonal periods over time.\n\n\n\nets_forecastT &lt;- forecast(ets_modelT, h=length(validationtemp))\ndatatable(data.frame(ets_forecastT))\n\n\n\n\n\n\n\n\nMAPE(ets_forecastT$mean, validationtemp) *100\n\n[1] 1.471135\n\n\nFrom the above output, we have a MAPE of 1.47% meaning that the average difference between the forecasted value and the actual value is 1.47%, which is so far the best performing model.\n\n\n\nautoplot(ets_forecastT) +\n  ggtitle(\"ETS Forecasts for Monthly Mean Temperature\") +\n  xlab(\"Month-Year\") + \n  ylab(\"Temperature (degree celsius)\") + \n  theme_ipsum_rc()\n\n\n\n\n\n\n\n\n\n\n\n\n\nHolt-Winters\nSince time series analysis decomposes past weather observations into seasonal, trend, and random components, that data can be used to create forecasts based on an assumption that the observed patterns will continue into the future. This type of forecasting is especially useful in business for anticipating potential demand for seasonal products.\nTo forecast future temperatures based on historical observations, we can use Holt-Winters model that considers past seasonal cycles, trends, and random variation.\nNote that for Holt-Winters’ method, we can choose additive or multiplicative seasonality to forecast the monthly mean temperature, which can be part of the user input.\n\nAdditive Seasonality\n\nData TableMAPEPlotting Forecasted Results\n\n\n\nhw_modela &lt;- hw(trainingtemp, h = length(validationtemp), seasonal = \"additive\") \ndatatable(data.frame(hw_modela))\n\n\n\n\n\n\n\n\nMAPE(hw_modela$mean, validationtemp)*100\n\n[1] 1.467264\n\n\nFrom the above output, we have a MAPE of 1.47% meaning that the average difference between the forecasted value and the actual value is 1.47%, which gives us as good performance as the State Space Model.\n\n\n\nautoplot(hw_modela) +\n  ggtitle(\"Holt-Winters (Additive Seasonality) Forecasts for \\nMonthly Mean Temperature\") +\n  xlab(\"Month-Year\") + \n  ylab(\"Temperature (degree celsius)\") + \n  theme_ipsum_rc()\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultiplicative Seasonality\n\nData TableMAPEPlotting Forecasted Results\n\n\n\nhw_modelm &lt;- hw(trainingtemp, h = length(validationtemp), seasonal = \"multiplicative\") \ndatatable(data.frame(hw_modelm))\n\n\n\n\n\n\n\n\nMAPE(hw_modelm$mean, validationtemp)*100\n\n[1] 1.525166\n\n\nFrom the above output, we have a MAPE of 1.53% meaning that the average difference between the forecasted value and the actual value is 1.53%, which is relatively slightly poorer than the Holt-Winters’ Additive Seasonality Model.\n\n\n\nautoplot(hw_modelm) +\n  ggtitle(\"Holt-Winters (Multiplicative Seasonality) Forecasts for \\nMonthly Mean Temperature\") +\n  xlab(\"Month-Year\") + \n  ylab(\"Temperature (degree celsius)\") + \n  theme_ipsum_rc()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nARIMA\nARIMA models provide another approach to time series forecasting. While exponential smoothing models are based on a description of the trend and seasonality in the data, auto regressive integrated moving average (ARIMA) modeling involves a more detailed analysis of the training data using lags and lagged forecast errors.\n\nFitting the modelGetting the Forecasted ResultsMAPEPlotting the forecasted results\n\n\nThe first step is to use a function like auto.arima() to analyze the data and find appropriate model configuration parameters.\n\narima_optimal &lt;- auto.arima(trainingtemp)\narima_optimal\n\nSeries: trainingtemp \nARIMA(1,0,1)(2,1,1)[12] with drift \n\nCoefficients:\n         ar1      ma1    sar1     sar2     sma1   drift\n      0.7912  -0.4842  0.0130  -0.1503  -0.8839  0.0013\ns.e.  0.1180   0.1735  0.1349   0.1298   0.1996  0.0018\n\nsigma^2 = 0.1948:  log likelihood = -93.88\nAIC=201.76   AICc=202.59   BIC=222.55\n\n\nThe function returned the following model: ARIMA (1,0,1)(2,1,1)[12] with drift.\n\n\n\narima_model &lt;- forecast(arima_optimal)\ndatatable(data.frame(arima_model))\n\n\n\n\n\n\n\n\nMAPE(arima_model$mean, validationtemp)*100\n\n[1] 1.552931\n\n\nFrom the above output, we have a MAPE of 1.55% meaning that the average difference between the forecasted value and the actual value is 1.55%, which gives us better performance than the benchmark models.\n\n\n\nautoplot(arima_model) +\n  ggtitle(\"ARIMA Forecasts for Monthly Mean Temperature\") +\n  xlab(\"Month-Year\") + \n  ylab(\"Temperature (degree celsius)\") + \n  theme_ipsum_rc()\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparisons of Models Tried\n\nMAPE Results of Models Tried\n\n\nModel\nMAPE (%)\n\n\n\n\nNaive\n2.79\n\n\nSeasonal Naive\n2.07\n\n\nSimple Exponential Smoothing\n2.78\n\n\nState Space Model\n1.47\n\n\nHolt-Winters’ Model (Additive Seasonality)\n1.47\n\n\nHolt-Winters’ Model (Multiplicative Seasonality)\n1.53\n\n\nARIMA\n1.55\n\n\n\nFrom the above table, the state space model, Holt-Winters’ model and ARIMA model all outperformed the benchmark models (i.e. naive Model and Seasonal Naive Model) for temperature data. We can consider letting users to choose to use these models when forecasting temperature data."
  },
  {
    "objectID": "Analysis/Dataprep.html#investigating-missing-values-1",
    "href": "Analysis/Dataprep.html#investigating-missing-values-1",
    "title": "Data Preparation",
    "section": "Investigating missing values",
    "text": "Investigating missing values\nFirst, let us use summary() to check for missing data.\n\n\nShow the code\nsummary(rain)\n\n\n     tdate              station          daily_rainfall_total\n Min.   :1980-01-01   Length:329156      Min.   :  0.000     \n 1st Qu.:1997-04-29   Class :character   1st Qu.:  0.000     \n Median :2011-09-18   Mode  :character   Median :  0.200     \n Mean   :2007-07-02                      Mean   :  6.822     \n 3rd Qu.:2017-11-27                      3rd Qu.:  6.500     \n Max.   :2023-12-31                      Max.   :278.600     \n NA's   :58                              NA's   :5136        \n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nThe observations ranged from 1 Jan 1980 to 31 Dec 2023. There are 58 rows with missing dates. We should drop these rows since they are unable to tell us which day the observations were made (even if they have rainfall readings).\nThere are 5,136 rows of NAs for daily rainfall.\n\n\n\nFirst, let us drop those rows where date is missing because we would not be able to definitively identify when the temperature(s) were collected (even if there were temperature readings for these rows.\n\n\nShow the code\nrain &lt;- rain %&gt;%\n  drop_na(tdate)\n\nsummary(rain)\n\n\n     tdate              station          daily_rainfall_total\n Min.   :1980-01-01   Length:329098      Min.   :  0.000     \n 1st Qu.:1997-04-29   Class :character   1st Qu.:  0.000     \n Median :2011-09-18   Mode  :character   Median :  0.200     \n Mean   :2007-07-02                      Mean   :  6.822     \n 3rd Qu.:2017-11-27                      3rd Qu.:  6.500     \n Max.   :2023-12-31                      Max.   :278.600     \n                                         NA's   :5078        \n\n\nLet us also do a check of the weather stations.\n\n\nShow the code\nunique(rain$station)\n\n\n [1] \"Macritchie Reservoir\"    \"Lower Peirce Reservoir\" \n [3] \"Admiralty\"               \"East Coast Parkway\"     \n [5] \"Ang Mo Kio\"              \"Newton\"                 \n [7] \"Lim Chu Kang\"            \"Marine Parade\"          \n [9] \"Choa Chu Kang (Central)\" \"Tuas South\"             \n[11] \"Pasir Panjang\"           \"Jurong Island\"          \n[13] \"Nicoll Highway\"          \"Botanic Garden\"         \n[15] \"Choa Chu Kang (South)\"   \"Whampoa\"                \n[17] \"Changi\"                  \"Jurong Pier\"            \n[19] \"Ulu Pandan\"              \"Mandai\"                 \n[21] \"Tai Seng\"                \"Jurong (West)\"          \n[23] \"Clementi\"                \"Sentosa Island\"         \n[25] \"Bukit Panjang\"           \"Kranji Reservoir\"       \n[27] \"Upper Peirce Reservoir\"  \"Kent Ridge\"             \n[29] \"Queenstown\"              \"Tanjong Katong\"         \n[31] \"Somerset (Road)\"         \"Punggol\"                \n[33] \"Simei\"                   \"Toa Payoh\"              \n[35] \"Tuas\"                    \"Bukit Timah\"            \n[37] \"Pasir Ris (Central)\""
  },
  {
    "objectID": "Analysis/Dataprep.html#further-exploration-of-total-rainfall-using-plotly",
    "href": "Analysis/Dataprep.html#further-exploration-of-total-rainfall-using-plotly",
    "title": "Data Preparation",
    "section": "Further exploration of total rainfall using plotly",
    "text": "Further exploration of total rainfall using plotly\nFrom the previous section, we noted that there are many weather stations in the rainfall dataframe. Hence, we will make use of plotly to further explore the missing temperatures.\nFirst, we will pivot the dataframe wider.\n\n\nShow the code\nrain_wide &lt;- rain %&gt;%\n  pivot_wider(names_from = station, values_from = daily_rainfall_total)\n\nsummary(rain_wide)\n\n\n     tdate            Macritchie Reservoir Lower Peirce Reservoir\n Min.   :1980-01-01   Min.   :  0.000      Min.   :  0.000       \n 1st Qu.:1990-12-31   1st Qu.:  0.000      1st Qu.:  0.000       \n Median :2001-12-31   Median :  0.200      Median :  0.400       \n Mean   :2001-12-31   Mean   :  7.145      Mean   :  7.706       \n 3rd Qu.:2012-12-30   3rd Qu.:  7.100      3rd Qu.:  8.200       \n Max.   :2023-12-31   Max.   :256.000      Max.   :227.600       \n                      NA's   :121          NA's   :11141         \n   Admiralty       East Coast Parkway   Ang Mo Kio          Newton       \n Min.   :  0.000   Min.   :  0.000    Min.   :  0.000   Min.   :  0.000  \n 1st Qu.:  0.000   1st Qu.:  0.000    1st Qu.:  0.000   1st Qu.:  0.000  \n Median :  0.400   Median :  0.000    Median :  0.400   Median :  0.200  \n Mean   :  6.735   Mean   :  4.977    Mean   :  7.218   Mean   :  6.625  \n 3rd Qu.:  6.800   3rd Qu.:  3.800    3rd Qu.:  7.800   3rd Qu.:  6.800  \n Max.   :142.000   Max.   :192.600    Max.   :164.400   Max.   :150.400  \n NA's   :10785     NA's   :10778      NA's   :10901     NA's   :11112    \n  Lim Chu Kang     Marine Parade    Choa Chu Kang (Central)   Tuas South     \n Min.   :  0.000   Min.   :  0.00   Min.   :  0.00          Min.   :  0.000  \n 1st Qu.:  0.000   1st Qu.:  0.00   1st Qu.:  0.00          1st Qu.:  0.000  \n Median :  0.400   Median :  0.00   Median :  0.40          Median :  0.200  \n Mean   :  6.759   Mean   :  5.61   Mean   :  7.51          Mean   :  6.892  \n 3rd Qu.:  7.000   3rd Qu.:  4.95   3rd Qu.:  8.60          3rd Qu.:  6.200  \n Max.   :158.600   Max.   :195.40   Max.   :144.20          Max.   :208.200  \n NA's   :11214     NA's   :10933    NA's   :10994           NA's   :11472    \n Pasir Panjang    Jurong Island     Nicoll Highway    Botanic Garden   \n Min.   :  0.00   Min.   :  0.000   Min.   :  0.000   Min.   :  0.000  \n 1st Qu.:  0.00   1st Qu.:  0.000   1st Qu.:  0.000   1st Qu.:  0.000  \n Median :  0.20   Median :  0.000   Median :  0.200   Median :  0.200  \n Mean   :  6.29   Mean   :  6.287   Mean   :  6.548   Mean   :  7.283  \n 3rd Qu.:  6.00   3rd Qu.:  5.600   3rd Qu.:  6.200   3rd Qu.:  7.800  \n Max.   :151.60   Max.   :185.200   Max.   :163.800   Max.   :160.400  \n NA's   :11031    NA's   :11582     NA's   :11269     NA's   :11228    \n Choa Chu Kang (South)    Whampoa            Changi        Jurong Pier     \n Min.   :  0.000       Min.   :  0.000   Min.   :  0.00   Min.   :  0.000  \n 1st Qu.:  0.000       1st Qu.:  0.000   1st Qu.:  0.00   1st Qu.:  0.000  \n Median :  0.400       Median :  0.200   Median :  0.00   Median :  0.200  \n Mean   :  7.469       Mean   :  6.888   Mean   :  5.81   Mean   :  7.131  \n 3rd Qu.:  8.200       3rd Qu.:  7.100   3rd Qu.:  4.40   3rd Qu.:  7.000  \n Max.   :143.800       Max.   :154.600   Max.   :216.20   Max.   :226.400  \n NA's   :11491         NA's   :11606                      NA's   :275      \n   Ulu Pandan          Mandai           Tai Seng       Jurong (West)    \n Min.   :  0.000   Min.   :  0.000   Min.   :  0.000   Min.   :  0.000  \n 1st Qu.:  0.000   1st Qu.:  0.000   1st Qu.:  0.000   1st Qu.:  0.000  \n Median :  0.200   Median :  0.400   Median :  0.000   Median :  0.300  \n Mean   :  7.201   Mean   :  7.218   Mean   :  6.757   Mean   :  7.224  \n 3rd Qu.:  6.900   3rd Qu.:  7.150   3rd Qu.:  5.900   3rd Qu.:  7.000  \n Max.   :230.400   Max.   :247.200   Max.   :217.200   Max.   :226.200  \n NA's   :355       NA's   :828       NA's   :5         NA's   :445      \n    Clementi       Sentosa Island    Bukit Panjang     Kranji Reservoir \n Min.   :  0.000   Min.   :  0.000   Min.   :  0.000   Min.   :  0.000  \n 1st Qu.:  0.000   1st Qu.:  0.000   1st Qu.:  0.000   1st Qu.:  0.000  \n Median :  0.300   Median :  0.000   Median :  0.400   Median :  0.300  \n Mean   :  7.216   Mean   :  6.166   Mean   :  7.316   Mean   :  7.041  \n 3rd Qu.:  7.200   3rd Qu.:  5.100   3rd Qu.:  7.400   3rd Qu.:  7.100  \n Max.   :239.500   Max.   :220.800   Max.   :235.600   Max.   :239.800  \n NA's   :207       NA's   :365       NA's   :227       NA's   :234      \n Upper Peirce Reservoir   Kent Ridge        Queenstown      Tanjong Katong   \n Min.   :  0.000        Min.   :  0.000   Min.   :  0.000   Min.   :  0.000  \n 1st Qu.:  0.000        1st Qu.:  0.000   1st Qu.:  0.000   1st Qu.:  0.000  \n Median :  0.400        Median :  0.200   Median :  0.200   Median :  0.100  \n Mean   :  7.527        Mean   :  7.365   Mean   :  6.805   Mean   :  6.136  \n 3rd Qu.:  7.900        3rd Qu.:  7.400   3rd Qu.:  6.100   3rd Qu.:  5.100  \n Max.   :202.800        Max.   :179.600   Max.   :278.600   Max.   :226.000  \n NA's   :11168          NA's   :10858     NA's   :773       NA's   :392      \n Somerset (Road)      Punggol            Simei           Toa Payoh      \n Min.   :  0.000   Min.   :  0.000   Min.   :  0.000   Min.   :  0.000  \n 1st Qu.:  0.000   1st Qu.:  0.000   1st Qu.:  0.000   1st Qu.:  0.000  \n Median :  0.200   Median :  0.200   Median :  0.000   Median :  0.200  \n Mean   :  6.387   Mean   :  6.594   Mean   :  5.987   Mean   :  7.211  \n 3rd Qu.:  6.200   3rd Qu.:  6.400   3rd Qu.:  5.200   3rd Qu.:  7.600  \n Max.   :155.800   Max.   :168.800   Max.   :182.600   Max.   :150.200  \n NA's   :11427     NA's   :10767     NA's   :11013     NA's   :11037    \n      Tuas          Bukit Timah     Pasir Ris (Central)\n Min.   :  0.000   Min.   :  0.00   Min.   :  0.000    \n 1st Qu.:  0.000   1st Qu.:  0.00   1st Qu.:  0.000    \n Median :  0.200   Median :  0.40   Median :  0.200    \n Mean   :  7.198   Mean   :  7.13   Mean   :  6.165    \n 3rd Qu.:  7.600   3rd Qu.:  7.40   3rd Qu.:  5.400    \n Max.   :217.000   Max.   :156.80   Max.   :185.800    \n NA's   :10690     NA's   :10826    NA's   :11057      \n\n\nWe will make use of plotly to explore the daily rainfall for each station using a dropdown list.\n\n\nShow the code\nplot_ly(data = rain_wide, \n        x = ~tdate, \n        y = ~ Admiralty, \n        type = \"scatter\",\n        mode = \"lines\") |&gt; \n  layout(title = \"Total Rain Fall observed by Weather Station\", \n       xaxis = list(title = \"Date\", range(as.Date(\"1980-01-01\"), as.Date(\"2023-12-31\"))), \n       yaxis = list(title = \"\"), \n      theme_ipsum_rc(plot_title_size = 13, plot_title_margin=4, subtitle_size=11, subtitle_margin=4,  \n                 axis_title_size = 8, axis_text_size=8, axis_title_face= \"bold\", plot_margin = margin(4, 4, 4, 4)),  \n       updatemenus = list(list(type = 'dropdown', \n                               xref = \"paper\", \n                               yref = \"paper\", \n                               xanchor = \"left\",\n                               x = 0.04,\n                               y = 0.95, \n                               buttons = list(\n                                 list(method = \"update\",\n                                      args = list(list(y = list(rain_wide$Admiralty)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed in Admiralty\"))),label = \"Admiralty\"),\n                                 list(method = \"update\",\n                                      args = list(list(y = list(rain_wide$`East Coast Parkway`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed in East Coast Parkway\"))),label = \"East Coast Parkway\"), \n                                 list(method = \"update\",\n                                      args = list(list(y = list(rain_wide$`Ang Mo Kio`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed in Ang Mo Kio\"))),label = \"Ang Mo Kio\"), \n                                 list(method = \"update\",\n                                      args = list(list(y = list(rain_wide$Newton)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed in Newton\"))),label = \"Newton\"), \n                                 list(method = \"update\",\n                                      args = list(list(y = list(rain_wide$`Tuas South`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed in Tuas South\"))),label = \"Tuas South\"),\n                                  list(method = \"update\",\n                                      args = list(list(y = list(rain_wide$`Pasir Panjang`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed in Pasir Panjang\"))),label = \"Pasir Panjang\"), \n                                  list(method = \"update\",\n                                      args = list(list(y = list(rain_wide$`Jurong Island`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed in Jurong Island\"))),label = \"Jurong Island\"), \n                                 list(method = \"update\",\n                                      args = list(list(y = list(rain_wide$`Choa Chu Kang (South)`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed in Choa Chu Kang (South)\"))),label = \"Choa Chu Kang (South)\"), \n                                 list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$Changi)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed in Changi\"))),label = \"Changi\"),\n                                  list(method = \"update\",\n                                      args = list(list(y = list(rain_wide$`Tai Seng`)), \n                                                  list(yaxis = list(title = \"Total Rainfall observed in Tai Seng\"))),label = \"Tai Seng\"),\n                                  list(method = \"update\",\n                                      args = list(list(y = list(rain_wide$`Jurong (West)`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed in Jurong West\"))),label = \"Jurong West\"), \n                                   list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$Clementi)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed in Clementi\"))),label = \"Clementi\"), \n                                   list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$`Sentosa Island`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed in Sentosa\"))),label = \"Sentosa\"), \n                                 list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$`Macritchie Reservoir`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed  at Macritchie Reservoir\"))),label = \"Macritchie Reservoir\"), \n                                list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$`Lower Peirce Reservoir`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed  at Lower Peirce Reservoir\"))),label = \"Lower Peirce Reservoir\"),\n                                 list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$`Lim Chu Kang`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed at Lim Chu Kang\"))),label = \"Lim Chu Kang\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$`Marine Parade`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed at Marine Parade\"))),label = \"Marine Parade\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$`Choa Chu Kang (Central)`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed at Choa Chu Kang (Central)\"))),label = \"Choa Chu Kang (Central)\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$`Nicoll Highway`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed at Nicoll Highway\"))),label = \"Nicoll Highway\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$`Botanic Garden`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed at Botanic Garden\"))),label = \"Botanic Garden\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$Whampoa)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed at Whampoa\"))),label = \"Whampoa\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$`Jurong Pier`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed at Jurong Pier\"))),label = \"Jurong Pier\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$`Ulu Pandan`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed at Ulu Pandan\"))),label = \"Ulu Pandan\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$Mandai)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed at Mandai\"))),label = \"Mandai\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$`Bukit Panjang`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed at Bukit Panjang\"))),label = \"Bukit Panjang\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$`Kranji Reservoir`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed at Kranji Reservoir\"))),label = \"Kranji Reservoir\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$`Upper Peirce Reservoir`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed at Upper Peirce Reservoir\"))),label = \"Upper Peirce Reservoir\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$`Kent Ridge`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed at Kent Ridge\"))),label = \"Kent Ridge\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$Queenstown)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed at Queenstown\"))),label = \"Queenstown\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$`Tanjong Katong`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed at Tanjong Katong\"))),label = \"Tanjong Katong\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$`Somerset (Road)`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed at Somerset (Road)\"))),label = \"Somerset (Road)\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$`Punggol`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed at Punggol\"))),label = \"Punggol\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$`Simei`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed at Simei\"))),label = \"Simei\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$`Toa Payoh`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed at Toa Payoh\"))),label = \"Toa Payoh\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$`Tuas`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed at Tuas\"))),label = \"Tuas\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$`Bukit Timah`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed at Bukit Timah\"))),label = \"Bukit Timah\"),\n                                list(method = \"update\", \n                                        args = list(list(y = list(rain_wide$`Pasir Ris (Central)`)), \n                                                    list(yaxis = list(title = \"Total Rainfall observed at Pasir Ris (Central)\"))),label = \"Pasir Ris (Central)\")\n                               ))))  \n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nIt seems like there are some stations with no rainfall data in all years, while some have rainfall data from certain years onwards. Let’s explore further.\n\n\n\nLet us find out the amount of missing values for each weather station using the following code chunk.\n\nmissing_values &lt;- rain_wide %&gt;%\n  gather(key = \"key\", value = \"val\") %&gt;%\n  mutate(isna = is.na(val)) %&gt;%\n  group_by(key) %&gt;%\n  mutate(total = n()) %&gt;%\n  group_by(key, total, isna) %&gt;%\n  summarise(num.isna = n()) %&gt;%\n  mutate(pct = num.isna / total * 100)\n\nlevels &lt;-\n    (missing_values  %&gt;% filter(isna == T) %&gt;% arrange(desc(pct)))$key\n\npercentage_plot &lt;- missing_values %&gt;%\n      ggplot() +\n        geom_bar(aes(x = reorder(key, desc(pct)), \n                     y = pct, fill=isna), \n                 stat = 'identity', alpha=0.8) +\n      scale_x_discrete(limits = levels) +\n      scale_fill_manual(name = \"\", \n                        values = c('steelblue', 'tomato3'), labels = c(\"Present\", \"Missing\")) +\n      coord_flip() +\n      labs(title = \"Percentage of missing values\", x =\n             'Variable', y = \"% of missing values\")\n\n\nTable of missing valuesPlot of amount of missing values\n\n\n\nmissing_values %&gt;%\n  filter(isna == TRUE) %&gt;% \n  datatable()\n\n\n\n\n\n\n\n\npercentage_plot\n\n\n\n\n\n\n\n\n\n\n\nLet us check if there are any stations where they have 100% missing values.\n\n\nShow the code\nnorfdata &lt;- missing_values %&gt;%\n  filter(isna == TRUE & pct==100)\n\nnorfdata$key\n\n\ncharacter(0)\n\n\nFrom the above output, it seems like no stations have 100% missing values.\nLet us check if there are any stations with no missing values.\n\n\nShow the code\nallrfdata &lt;- missing_values %&gt;%\n  filter(isna == FALSE & pct==100)\n\nallrfdata$key\n\n\n[1] \"Changi\" \"tdate\" \n\n\nFrom the above output, it seems like only Changi weather station has no missing values. This means that for other weather stations there are some amount of missing data for each weather station. Let us impute the missing values in the next section."
  },
  {
    "objectID": "Analysis/Dataprep.html#creating-time-series-object-1",
    "href": "Analysis/Dataprep.html#creating-time-series-object-1",
    "title": "Data Preparation",
    "section": "Creating Time Series Object",
    "text": "Creating Time Series Object\nAs mentioned earlier, for us to make use of the time series forecasting packages and their functions, we would need to convert the tibble dataframe into a time series object.\nBefore we create the time series object, let us first aggregate the daily rainfall readings to monthly rainfall readings by (1) creating the year-month column for each observation using floor_date() and specifying it to derive the year and month of each observation, and (2) aggregate the temperature readings by station and year_month then use summarise() to compute the monthly rainfall reading.\n\n\nShow the code\n#create year-month col\nrain$year_month &lt;- floor_date(rain$tdate, \"month\")\nglimpse(rain)\n\n\nRows: 329,098\nColumns: 4\n$ tdate                &lt;date&gt; 1980-01-01, 1980-01-02, 1980-01-03, 1980-01-04, …\n$ station              &lt;chr&gt; \"Macritchie Reservoir\", \"Macritchie Reservoir\", \"…\n$ daily_rainfall_total &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 22.6, 49.6, 2.4, 0.0, 0.0, 0.…\n$ year_month           &lt;date&gt; 1980-01-01, 1980-01-01, 1980-01-01, 1980-01-01, …\n\n\n\n\nShow the code\nmonthly_rain &lt;- rain %&gt;%                         \n  group_by(station, year_month) %&gt;% \n  summarise(total_rf = sum(daily_rainfall_total))\n\nglimpse(monthly_rain)\n\n\nRows: 10,813\nColumns: 3\nGroups: station [37]\n$ station    &lt;chr&gt; \"Admiralty\", \"Admiralty\", \"Admiralty\", \"Admiralty\", \"Admira…\n$ year_month &lt;date&gt; 2009-01-01, 2009-02-01, 2009-03-01, 2009-04-01, 2009-05-01…\n$ total_rf   &lt;dbl&gt; NA, 148.0, NA, 148.8, 205.6, 92.0, 103.0, 90.2, 67.6, 160.0…\n\n\nWith the monthly temperature of all weather stations, let us filter out one weather station (e.g. Admiralty) to create a tibble data frame adm_rf so that we can convert it into an xts object, which is a type of time series object.\n\nadm_rf&lt;- monthly_rain %&gt;%\n  filter(station == \"Admiralty\")\n\nsummary(adm_rf)\n\n   station            year_month            total_rf    \n Length:179         Min.   :2009-01-01   Min.   : 15.8  \n Class :character   1st Qu.:2012-09-16   1st Qu.:124.4  \n Mode  :character   Median :2016-07-01   Median :189.0  \n                    Mean   :2016-06-19   Mean   :204.9  \n                    3rd Qu.:2020-03-16   3rd Qu.:270.4  \n                    Max.   :2023-12-01   Max.   :517.4  \n                                         NA's   :18     \n\n\nWe will use xts() from xts package to create a time series object. The order.by parameter uses the dates from the adm_rf dataframe. We then use the ts_regular() function to give the time series object adm_rf_xts a regular interval by adding NA values for missing dates.\nJust in case there are missing months which we did not detected, we use the na.fill() function fills in those missing dates by extending values from previous days.\n\n\nShow the code\nadm_rf_xts &lt;- xts(adm_rf[,\"total_rf\"], order.by=as.Date(adm_rf$year_month))\nadm_rf_xts&lt;- ts_regular(adm_rf_xts)\nadm_rf_xts &lt;- na.fill(adm_rf_xts, \"extend\")\n\n\nLet us plot out the monthly rainfall of Admiralty weather station using ggplotly.\n\np3 &lt;- ggplot(adm_rf_xts, aes(x = Index, y = value)) + \n  geom_line() + theme_clean() +\n  labs(title = \"Monthly Rainfall of Admiralty Weather Station\", caption = \"Data from Weather.gov.sg\") +\n  xlab(\"Month-Year\") +\n  ylab(\"Rainfall (in mm)\") +\n  theme_ipsum_rc()\n\nggplotly(p3)\n\n\n\n\n\nFrom the above output, we see that there are missing temperatures for numerous time periods. As a result, the line for the above chart is not continuous.\nLet us investigate futher using imputeTS package’s ggplot_na_distribution, which highlights the missing values in our data.\n\nggplot_na_distribution(adm_rf_xts)\n\n\n\n\n\n\n\n\n\nMissing Value Imputation\nThere are several ways to impute missing data in time series objects.\n\nMoving Averages\nThis na_ma()function also allows us to use linear-weighted and exponentially-weighted moving averages.\n\nadmrf_imp_movingavg &lt;- na_ma(adm_rf_xts, weighting = \"exponential\") #default is exponential. Other options are \"simple\" and \"linear\". We can allow users to choose if the option they want. \n\n#plot chart \nggplot(admrf_imp_movingavg, aes(x = Index, y = value)) + \n  geom_line()\n\n\n\n\n\n\n\n\n\n\nKalman Smoothing\nWe can also use Kalman Smoothing on ARIMA model to impute the missing values.\n\nadmrf_imp_kalman &lt;- na_kalman(adm_rf_xts, model = \"auto.arima\")\n\n#plot chart \n\nggplot(admrf_imp_kalman, aes(x = Index, y = value)) + \n  geom_line()\n\n\n\n\n\n\n\n\nKalman Smoothing also has a “StrucTS” option. Let us try and see how it works for our monthly rainfall data.\n\nadmrf_imp_kalmans &lt;- na_kalman(adm_rf_xts, model = \"StructTS\")\n\n#plot chart \n\nggplot(admrf_imp_kalmans, aes(x = Index, y = value)) + \n  geom_line()"
  },
  {
    "objectID": "Analysis/Dataprep.html#selecting-relevant-columns-for-analysis",
    "href": "Analysis/Dataprep.html#selecting-relevant-columns-for-analysis",
    "title": "Data Preparation",
    "section": "3.2 Selecting relevant columns for analysis",
    "text": "3.2 Selecting relevant columns for analysis\n\n\nShow the code\ndatacleaned &lt;- data %&gt;%\n  select(station, DATE, mean_temperature, maximum_temperature, minimum_temperature, daily_rainfall_total) %&gt;%\n  drop_na(DATE)\n\nstr(datacleaned)\n\n\ntibble [329,098 × 6] (S3: tbl_df/tbl/data.frame)\n $ station             : chr [1:329098] \"Macritchie Reservoir\" \"Macritchie Reservoir\" \"Macritchie Reservoir\" \"Macritchie Reservoir\" ...\n $ DATE                : Date[1:329098], format: \"1980-01-01\" \"1980-01-02\" ...\n $ mean_temperature    : num [1:329098] NA NA NA NA NA NA NA NA NA NA ...\n $ maximum_temperature : num [1:329098] NA NA NA NA NA NA NA NA NA NA ...\n $ minimum_temperature : num [1:329098] NA NA NA NA NA NA NA NA NA NA ...\n $ daily_rainfall_total: num [1:329098] 0 0 0 0 22.6 49.6 2.4 0 0 0 ..."
  },
  {
    "objectID": "Analysis/Dataprep.html#removing-weather-stations-with-no-temperature-data",
    "href": "Analysis/Dataprep.html#removing-weather-stations-with-no-temperature-data",
    "title": "Data Preparation",
    "section": "3.3 Removing weather stations with no temperature data",
    "text": "3.3 Removing weather stations with no temperature data\n\n\nShow the code\nstationstoremove &lt;- c(\"Botanic Garden\",\"Bukit Panjang\",\"Bukit Timah\",\"Choa Chu Kang (Central)\",\"Jurong Pier\",\"Kent Ridge\", \"Kranji Reservoir\", \"Lim Chu Kang\", \"Lower Peirce Reservoir\", \"Macritchie Reservoir\",\"Mandai\", \"Marine Parade\",\"Nicoll Highway\", \"Pasir Ris (Central)\", \"Punggol\", \"Queenstown\",\"Simei\", \"Somerset (Road)\",\"Tanjong Katong\", \"Toa Payoh\", \"Tuas\", \"Ulu Pandan\", \"Upper Peirce Reservoir\",\"Whampoa\")\n\n#create a operator to exclude things \n'%!in%' &lt;- function(x,y)!('%in%'(x,y))\n\n#excluded stations that have no temp data at all \ndatacleaned &lt;- datacleaned %&gt;%\n  filter(station %!in% stationstoremove) \n\nglimpse(datacleaned)\n\n\nRows: 120,139\nColumns: 6\n$ station              &lt;chr&gt; \"Admiralty\", \"Admiralty\", \"Admiralty\", \"Admiralty…\n$ DATE                 &lt;date&gt; 2009-01-01, 2009-01-02, 2009-01-03, 2009-01-04, …\n$ mean_temperature     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ maximum_temperature  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ minimum_temperature  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ daily_rainfall_total &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…"
  },
  {
    "objectID": "Analysis/Dataprep.html#period-summarisation",
    "href": "Analysis/Dataprep.html#period-summarisation",
    "title": "Data Preparation",
    "section": "3.4 Period Summarisation",
    "text": "3.4 Period Summarisation\n\nmean_monthly_temp &lt;- datacleaned %&gt;%\n  group_by(station) %&gt;%\n  summarise_by_time(\n    DATE,\n    .by = \"month\", \n    value = mean(mean_temperature),\n    .type = \"ceiling\"\n  ) %&gt;% rename(mean_monthly_temperature = value)\n\nmean_monthly_temp\n\n# A tibble: 3,947 × 3\n# Groups:   station [13]\n   station   DATE       mean_monthly_temperature\n   &lt;chr&gt;     &lt;date&gt;                        &lt;dbl&gt;\n 1 Admiralty 2009-02-01                     NA  \n 2 Admiralty 2009-03-01                     26.8\n 3 Admiralty 2009-04-01                     NA  \n 4 Admiralty 2009-05-01                     28.1\n 5 Admiralty 2009-06-01                     28.5\n 6 Admiralty 2009-07-01                     28.9\n 7 Admiralty 2009-08-01                     28.1\n 8 Admiralty 2009-09-01                     28.1\n 9 Admiralty 2009-10-01                     28.3\n10 Admiralty 2009-11-01                     28.0\n# ℹ 3,937 more rows\n\n\n\nmin_monthly_temp &lt;- datacleaned %&gt;%\n  group_by(station) %&gt;%\n  summarise_by_time(\n    DATE,\n    .by = \"month\", \n    value = min(minimum_temperature),\n    .type = \"ceiling\"\n  ) %&gt;% rename(min_monthly_temperature = value)\n\nmin_monthly_temp\n\n# A tibble: 3,947 × 3\n# Groups:   station [13]\n   station   DATE       min_monthly_temperature\n   &lt;chr&gt;     &lt;date&gt;                       &lt;dbl&gt;\n 1 Admiralty 2009-02-01                    NA  \n 2 Admiralty 2009-03-01                    23  \n 3 Admiralty 2009-04-01                    NA  \n 4 Admiralty 2009-05-01                    23.7\n 5 Admiralty 2009-06-01                    21.8\n 6 Admiralty 2009-07-01                    23.7\n 7 Admiralty 2009-08-01                    22.5\n 8 Admiralty 2009-09-01                    22.7\n 9 Admiralty 2009-10-01                    23.1\n10 Admiralty 2009-11-01                    22.2\n# ℹ 3,937 more rows\n\n\n\nmax_monthly_temp &lt;- datacleaned %&gt;%\n  group_by(station) %&gt;%\n  summarise_by_time(\n    DATE,\n    .by = \"month\", \n    value = max(minimum_temperature),\n    .type      = \"ceiling\"\n  ) %&gt;% rename(max_monthly_temperature = value)\n\nmax_monthly_temp\n\n# A tibble: 3,947 × 3\n# Groups:   station [13]\n   station   DATE       max_monthly_temperature\n   &lt;chr&gt;     &lt;date&gt;                       &lt;dbl&gt;\n 1 Admiralty 2009-02-01                    NA  \n 2 Admiralty 2009-03-01                    26  \n 3 Admiralty 2009-04-01                    NA  \n 4 Admiralty 2009-05-01                    27.7\n 5 Admiralty 2009-06-01                    27  \n 6 Admiralty 2009-07-01                    27.9\n 7 Admiralty 2009-08-01                    27.6\n 8 Admiralty 2009-09-01                    27.4\n 9 Admiralty 2009-10-01                    27.7\n10 Admiralty 2009-11-01                    26.7\n# ℹ 3,937 more rows\n\n\n\nmonthly_rf &lt;- datacleaned %&gt;%\n  group_by(station) %&gt;%\n  summarise_by_time(\n    DATE,\n    .by = \"month\", \n    value = sum(daily_rainfall_total)\n  ) %&gt;% rename(monthly_rainfall = value)\n\nmonthly_rf\n\n# A tibble: 3,947 × 3\n# Groups:   station [13]\n   station   DATE       monthly_rainfall\n   &lt;chr&gt;     &lt;date&gt;                &lt;dbl&gt;\n 1 Admiralty 2009-01-01             NA  \n 2 Admiralty 2009-02-01            148  \n 3 Admiralty 2009-03-01             NA  \n 4 Admiralty 2009-04-01            149. \n 5 Admiralty 2009-05-01            206. \n 6 Admiralty 2009-06-01             92  \n 7 Admiralty 2009-07-01            103  \n 8 Admiralty 2009-08-01             90.2\n 9 Admiralty 2009-09-01             67.6\n10 Admiralty 2009-10-01            160  \n# ℹ 3,937 more rows"
  },
  {
    "objectID": "Analysis/Dataprep.html#joining-the-data-tables",
    "href": "Analysis/Dataprep.html#joining-the-data-tables",
    "title": "Data Preparation",
    "section": "3.5 Joining the data tables",
    "text": "3.5 Joining the data tables\n\nweatherdata &lt;- left_join(mean_monthly_temp, min_monthly_temp)\nweatherdata\n\n# A tibble: 3,947 × 4\n# Groups:   station [13]\n   station   DATE       mean_monthly_temperature min_monthly_temperature\n   &lt;chr&gt;     &lt;date&gt;                        &lt;dbl&gt;                   &lt;dbl&gt;\n 1 Admiralty 2009-02-01                     NA                      NA  \n 2 Admiralty 2009-03-01                     26.8                    23  \n 3 Admiralty 2009-04-01                     NA                      NA  \n 4 Admiralty 2009-05-01                     28.1                    23.7\n 5 Admiralty 2009-06-01                     28.5                    21.8\n 6 Admiralty 2009-07-01                     28.9                    23.7\n 7 Admiralty 2009-08-01                     28.1                    22.5\n 8 Admiralty 2009-09-01                     28.1                    22.7\n 9 Admiralty 2009-10-01                     28.3                    23.1\n10 Admiralty 2009-11-01                     28.0                    22.2\n# ℹ 3,937 more rows\n\n\n\nweatherdata &lt;- left_join(weatherdata, max_monthly_temp)\nweatherdata\n\n# A tibble: 3,947 × 5\n# Groups:   station [13]\n   station   DATE       mean_monthly_temperature min_monthly_temperature\n   &lt;chr&gt;     &lt;date&gt;                        &lt;dbl&gt;                   &lt;dbl&gt;\n 1 Admiralty 2009-02-01                     NA                      NA  \n 2 Admiralty 2009-03-01                     26.8                    23  \n 3 Admiralty 2009-04-01                     NA                      NA  \n 4 Admiralty 2009-05-01                     28.1                    23.7\n 5 Admiralty 2009-06-01                     28.5                    21.8\n 6 Admiralty 2009-07-01                     28.9                    23.7\n 7 Admiralty 2009-08-01                     28.1                    22.5\n 8 Admiralty 2009-09-01                     28.1                    22.7\n 9 Admiralty 2009-10-01                     28.3                    23.1\n10 Admiralty 2009-11-01                     28.0                    22.2\n# ℹ 3,937 more rows\n# ℹ 1 more variable: max_monthly_temperature &lt;dbl&gt;\n\n\n\nweatherdata &lt;- left_join(weatherdata, monthly_rf)\nsummary(weatherdata)\n\n   station               DATE            mean_monthly_temperature\n Length:3947        Min.   :1980-02-01   Min.   :25.23           \n Class :character   1st Qu.:1996-07-01   1st Qu.:27.34           \n Mode  :character   Median :2011-04-01   Median :27.94           \n                    Mean   :2007-01-17   Mean   :27.88           \n                    3rd Qu.:2017-10-01   3rd Qu.:28.47           \n                    Max.   :2024-01-01   Max.   :29.78           \n                                         NA's   :1750            \n min_monthly_temperature max_monthly_temperature monthly_rainfall\n Min.   :20.00           Min.   :24.00           Min.   :  0.2   \n 1st Qu.:22.30           1st Qu.:26.30           1st Qu.:120.8   \n Median :22.80           Median :27.20           Median :186.6   \n Mean   :22.77           Mean   :27.12           Mean   :199.8   \n 3rd Qu.:23.30           3rd Qu.:28.00           3rd Qu.:263.0   \n Max.   :26.20           Max.   :30.00           Max.   :765.9   \n NA's   :1699            NA's   :1699            NA's   :251     \n\n\n\nweatherdata &lt;- weatherdata %&gt;%\n  filter_by_time(DATE, .start_date = \"2014-01\", .end_date = \"2023-12\")\n\n\nsummary(weatherdata)\n\n   station               DATE            mean_monthly_temperature\n Length:1548        Min.   :2014-01-01   Min.   :25.46           \n Class :character   1st Qu.:2016-07-01   1st Qu.:27.54           \n Mode  :character   Median :2019-01-01   Median :28.13           \n                    Mean   :2018-12-25   Mean   :28.05           \n                    3rd Qu.:2021-07-01   3rd Qu.:28.63           \n                    Max.   :2023-12-01   Max.   :29.78           \n                                         NA's   :227             \n min_monthly_temperature max_monthly_temperature monthly_rainfall\n Min.   :20.40           Min.   :24.20           Min.   :  0.2   \n 1st Qu.:22.40           1st Qu.:26.60           1st Qu.:115.4   \n Median :22.90           Median :27.50           Median :182.0   \n Mean   :22.91           Mean   :27.34           Mean   :192.4   \n 3rd Qu.:23.40           3rd Qu.:28.10           3rd Qu.:253.2   \n Max.   :26.20           Max.   :29.70           Max.   :692.8   \n NA's   :198             NA's   :198             NA's   :159     \n\n\n\nwrite_rds(weatherdata, \"data/weather_data.rds\")"
  },
  {
    "objectID": "Analysis/Dataprep.html#missing-value-imputation",
    "href": "Analysis/Dataprep.html#missing-value-imputation",
    "title": "Data Preparation",
    "section": "3.6 Missing value imputation",
    "text": "3.6 Missing value imputation\n\nunique(weatherdata$DATE)\n\n  [1] \"2014-01-01\" \"2014-02-01\" \"2014-03-01\" \"2014-04-01\" \"2014-05-01\"\n  [6] \"2014-06-01\" \"2014-07-01\" \"2014-08-01\" \"2014-09-01\" \"2014-11-01\"\n [11] \"2014-12-01\" \"2015-01-01\" \"2015-02-01\" \"2015-03-01\" \"2015-04-01\"\n [16] \"2015-05-01\" \"2015-06-01\" \"2015-07-01\" \"2015-08-01\" \"2015-09-01\"\n [21] \"2015-10-01\" \"2015-11-01\" \"2015-12-01\" \"2016-01-01\" \"2016-02-01\"\n [26] \"2016-03-01\" \"2016-04-01\" \"2016-05-01\" \"2016-06-01\" \"2016-07-01\"\n [31] \"2016-08-01\" \"2016-09-01\" \"2016-10-01\" \"2016-11-01\" \"2016-12-01\"\n [36] \"2017-01-01\" \"2017-02-01\" \"2017-03-01\" \"2017-04-01\" \"2017-05-01\"\n [41] \"2017-06-01\" \"2017-07-01\" \"2017-08-01\" \"2017-09-01\" \"2017-10-01\"\n [46] \"2017-11-01\" \"2017-12-01\" \"2018-01-01\" \"2018-02-01\" \"2018-03-01\"\n [51] \"2018-04-01\" \"2018-05-01\" \"2018-06-01\" \"2018-07-01\" \"2018-08-01\"\n [56] \"2018-09-01\" \"2018-10-01\" \"2018-11-01\" \"2018-12-01\" \"2019-01-01\"\n [61] \"2019-02-01\" \"2019-03-01\" \"2019-04-01\" \"2019-05-01\" \"2019-06-01\"\n [66] \"2019-07-01\" \"2019-08-01\" \"2019-09-01\" \"2019-10-01\" \"2019-11-01\"\n [71] \"2019-12-01\" \"2020-01-01\" \"2020-02-01\" \"2020-03-01\" \"2020-04-01\"\n [76] \"2020-05-01\" \"2020-06-01\" \"2020-07-01\" \"2020-08-01\" \"2020-09-01\"\n [81] \"2020-10-01\" \"2020-11-01\" \"2020-12-01\" \"2021-01-01\" \"2021-02-01\"\n [86] \"2021-03-01\" \"2021-04-01\" \"2021-05-01\" \"2021-06-01\" \"2021-07-01\"\n [91] \"2021-08-01\" \"2021-09-01\" \"2021-10-01\" \"2021-11-01\" \"2021-12-01\"\n [96] \"2022-01-01\" \"2022-02-01\" \"2022-03-01\" \"2022-04-01\" \"2022-05-01\"\n[101] \"2022-06-01\" \"2022-07-01\" \"2022-08-01\" \"2022-09-01\" \"2022-10-01\"\n[106] \"2022-11-01\" \"2022-12-01\" \"2023-01-01\" \"2023-02-01\" \"2023-03-01\"\n[111] \"2023-04-01\" \"2023-05-01\" \"2023-06-01\" \"2023-07-01\" \"2023-08-01\"\n[116] \"2023-09-01\" \"2023-10-01\" \"2023-11-01\" \"2023-12-01\" \"2014-10-01\"\n\n\n\nweatherdata$mean_monthly_temperature &lt;- weatherdata$mean_monthly_temperature %&gt;%\n  ts_impute_vec(period = 2, lambda = \"auto\")\n\nsummary(weatherdata)\n\n   station               DATE            mean_monthly_temperature\n Length:1548        Min.   :2014-01-01   Min.   :25.46           \n Class :character   1st Qu.:2016-07-01   1st Qu.:27.54           \n Mode  :character   Median :2019-01-01   Median :28.09           \n                    Mean   :2018-12-25   Mean   :28.03           \n                    3rd Qu.:2021-07-01   3rd Qu.:28.57           \n                    Max.   :2023-12-01   Max.   :29.78           \n                                                                 \n min_monthly_temperature max_monthly_temperature monthly_rainfall\n Min.   :20.40           Min.   :24.20           Min.   :  0.2   \n 1st Qu.:22.40           1st Qu.:26.60           1st Qu.:115.4   \n Median :22.90           Median :27.50           Median :182.0   \n Mean   :22.91           Mean   :27.34           Mean   :192.4   \n 3rd Qu.:23.40           3rd Qu.:28.10           3rd Qu.:253.2   \n Max.   :26.20           Max.   :29.70           Max.   :692.8   \n NA's   :198             NA's   :198             NA's   :159     \n\n\n\nweatherdata %&gt;%\n  group_by(station) %&gt;%\n  plot_time_series(DATE, mean_monthly_temperature, .facet_ncol = 3)\n\n\n\n\n\n\nweatherdata$min_monthly_temperature &lt;- weatherdata$min_monthly_temperature %&gt;%\n  ts_impute_vec(period = 2, lambda = \"auto\")\n\nsummary(weatherdata)\n\n   station               DATE            mean_monthly_temperature\n Length:1548        Min.   :2014-01-01   Min.   :25.46           \n Class :character   1st Qu.:2016-07-01   1st Qu.:27.54           \n Mode  :character   Median :2019-01-01   Median :28.09           \n                    Mean   :2018-12-25   Mean   :28.03           \n                    3rd Qu.:2021-07-01   3rd Qu.:28.57           \n                    Max.   :2023-12-01   Max.   :29.78           \n                                                                 \n min_monthly_temperature max_monthly_temperature monthly_rainfall\n Min.   :20.40           Min.   :24.20           Min.   :  0.2   \n 1st Qu.:22.40           1st Qu.:26.60           1st Qu.:115.4   \n Median :22.90           Median :27.50           Median :182.0   \n Mean   :22.91           Mean   :27.34           Mean   :192.4   \n 3rd Qu.:23.40           3rd Qu.:28.10           3rd Qu.:253.2   \n Max.   :26.20           Max.   :29.70           Max.   :692.8   \n                         NA's   :198             NA's   :159     \n\n\n\nweatherdata %&gt;%\n  group_by(station) %&gt;%\n  plot_time_series(DATE, min_monthly_temperature, .facet_ncol = 3)\n\n\n\n\n\n\nweatherdata$max_monthly_temperature &lt;- weatherdata$max_monthly_temperature %&gt;%\n  ts_impute_vec(period = 2, lambda = \"auto\")\n\nsummary(weatherdata)\n\n   station               DATE            mean_monthly_temperature\n Length:1548        Min.   :2014-01-01   Min.   :25.46           \n Class :character   1st Qu.:2016-07-01   1st Qu.:27.54           \n Mode  :character   Median :2019-01-01   Median :28.09           \n                    Mean   :2018-12-25   Mean   :28.03           \n                    3rd Qu.:2021-07-01   3rd Qu.:28.57           \n                    Max.   :2023-12-01   Max.   :29.78           \n                                                                 \n min_monthly_temperature max_monthly_temperature monthly_rainfall\n Min.   :20.40           Min.   :24.20           Min.   :  0.2   \n 1st Qu.:22.40           1st Qu.:26.60           1st Qu.:115.4   \n Median :22.90           Median :27.40           Median :182.0   \n Mean   :22.91           Mean   :27.32           Mean   :192.4   \n 3rd Qu.:23.40           3rd Qu.:28.10           3rd Qu.:253.2   \n Max.   :26.20           Max.   :29.70           Max.   :692.8   \n                                                 NA's   :159     \n\n\n\nweatherdata %&gt;%\n  group_by(station) %&gt;%\n  plot_time_series(DATE, max_monthly_temperature, .facet_ncol = 3)\n\n\n\n\n\n\nweatherdata$monthly_rainfall &lt;- weatherdata$monthly_rainfall%&gt;%\n  ts_impute_vec(period = 2, lambda = \"auto\")\n\nsummary(weatherdata)\n\n   station               DATE            mean_monthly_temperature\n Length:1548        Min.   :2014-01-01   Min.   :25.46           \n Class :character   1st Qu.:2016-07-01   1st Qu.:27.54           \n Mode  :character   Median :2019-01-01   Median :28.09           \n                    Mean   :2018-12-25   Mean   :28.03           \n                    3rd Qu.:2021-07-01   3rd Qu.:28.57           \n                    Max.   :2023-12-01   Max.   :29.78           \n min_monthly_temperature max_monthly_temperature monthly_rainfall\n Min.   :20.40           Min.   :24.20           Min.   :  0.2   \n 1st Qu.:22.40           1st Qu.:26.60           1st Qu.:116.8   \n Median :22.90           Median :27.40           Median :180.9   \n Mean   :22.91           Mean   :27.32           Mean   :190.6   \n 3rd Qu.:23.40           3rd Qu.:28.10           3rd Qu.:248.2   \n Max.   :26.20           Max.   :29.70           Max.   :692.8   \n\n\n\nweatherdata %&gt;%\n  group_by(station) %&gt;%\n  plot_time_series(DATE, monthly_rainfall, .facet_ncol = 3)\n\n\n\n\n\n\nwrite_rds(weatherdata, \"data/weather_data_imputed.rds\")\n\nThe dataset weather_data_imputed was the starting dataset for further analysis - Exploratory Data Analysis, Confirmatory Data Analysis and Forecasting."
  },
  {
    "objectID": "Analysis/CDA.html#temperature-2",
    "href": "Analysis/CDA.html#temperature-2",
    "title": "Confirmatory Data Analysis",
    "section": "4.3.2 Temperature",
    "text": "4.3.2 Temperature\n\n\nShow the code\ntemp_stn &lt;- weather_data_detailed %&gt;%\n  group_by(station,year) %&gt;%\n  summarise(meantemp = median(mean_monthly_temperature),\n            maxtemp = max(max_monthly_temperature),\n            mintemp = min(min_monthly_temperature))\n\n\nDT::datatable(temp_stn,class = \"compact\")\n\n\n\n\n\n\nSaving it as a csv file:\n\n\nShow the code\nwrite_csv(temp_stn, \"data/temp_stn.csv\")\n\n\n\n4.3.2.1 Overview of Temperature across weather stations\n\nMean TemperatureMaximum TemperatureMinimum Temperature\n\n\n\np26 &lt;- ggplot(temp_stn,\n             aes(y = meantemp,\n                 x = year,\n                 group = station,\n                 color = station)) +\n  geom_line() +\n  facet_wrap(~station,scales = \"free_x\") +\n  labs(title=\"Mean temperature across weather stations from 2014 to 2023\",\n       y = \"Temperature (°C)\",\n       x = \"Year\") +\n  theme_minimal() +\n  theme(axis.text.x=element_text(angle=90,hjust=1))\n\np26 &lt;- ggplotly(p26, tooltip=\"all\",width = 800,height = 600) %&gt;% \n  layout(width = 800, height = 600)\n\np26\n\n\n\n\n\n\n\n\np27 &lt;- ggplot(temp_stn,\n             aes(y = maxtemp,\n                 x = year,\n                 group = station,\n                 color = station)) +\n  geom_line() +\n  facet_wrap(~station,scales = \"free_x\") +\n  labs(title=\"Max temperature across weather stations from 2014 to 2023\",\n       y = \"Temperature (°C)\",\n       x = \"Year\") +\n  theme_minimal() +\n  theme(axis.text.x=element_text(angle=90,hjust=1))\n\np27 &lt;- ggplotly(p27, tooltip=\"all\",width = 800,height = 600) %&gt;% \n  layout(width = 800, height = 600)\n\np27\n\n\n\n\n\nBased on observation, it seems like max temperature for each weather station did not undergo significant changes over the years from 2014 to 2023.\n\n\n\np28 &lt;- ggplot(temp_stn,\n             aes(y = mintemp,\n                 x = year,\n                 group = station,\n                 color = station)) +\n  geom_line() +\n  facet_wrap(~station,scales = \"free_x\") +\n  labs(title=\"Min temperature across weather stations from 2014 to 2023\",\n       y = \"Temperature (°C)\",\n       x = \"Year\") +\n  theme_minimal() +\n  theme(axis.text.x=element_text(angle=90,hjust=1))\n\np28 &lt;- ggplotly(p28, tooltip=\"all\",width = 800,height = 600) %&gt;% \n  layout(width = 800, height = 600)\n\np28\n\n\n\n\n\n\n\n\n\ncombined_data3 &lt;- reshape2::melt(temp_stn, id.vars = c(\"station\", \"year\"), variable.name = \"temperature_type\")\n\np29 &lt;- ggplot(combined_data3, aes(x = year, \n                                 y = value,\n                                 color = temperature_type)) +\n  geom_line() +\n  facet_wrap(~ station,scales = \"free_x\")+\n  labs(title = \"Detailed Temperature Trends across stations from 2014 to 2023\",\n       y = \"Temperature (°C)\",\n       x = \"Year\",\n       color = \"Temperature Type\") +\n  scale_x_continuous(breaks = seq(2014,2023, 1)) +\n  scale_color_manual(values = c(\"turquoise\", \"violetred2\", \"steelblue2\"), \n                      labels = c(\"Mean\", \"Max\", \"Min\")) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1),\n        panel.border = element_rect(color = \"lightgrey\",linetype = \"dashed\", fill = NA, size = 1))\n\np29 &lt;- ggplotly(p29, tooltip = \"all\", width = 800, height = 600) %&gt;% \n  layout(width = 800, height = 600)\n\np29\n\n\n\n\n\nSaving combined_data, combined_data2 and combined_data3 as csv files:\n\n\nShow the code\nwrite_csv(combined_data, \"data/combined_data.csv\")\nwrite_csv(combined_data2, \"data/combined_data2.csv\")\nwrite_csv(combined_data3, \"data/combined_data3.csv\")\n\n\n\n\n4.3.2.2 Statistical Test for Temperature across weather stations\n\nMean TemperatureMaximum TemperatureMinimum Temperature\n\n\nThe hypothesis is as follows:\nH0: There is no difference between mean temperature across weather stations.\nH1: There is a difference between mean temperature across weather stations.\n\np30 &lt;- ggbetweenstats(\n  data = weather_data_detailed,\n  x = station, \n  y = mean_monthly_temperature,\n  type = \"np\",\n  pairwise.display = \"significant\",\n  conf.level = 0.95,\n  messages = FALSE,\n  title=\"Distribution of Mean Temperature by Station\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Station\",\n  ggsignif.args = list(textsize = 3)\n) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1),\n        plot.title = element_text(size = 15),\n        text = element_text(size = 15))\np30\n\n\n\n\n\n\n\n\nThe plot above shows p-value &lt; 0.05, for which the null hypothesis will be rejected at alpha = 0.05. There is sufficient evidence to indicate that there is a difference in the mean temperature across stations. This suggests that different regions of Singapore are hotter/cooler.\n\n\nThe hypothesis is as follows:\nH0: There is no difference between maximum temperature across weather stations.\nH1: There is a difference between maximum temperature across weather stations.\n\np31 &lt;- ggbetweenstats(\n  data = weather_data_detailed,\n  x = station, \n  y = max_monthly_temperature,\n  type = \"np\",\n  pairwise.display = \"significant\",\n  conf.level = 0.95,\n  messages = FALSE,\n  title=\"Distribution of Max Temperature by Station\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Station\",\n  ggsignif.args = list(textsize = 3)\n) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1),\n        plot.title = element_text(size = 15),\n        text = element_text(size = 15))\np31\n\n\n\n\n\n\n\n\nThe plot above shows p-value of the test &lt; 0.05, for which the null hypothesis will be rejected at alpha = 0.05. There is sufficient evidence to indicate that there is a difference in the max temperature across stations. This suggests that different regions of Singapore are hotter/cooler.\n\n\nThe hypothesis is as follows:\nH0: There is no difference between minimum temperature across weather stations.\nH1: There is a difference between minimum temperature across weather stations.\n\np32 &lt;- ggbetweenstats(\n  data = weather_data_detailed,\n  x = station, \n  y = min_monthly_temperature,\n  type = \"np\",\n  pairwise.display = \"significant\",\n  conf.level = 0.95,\n  messages = FALSE,\n  title=\"Distribution of Min Temperature by Station\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Station\",\n  ggsignif.args = list(textsize = 3)\n) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1),\n        plot.title = element_text(size = 15),\n        text = element_text(size = 15))\np32\n\n\n\n\n\n\n\n\nThe plot above shows p-value of the test is &lt; 0.05, for which the null hypothesis will be rejected at alpha = 0.05. There is sufficient evidence to indicate that there is a difference in the min temperature across stations. This suggests that different regions of Singapore are hotter/cooler."
  }
]